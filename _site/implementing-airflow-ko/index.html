<!DOCTYPE html>
<html>
  <head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-K04Y972F7E"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-K04Y972F7E');
  </script>

  <title>Airflow 도입 후기 – Joshua Kim – Analytics Engineer | Data Analyst</title>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  “Airflow 도입을 통해 사내 데이터 알림 시스템을 효율적으로 관리하고자 기존 Python 기반 세션 방식에서 벗어나 DAG 기반 워크플로우를 구축했습니다. Docker Compose를 활용해 로컬 및 VM 환경에서 Airflow를 설정하고, Slack 알림을 포함한 다양한 데이터 파이프라인을 자동화했습니다. 이를 통해 유지보수 부담을 줄이고, 안정성을 높이며, 확장 가능한 데이터 처리 환경을 마련할 수 있었습니다.”

" />
    <meta property="og:description" content="
  “Airflow 도입을 통해 사내 데이터 알림 시스템을 효율적으로 관리하고자 기존 Python 기반 세션 방식에서 벗어나 DAG 기반 워크플로우를 구축했습니다. Docker Compose를 활용해 로컬 및 VM 환경에서 Airflow를 설정하고, Slack 알림을 포함한 다양한 데이터 파이프라인을 자동화했습니다. 이를 통해 유지보수 부담을 줄이고, 안정성을 높이며, 확장 가능한 데이터 처리 환경을 마련할 수 있었습니다.”

" />
    
    <meta name="author" content="Joshua Kim" />

    
    <meta property="og:title" content="Airflow 도입 후기" />
    <meta property="twitter:title" content="Airflow 도입 후기" />
    
  <!-- Async font loading -->
<script>
  window.WebFontConfig = {
      custom: {
          families: ['Spoqa Han Sans:100,300,400,700'],
          urls: ['https://spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css']
      },
      timeout: 60000
  };
  (function(d) {
      var wf = d.createElement('script'), s = d.scripts[0];
      wf.src = 'https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js';
      s.parentNode.insertBefore(wf, s);
  })(document);
</script>


  

  <!--[if lt IE 9]>
    <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="alternate" type="application/rss+xml" title="Joshua Kim - Analytics Engineer | Data Analyst" href="/feed.xml" />

  <link rel="apple-touch-icon" sizes="57x57" href="/assets/logo/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/logo/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/logo/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/logo/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/logo/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/logo/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/logo/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/logo/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/logo/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/logo/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/logo/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/logo/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/logo/favicon-16x16.png">
  <link rel="manifest" href="/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
</head>

  <body>      

    <div class="wrapper-masthead">
  <div class="container">
    <header class="masthead clearfix">
      
        <a href="/" class="site-avatar"><img src="https://avatars.githubusercontent.com/u/144670043?v=4" /></a>
      

      <div class="site-info">
        <h1 class="site-name"><a href="/">Joshua Kim</a></h1>
        <p class="site-description">Analytics Engineer | Data Analyst</p>
      </div>

      <nav>
        
        
        <a href="/about">About</a>
        
        
        
        <a href="/">Articles</a>
        
        
        
        <a href="/archive">Archive</a>
        
        
        
        <a href="/tags">Tags</a>
        
        
      </nav>
    </header>
  </div>
</div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Airflow 도입 후기</h1>

  <div>
    <span class="date">
      2024-12-28
    </span>

    <ul class="tag">
      
      <li>
        <a href="http://localhost:4000/tags#Language (Korean)">
          Language (Korean)
        </a>
      </li>
      
      <li>
        <a href="http://localhost:4000/tags#Article (Project)">
          Article (Project)
        </a>
      </li>
      
      <li>
        <a href="http://localhost:4000/tags#Level (1. Beginner)">
          Level (1. Beginner)
        </a>
      </li>
      
      <li>
        <a href="http://localhost:4000/tags#Field (Data Engineering)">
          Field (Data Engineering)
        </a>
      </li>
      
      <li>
        <a href="http://localhost:4000/tags#Skills (Airflow)">
          Skills (Airflow)
        </a>
      </li>
      
    </ul>
  </div>

  <div class="entry">
    <blockquote>
  <p>“Airflow 도입을 통해 사내 데이터 알림 시스템을 효율적으로 관리하고자 기존 Python 기반 세션 방식에서 벗어나 DAG 기반 워크플로우를 구축했습니다. Docker Compose를 활용해 로컬 및 VM 환경에서 Airflow를 설정하고, Slack 알림을 포함한 다양한 데이터 파이프라인을 자동화했습니다. 이를 통해 유지보수 부담을 줄이고, 안정성을 높이며, 확장 가능한 데이터 처리 환경을 마련할 수 있었습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>도입 배경</li>
  <li>도입 후기
    <ul>
      <li>2.1. 작업 계획</li>
      <li>2.2. 로컬 환경 세팅</li>
      <li>2.3. VM Instance 환경 세팅</li>
      <li>2.4. DAG 만들기</li>
    </ul>
  </li>
  <li>앞으로의 과제</li>
</ol>

<hr />

<h1 id="1-도입-배경">1. 도입 배경</h1>

<p>저는 아이오트러스트에서 데이터 엔지니어 포지션으로 근무하며, 아래와 같이 주로 <strong>애널리틱스 엔지니어링</strong> 업무에 집중하고 있어요.</p>

<pre><code class="language-plain">- (1) 데이터 웨어하우스 &amp; 데이터 마트 설계 및 개발
- (2) BI 대시보드
- (3) Ad-hoc 데이터 알림 봇 개발
- (4) 이벤트 택소노미 설계 + 정의서 관리
- (5) (Finance/HR/CX) 업무 자동화 환경 구축
</code></pre>

<p>그런데, 시간이 흐를수록 “<strong>(3) Ad-hoc 데이터 알림 봇 개발</strong>” 역할에 문제가 발생하기 시작했어요. 동료들이 적시에 중요한 핵심 지표를 슬랙으로 빠르게 확인할 수 있도록 지원하는 과정에서, 서서히 Python 파일이 많아졌고 관리 리소스도 제법 늘어나게 된 것이죠.</p>

<p><img src="/assets/2024-12-28-implementing-airflow/1.webp" alt="" /></p>

<p>구체적으로는, 아래와 같이 <code class="language-plaintext highlighter-rouge">tmux</code>를 통해 세션 레벨에서 각 Python 파일을 직접 실행하여 모든 슬랙 알림을 관리하고 있었어요. <code class="language-plaintext highlighter-rouge">tmux</code>는 단일 터미널에서 여러 세션을 독립적으로 관리할 수 있도록 해주는 오픈소스 터미널 자동화 도구예요. (<a href="https://en.wikipedia.org/wiki/Tmux">Wikipedia</a>)</p>

<p><img src="/assets/2024-12-28-implementing-airflow/2.webp" alt="" /></p>

<p>점차 Python 파일이 많아지고 복잡해지면서 구체적으로 다음과 같은 문제가 발생하기 시작했어요.</p>

<p><strong>(1) 유지보수 부담이 늘어났어요.</strong></p>

<p>Python 파일의 오류가 발생하면 실행이 즉시 중단되어 디버깅이 완료되기 전까지는 동료들이 알림을 받을 수 없었어요. 작업 재시도 기능이 없었기 때문이죠.</p>

<p>또한, 디버깅 과정에서 제법 많은 시간을 허비했어요. 의존성이 있는 각 파이프라인 단계를 main() 함수 하나로 관리하다 보니, 정확한 실패 원인을 찾는 데 상당한 시간이 소요되었던 것이죠. 그러다보니 중요한 일에 몰입하지 못하고 업무가 산만해지기 쉬웠죠.</p>

<p><strong>(2) 세션 기반 관리의 안정성이 부족했어요.</strong></p>

<p>서버 재부팅이나 네트워크 문제로 인해 작업이 중단될 여지가 높았고, 실제로 알 수 없는 이유로 세션이 모두 종료되어 복구 작업을 해야 했던 적도 있었어요.</p>

<p>또한, 각 세션이 동일한 환경을 공유하기 때문에 <a href="https://docs.python.org/3/library/venv.html">Python Venv</a>를 사용하더라도 의도치 않은 충돌이나 종속성 문제가 발생할 여지가 있었어요.</p>

<p><strong>이런 이유로 Airflow를 통한 워크플로우 관리 필요성이 점차 커지게 되었어요.</strong></p>

<ul>
  <li>컨테이너만 재시작하면 각 작업을 자동으로 복구할 수 있어요.</li>
  <li>각 작업별로 독립된 환경을 제공해요.</li>
  <li>지속적으로 작업을 확장할 수 있어요.</li>
  <li>웹서버 UI를 통해 관리를 용이하게 할 수 있어요.</li>
</ul>

<p>사실, “<strong>Ad-hoc 데이터 알림 봇 개발</strong>” 업무 초기에 이미 Airflow 도입을 적극적으로 검토했었습니다. 하지만 당시 워크플로우의 규모가 매우 작았기 때문에, <strong>YAGNI</strong> 원칙에 따라 굳이 도입할 필요가 없다고 판단했죠.</p>

<p><a href="https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it">YAGNI</a>는 “<strong>You Aren’t Gonna Need It</strong>”의 준말로, 필요하지 않은 기능이나 복잡성을 미리 추가하지 말라는 애자일 소프트웨어 개발의 핵심 원칙 중 하나입니다. 당시에는 현재 요구 사항을 충족하는 적절한 수준에서만 워크플로우 환경을 구축하는 것이 중요하다고 생각해, 세션 기반 관리 방식을 선택했어요.</p>

<p>그러나 워크플로우 규모가 점차 커지면서 세션 관리 방식에서 발생하는 리소스 낭비와 비효율성이 눈에 띄게 늘어났어요. 이에 따라, Airflow 도입이 필요하다고 판단하게 되었습니다.</p>

<hr />

<h1 id="2-도입-후기">2. 도입 후기</h1>

<h3 id="21-작업-계획">2.1. 작업 계획</h3>

<p><img src="/assets/2024-12-28-implementing-airflow/3.webp" alt="" /></p>

<p>먼저 위 그림과 같이 계획을 세웠어요.</p>

<p>(1) 기존 Python 파일들을 <strong>DAG 포맷</strong>에 맞게 코드를 수정합니다.</p>

<p>(2) <strong>로컬 환경</strong>에서 Airflow 프로젝트를 Docker Compose로 빌드하여, 알림이 슬랙 테스트 채널에 제대로 전송되는지 확인합니다.</p>

<p>(3) <strong>VM Instance 환경</strong>에서도 Airflow 프로젝트를 Docker Compose로 빌드하여, 최종적으로 알림 환경을 배포합니다.</p>

<h3 id="22-로컬-환경-세팅">2.2. 로컬 환경 세팅</h3>

<p>(0) 기본적으로 Docker가 설치되어 있어야 해요.</p>

<ul>
  <li>저는 Docker Desktop 앱을 설치하는 방향으로 준비했어요. 정확한 설치 방법은 <a href="https://www.docker.com/get-started/">이 문서</a>를 참고해주세요.</li>
</ul>

<p>(1) Python Venv를 생성했어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> venv venv
<span class="nb">source </span>venv/bin/activate
</code></pre></div></div>

<p>(2) <code class="language-plaintext highlighter-rouge">airflow</code> 이름의 디렉토리에서 아래 명령어를 통해 Airflow 이미지를 로드했어요. (<code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> 파일이 생성될 거예요.)</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-LfO</span> <span class="s1">'https://airflow.apache.org/docs/apache-airflow/2.9.1/docker-compose.yaml'</span>
</code></pre></div></div>

<p>(3) <code class="language-plaintext highlighter-rouge">dags</code>, <code class="language-plaintext highlighter-rouge">logs</code>, <code class="language-plaintext highlighter-rouge">plugins</code> 하위 디렉토리를 생성하고, <strong>AIRFLOW_UID</strong> 환경 변수를 지닌 <code class="language-plaintext highlighter-rouge">.env</code> 파일을 생성했어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> ./dags ./logs ./plugins
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"AIRFLOW_UID=</span><span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span><span class="s2">"</span> <span class="o">&gt;</span> .env
</code></pre></div></div>

<p>(4) 아래 내용을 지닌 <code class="language-plaintext highlighter-rouge">Dockerfile</code> 파일을 생성했어요.</p>

<div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># First-time build can take upto 10 mins.</span>

<span class="k">FROM</span><span class="s"> apache/airflow:2.9.1</span>

<span class="k">ENV</span><span class="s"> AIRFLOW_HOME=/opt/airflow</span>

<span class="k">USER</span><span class="s"> root</span>
<span class="k">RUN </span>apt-get update <span class="nt">-qq</span> <span class="o">&amp;&amp;</span> apt-get <span class="nb">install </span>vim <span class="nt">-qqq</span>
<span class="c"># git gcc g++ -qqq</span>

<span class="k">COPY</span><span class="s"> requirements.txt .</span>
<span class="k">RUN </span>pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Ref: https://airflow.apache.org/docs/docker-stack/recipes.html</span>

<span class="k">SHELL</span><span class="s"> ["/bin/bash", "-o", "pipefail", "-e", "-u", "-x", "-c"]</span>

<span class="k">ARG</span><span class="s"> CLOUD_SDK_VERSION=322.0.0</span>
<span class="k">ENV</span><span class="s"> GCLOUD_HOME=/home/google-cloud-sdk</span>

<span class="k">ENV</span><span class="s"> PATH="${GCLOUD_HOME}/bin/:${PATH}"</span>

<span class="k">RUN </span><span class="nv">DOWNLOAD_URL</span><span class="o">=</span><span class="s2">"https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-</span><span class="k">${</span><span class="nv">CLOUD_SDK_VERSION</span><span class="k">}</span><span class="s2">-linux-x86_64.tar.gz"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nv">TMP_DIR</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span><span class="nb">mktemp</span> <span class="nt">-d</span><span class="si">)</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> curl <span class="nt">-fL</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DOWNLOAD_URL</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--output</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/google-cloud-sdk.tar.gz"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">tar </span>xzf <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/google-cloud-sdk.tar.gz"</span> <span class="nt">-C</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--strip-components</span><span class="o">=</span>1 <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">/install.sh"</span> <span class="se">\
</span>       <span class="nt">--bash-completion</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--path-update</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--usage-reporting</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--quiet</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> gcloud <span class="nt">--version</span>

<span class="k">WORKDIR</span><span class="s"> $AIRFLOW_HOME</span>

<span class="k">COPY</span><span class="s"> scripts scripts</span>
<span class="k">RUN </span><span class="nb">chmod</span> +x scripts

<span class="k">USER</span><span class="s"> $AIRFLOW_UID</span>
</code></pre></div></div>

<p>(5) 아래 내용을 지닌 <code class="language-plaintext highlighter-rouge">requirements.txt</code> 파일을 생성했어요.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apache-airflow-providers-google
pyarrow
</code></pre></div></div>

<p>(6) <code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> 파일에서 다음 항목들을 추가/편집했어요.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">/keys</code>: 구글 클라우드 서비스 계정 json key 파일을 보관하는 용도</li>
  <li><code class="language-plaintext highlighter-rouge">.env</code>: Airflow Admin 로그인 정보와 슬랙 API 토큰을 보관하는 용도</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">x-airflow-common</span><span class="pi">:</span>
  <span class="s">...</span>
  <span class="s">environment</span><span class="err">:</span>
    <span class="s">...</span>
    <span class="s">AIRFLOW__CORE__LOAD_EXAMPLES</span><span class="err">:</span> <span class="s1">'</span><span class="s">false'</span> <span class="c1"># 샘플 DAG가 생성되지 않도록 했어요.</span>
    <span class="s">...</span>
    <span class="s">GOOGLE_APPLICATION_CREDENTIALS</span><span class="err">:</span> <span class="s">/keys/airflow_credentials.json</span> <span class="c1"># 구글 클라우드 서비스 계정 json key 파일의 경로를 입력했어요.</span>
    <span class="na">AIRFLOW_CONN_GOOGLE_CLOUD_DEFAULT</span><span class="pi">:</span> <span class="s1">'</span><span class="s">google-cloud-platform://?extra__google_cloud_platform__key_path=/keys/airflow_credentials.json'</span> <span class="c1"># 여기도 마찬가지에요.</span>
    <span class="na">GCP_PROJECT_ID</span><span class="pi">:</span> <span class="s1">'</span><span class="s">gcp_project_id'</span> <span class="c1"># 구글 클라우드 프로젝트 ID를 입력했어요.</span>
    <span class="na">AIRFLOW_CONN_SLACK_DEFAULT</span><span class="pi">:</span> <span class="s1">'</span><span class="s">slack://:${SLACK_TOKEN}@'</span> <span class="c1"># 슬랙 API 토큰은 .env 파일에서 관리했어요.</span>
    <span class="s">...</span>
  <span class="na">volumes</span><span class="pi">:</span>
    <span class="s">...</span>
    <span class="s">- ./keys:/keys:ro</span> <span class="c1"># 구글 클라우드 서비스 계정 json key 파일이 담긴 /keys 디렉토리를 Docker 상에 매핑해줬어요.</span>
<span class="nn">...</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="s">...</span>
  <span class="s">airflow-init</span><span class="err">:</span>
    <span class="s">...</span>
    <span class="s">environment</span><span class="err">:</span>
      <span class="s">...</span>
      <span class="s">_AIRFLOW_WWW_USER_USERNAME</span><span class="err">:</span> <span class="s">${_AIRFLOW_WWW_USER_USERNAME}</span> <span class="c1"># Airflow Webserver 로그인 정보는 .env 파일에서 관리했어요.</span>
      <span class="na">_AIRFLOW_WWW_USER_PASSWORD</span><span class="pi">:</span> <span class="s">${_AIRFLOW_WWW_USER_PASSWORD}</span> <span class="c1"># Airflow Webserver 로그인 정보는 .env 파일에서 관리했어요.</span>
      <span class="s">...</span>
</code></pre></div></div>

<p>(7) Docker Compose를 빌드하고, Initialize Airflow 했어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose build
docker-compose up airflow-init
</code></pre></div></div>

<p>(8) 마지막으로 Docker Compose를 실행했어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose up <span class="nt">-d</span>
docker-compose ps
</code></pre></div></div>

<p>(9) 브라우저에서 Airflow Webserver에 접속하여 로그인했어요.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) http://0.0.0.0:8080 로 접속해요.
2) docker-compose.yaml에서 설정했던 아래의 환경 변수로 로그인하면 돼요.
  - _AIRFLOW_WWW_USER_USERNAME
  - _AIRFLOW_WWW_USER_PASSWORD
</code></pre></div></div>

<p><img src="/assets/2024-12-28-implementing-airflow/4.webp" alt="" /></p>

<p>(10) <code class="language-plaintext highlighter-rouge">airflow</code> 디렉토리에 Initialize Git을 한 후, GitHub Remote Repo에 연동했어요. (물론, 연동하면 안되는 파일들은 <code class="language-plaintext highlighter-rouge">.gitignore</code>에 리스트업했어요.)</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git init
git remote add origin https://github.com/.../airflow.git
git branch <span class="nt">-m</span> main
git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s2">"created airflow project"</span>
git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<h3 id="23-vm-instance-환경-세팅">2.3. VM Instance 환경 세팅</h3>

<p>(1) 방화벽 규칙을 생성했어요. (VM Instance에서 운영 중인 Airflow Webserver에 사내 로컬에서도 접속할 수 있도록 해야 하거든요.)</p>

<p><img src="/assets/2024-12-28-implementing-airflow/5.webp" alt="" /></p>

<ul>
  <li><strong>방향</strong>: Ingress</li>
  <li><strong>대상 태그</strong>: airflow (원하는 이름으로 적으셔도 돼요.)</li>
  <li><strong>소스 필터 &gt; IP 범위</strong>: 사내 IP Address Range를 입력했어요.</li>
  <li><strong>프로토콜 및 포트</strong>: tcp-8080 (Webserver는 8080 포트를 통해 Host Machine과 소통하기 때문이에요. <code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> 파일에서 포트를 수정할 수도 있어요.)</li>
</ul>

<p>(2) <code class="language-plaintext highlighter-rouge">airflow</code> 이름의 VM Instance를 만들었어요.</p>

<p><img src="/assets/2024-12-28-implementing-airflow/6.webp" alt="" /></p>

<ul>
  <li><strong>Machine</strong>: E2 시리즈 중 vCPU 2개 이상, 메모리 8GB 이상을 추천해요. (메모리 4GB를 선택하면 서버가 네트워크 트래픽을 견디지 못해 쉽게 먹통이 될 거예요.)</li>
  <li><strong>OS &amp; Storage</strong>: OS는 Debian, 스토리지 사이즈는 10GB를 선택했어요.</li>
  <li><strong>방화벽</strong>: HTTP &amp; HTTPS 트래픽을 “사용”으로 설정한 후, 방화벽 규칙에서 생성했던 태그인 <code class="language-plaintext highlighter-rouge">airflow</code>를 입력했어요.</li>
</ul>

<p>(3) 로컬 환경에서 세팅한 것과 마찬가지로 Docker를 설치하고, Python Venv를 생성했어요.</p>

<ul>
  <li>2.2. 로컬 환경 세팅의 (0), (1)을 참고해주세요.</li>
</ul>

<p>(4) <code class="language-plaintext highlighter-rouge">airflow</code> 디렉토리를 만들고 Remote Repo를 Clone한 후, <code class="language-plaintext highlighter-rouge">/keys</code>, <code class="language-plaintext highlighter-rouge">.env</code> 파일은 직접 작성해줬어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/.../airflow.git
</code></pre></div></div>

<p>(5) 로컬 환경에서 세팅한 것과 마찬가지로 Docker Compose를 빌드한 후 실행했어요.</p>

<ul>
  <li>2.2. 로컬 환경 세팅의 (7), (8)을 참고해주세요.</li>
</ul>

<p>(6) 로컬 환경에서 VM Instance Airflow Webserver에 접속하여 로그인했어요.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) http://{VM Instance의 외부 IP 주소}:8080 로 접속해요.
2) docker-compose.yaml에서 설정했던 아래의 환경 변수로 로그인하면 돼요.
  - _AIRFLOW_WWW_USER_USERNAME
  - _AIRFLOW_WWW_USER_PASSWORD
</code></pre></div></div>

<h3 id="24-dag-만들기">2.4. DAG 만들기</h3>

<p>제가 작성한 DAG 중 가장 간단한 것은 “<strong>매일 빅쿼리 사용량 알림</strong>”입니다. 구글 클라우드를 관리하고 있는 저의 안심(?)을 도모하기 위한 셀프 알림 목적을 지니고 있는데요. <code class="language-plaintext highlighter-rouge">DAG.py</code> 코드를 단계를 나누어 서술해드릴게요.</p>

<p>(1) 필요한 라이브러리 및 오퍼레이터를 불러왔어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# 라이브러리 및 환경변수 불러오기
# ========================================================================
</span>
<span class="kn">from</span> <span class="n">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="n">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="n">airflow.providers.slack.operators.slack</span> <span class="kn">import</span> <span class="n">SlackAPIPostOperator</span>
<span class="kn">from</span> <span class="n">airflow.models</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="kn">from</span> <span class="n">google.cloud</span> <span class="kn">import</span> <span class="n">bigquery</span>

<span class="kn">from</span> <span class="n">pendulum</span> <span class="kn">import</span> <span class="n">timezone</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
</code></pre></div></div>

<ul>
  <li>BigQuery 관련 오퍼레이터를 사용하지 않고, <code class="language-plaintext highlighter-rouge">google.cloud.bigquery</code>와 <code class="language-plaintext highlighter-rouge">PythonOperator</code>를 사용했어요. Create, Insert, Update 작업이 아닌, Select 작업의 경우 응답 받아야 하는 데이터가 많으므로 Xcom을 활용하기에는 부적절하다고 판단했기 때문이에요.</li>
</ul>

<p>(2) 중요한 변수들과 클라이언트를 정의했어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# 클라이언트 및 중요한 변수 정의
# ========================================================================
</span>
<span class="n">bigquery_client</span> <span class="o">=</span> <span class="n">bigquery</span><span class="p">.</span><span class="nc">Client</span><span class="p">()</span>
<span class="n">kst</span> <span class="o">=</span> <span class="nf">timezone</span><span class="p">(</span><span class="sh">'</span><span class="s">Asia/Seoul</span><span class="sh">'</span><span class="p">)</span>

<span class="n">SLACK_CHANNEL_TEST</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">slack-channel-test</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SLACK_CHANNEL</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">slack-channel-prod</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">default_var</span><span class="o">=</span><span class="n">SLACK_CHANNEL_TEST</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><strong>kst</strong>: Airflow의 시간대를 한국 기준으로 명시하기 위해 <code class="language-plaintext highlighter-rouge">pendulum.timezone</code>을 사용했어요. (Airflow는 기본적으로 UTC 기준의 시간대를 바라보고 있는데, 작업시 상당히 혼동스러울 수 있거든요.)</li>
  <li><strong>슬랙 채널</strong>: 본 DAG는 최종적으로 슬랙 채널에 알림을 전송하는 Task로 끝나요. 따라서, “<strong>테스트 목적으로 만든 슬랙 채널</strong>”에 기본적으로 DAG를 실행한 후 문제가 없다면 비로소 타겟 슬랙 채널에 배포하는 것이 알림을 받아보는 동료들에게 좋은 인상을 줄 수 있을 거예요. 다음과 같이, Airflow Webserver 상에서 Variable을 추가해서 관리했어요.</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/7.webp" alt="" /></p>
<blockquote>
  <p><a href="https://airflow.apache.org/docs/apache-airflow/stable/howto/variable.html">Apache Airflow Docs</a></p>
</blockquote>

<p>(3) DAG의 기본 Arguments를 Dictionary로 정의해줬어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# DAG Default Arguments 정의
# ========================================================================
</span>
<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">owner</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">김진석의 이메일 주소</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">:</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tzinfo</span><span class="o">=</span><span class="n">kst</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">depends_on_past</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="bp">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>(4) 쿼리문을 동적으로 실행할 수 있도록 함수화했어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# 쿼리문 정의
# ========================================================================
</span>
<span class="bp">...</span>

<span class="c1"># 총 사용량 (사용자별)
</span><span class="k">def</span> <span class="nf">query_usage_by_user</span><span class="p">(</span><span class="n">date</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT
            user_email AS user,
            SUM(total_bytes_billed) / POW(2, 30) AS gibibyte
        FROM
            `</span><span class="si">{</span><span class="n">project_id</span><span class="si">}</span><span class="s">.</span><span class="si">{</span><span class="n">region</span><span class="si">}</span><span class="s">.INFORMATION_SCHEMA.JOBS`
        WHERE
            DATE(TIMESTAMP(creation_time), </span><span class="sh">"</span><span class="s">Asia/Seoul</span><span class="sh">"</span><span class="s">) = </span><span class="sh">'</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="sh">'</span><span class="s">
            AND job_type = </span><span class="sh">'</span><span class="s">QUERY</span><span class="sh">'</span><span class="s">
        GROUP BY
            1
        ORDER BY
            2 DESC
    </span><span class="sh">"""</span>

<span class="bp">...</span>
</code></pre></div></div>

<p>(5) Task들을 실행할 주요 함수들을 작성했어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# 함수 정의
# ========================================================================
</span>
<span class="c1"># BigQuery 데이터 추출
</span><span class="k">def</span> <span class="nf">fetch_bigquery_data</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="c1"># 어제 날짜 구하기
</span>    <span class="n">today_kst</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">execution_date</span><span class="sh">'</span><span class="p">].</span><span class="nf">in_timezone</span><span class="p">(</span><span class="n">kst</span><span class="p">)</span>
    <span class="n">yesterday_kst</span> <span class="o">=</span> <span class="n">today_kst</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">to_date_string</span><span class="p">()</span>

    <span class="bp">...</span>

    <span class="c1"># 어제 총 사용량 (사용자별)
</span>    <span class="n">usage_by_user_df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="nf">query_usage_by_user</span><span class="p">(</span><span class="n">yesterday_kst</span><span class="p">)).</span><span class="nf">to_dataframe</span><span class="p">()</span>
    <span class="n">usage_by_user_dict</span> <span class="o">=</span> <span class="n">usage_by_user_df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">user</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">gibibyte</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_dict</span><span class="p">()</span>

    <span class="c1"># XComm으로 데이터 전달
</span>    <span class="bp">...</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">ti</span><span class="sh">'</span><span class="p">].</span><span class="nf">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="sh">'</span><span class="s">usage_by_user_dict</span><span class="sh">'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">usage_by_user_dict</span><span class="p">)</span>
    <span class="bp">...</span>

<span class="c1"># Slack 메시지 작성
</span><span class="k">def</span> <span class="nf">write_slack_message</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="c1"># BigQuery 결과 읽어오기
</span>    <span class="bp">...</span>
    <span class="n">usage_by_user_dict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">ti</span><span class="sh">'</span><span class="p">].</span><span class="nf">xcom_pull</span><span class="p">(</span><span class="n">task_ids</span><span class="o">=</span><span class="sh">'</span><span class="s">fetch_bigquery_data</span><span class="sh">'</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="sh">'</span><span class="s">usage_by_user_dict</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># 메시지 만들기
</span>    <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">:bigquery: *전일 BigQuery 사용량 요약* (한국시각 기준)</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>
    <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">*:busts_in_silhouette: 사용자별*</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>
    <span class="k">for</span> <span class="n">user</span><span class="p">,</span> <span class="n">usage</span> <span class="ow">in</span> <span class="n">usage_by_user_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">   - *</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s">*: `</span><span class="si">{</span><span class="nf">float</span><span class="p">(</span><span class="n">usage</span><span class="p">)</span><span class="si">:</span><span class="p">,.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">`GiB</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>

    <span class="k">return</span> <span class="n">message</span>
</code></pre></div></div>

<p>(6) 마지막으로 DAG를 정의했어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# DAG 정의
# ========================================================================
</span>
<span class="k">with</span> <span class="nc">DAG</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">DAG.py 파일 이름과 동일하게 작성</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
    <span class="n">description</span> <span class="o">=</span> <span class="sh">'</span><span class="s">BigQuery 사용량 알림</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">schedule_interval</span> <span class="o">=</span> <span class="sh">'</span><span class="s">5 0 * * *</span><span class="sh">'</span><span class="p">,</span> <span class="c1"># 매일 00:05 AM KST
</span>    <span class="n">catchup</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
    
    <span class="c1"># BigQuery 데이터 추출
</span>    <span class="n">task_fetch_bigquery_data</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">fetch_bigquery_data</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">python_callable</span> <span class="o">=</span> <span class="n">fetch_bigquery_data</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Slack 메시지 작성
</span>    <span class="n">task_write_slack_message</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">write_slack_message</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">python_callable</span> <span class="o">=</span> <span class="n">write_slack_message</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Slack 메시지 전송
</span>    <span class="n">task_send_slack_message</span> <span class="o">=</span> <span class="nc">SlackAPIPostOperator</span><span class="p">(</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">send_slack_message</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">text</span> <span class="o">=</span> <span class="sh">''</span><span class="p">,</span>
        <span class="n">slack_conn_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">slack_default</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">channel</span> <span class="o">=</span> <span class="n">SLACK_CHANNEL</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Task 간의 실행 순서 정의
</span>    <span class="n">task_fetch_bigquery_data</span> <span class="o">&gt;&gt;</span> <span class="n">task_write_slack_message</span> <span class="o">&gt;&gt;</span> <span class="n">task_send_slack_message</span>
</code></pre></div></div>

<ul>
  <li>이 DAG는 다음과 같은 흐름으로 각 Task들을 실행해요.</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/8.webp" alt="" /></p>

<ul>
  <li>다음과 같은 슬랙 메시지가 전송되었어요.</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/9.webp" alt="" /></p>

<hr />

<h1 id="3-앞으로의-과제">3. 앞으로의 과제</h1>

<p>사실, Linux나 Docker 환경에 익숙하지 않은 사람들에게 Airflow는 러닝 커브가 상당히 가파른 편이에요. 여러 가지 Orchestration 관리 도구 중 Airflow가 가장 자유도가 높은 만큼 어렵기 때문인데요. 하지만 Python에 상당히 익숙한 데이터 분석가, 애널리틱스 엔지니어, 그리고 백엔드 개발자라면 서로 커뮤니케이션을 하는 데 상당히 도움이 될 거예요.</p>

<p>사내에 본격적으로 Airflow를 도입한 후, 다음과 같은 “<strong>응용 버전</strong>”의 고민들이 추가로 생겼어요. 꼭 풀어가고 싶은 것들입니다.</p>

<ul>
  <li>외부 데이터 수집을 위한 파이프라인을 설계한 후, 정제된 데이터를 이해관계자 동료들에게 이메일이나 슬랙 DM으로 전송하기</li>
  <li>dbt의 각 테이블 의존성이나 최신화 주기 차이에 따라 배치 실행을 분리한 후 Airflow DAG로 관리하기</li>
  <li>이 외에도 여러 가지 고민들</li>
</ul>

<p>Airflow를 통해 유지보수 부담을 줄이고, 워크플로우의 안정성을 제고함으로써 개인적인 업무 효율화를 극대화할 수 있을 것으로 기대하고 있어요. 늘어난 가용 시간만큼 더욱 중요한 일에 몰입하여 동료들이 데이터를 더욱 잘 활용할 수 있는 환경을 만들 수 있기를 바라요. 개인적인 학습 뿐만 아니라, 기업의 성장과 고객의 만족을 위한 방향일테니까요.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>

<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>

  </div>

  <div class="pagination">
    
      <span class="prev" >
          <a href="http://localhost:4000/implementing-airflow-en/">
            &#xE000; Review of Implementing Airflow
          </a>
      </span>
    
    
  </div>

  <script type="text/javascript"
  src="https://unpkg.com/mermaid@10.6.1/dist/mermaid.min.js">
</script>
<script>
$(document).ready(function() {
    mermaid.initialize({
        theme: 'forest'
    });
});
</script>
  
</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          <!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  

  

  

  

  

  
  <li><a href="https://github.com/joshua-data" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
  

  

  

  
  <li><a href="https://www.linkedin.com/in/joshuajsk" class="icon-17 linkedin" title="LinkedIn"><svg viewBox="0 0 512 512"><path d="M186.4 142.4c0 19-15.3 34.5-34.2 34.5 -18.9 0-34.2-15.4-34.2-34.5 0-19 15.3-34.5 34.2-34.5C171.1 107.9 186.4 123.4 186.4 142.4zM181.4 201.3h-57.8V388.1h57.8V201.3zM273.8 201.3h-55.4V388.1h55.4c0 0 0-69.3 0-98 0-26.3 12.1-41.9 35.2-41.9 21.3 0 31.5 15 31.5 41.9 0 26.9 0 98 0 98h57.5c0 0 0-68.2 0-118.3 0-50-28.3-74.2-68-74.2 -39.6 0-56.3 30.9-56.3 30.9v-25.2H273.8z"/></svg><!--[if lt IE 9]><em>LinkedIn</em><![endif]--></a></li>
  

  

  
  <li><a href="/feed.xml" class="icon-21 rss" title="RSS"><svg viewBox="0 0 512 512"><path d="M201.8 347.2c0 20.3-16.5 36.8-36.8 36.8 -20.3 0-36.8-16.5-36.8-36.8s16.5-36.8 36.8-36.8C185.3 310.4 201.8 326.8 201.8 347.2zM128.2 204.7v54.5c68.5 0.7 124 56.3 124.7 124.7h54.5C306.7 285.3 226.9 205.4 128.2 204.7zM128.2 166.6c57.9 0.3 112.3 22.9 153.2 63.9 41 41 63.7 95.5 63.9 153.5h54.5c-0.3-149.9-121.7-271.4-271.6-271.9V166.6L128.2 166.6z"/></svg><!--[if lt IE 9]><em>RSS</em><![endif]--></a></li>
  

  

  

  

  

</ul>



<div class="footer-wrapper">
    <p>Joshua Kim</p>
    <a href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fjoshua-data.github.io&count_bg=%2379C83D&title_bg=%23555555&icon=ghostery.svg&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a>
</div>

        </footer>
      </div>
    </div>

    

  </body>
</html>
