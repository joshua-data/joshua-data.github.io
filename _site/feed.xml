<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-01-30T04:45:20+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Joshua Kim</title><subtitle>Analytics Engineer | Data Analyst</subtitle><entry><title type="html">Airflow 도입 후기</title><link href="http://localhost:4000/implementing-airflow-ko/" rel="alternate" type="text/html" title="Airflow 도입 후기" /><published>2024-12-28T00:00:00+09:00</published><updated>2024-12-28T00:00:00+09:00</updated><id>http://localhost:4000/implementing-airflow-ko</id><content type="html" xml:base="http://localhost:4000/implementing-airflow-ko/"><![CDATA[<blockquote>
  <p>“Airflow 도입을 통해 사내 데이터 알림 시스템을 효율적으로 관리하고자 기존 Python 기반 세션 방식에서 벗어나 DAG 기반 워크플로우를 구축했습니다. Docker Compose를 활용해 로컬 및 VM 환경에서 Airflow를 설정하고, Slack 알림을 포함한 다양한 데이터 파이프라인을 자동화했습니다. 이를 통해 유지보수 부담을 줄이고, 안정성을 높이며, 확장 가능한 데이터 처리 환경을 마련할 수 있었습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>도입 배경</li>
  <li>도입 후기
    <ul>
      <li>2.1. 작업 계획</li>
      <li>2.2. 로컬 환경 세팅</li>
      <li>2.3. VM Instance 환경 세팅</li>
      <li>2.4. DAG 만들기</li>
    </ul>
  </li>
  <li>앞으로의 과제</li>
</ol>

<hr />

<h1 id="1-도입-배경">1. 도입 배경</h1>

<p>저는 아이오트러스트에서 데이터 엔지니어 포지션으로 근무하며, 아래와 같이 주로 <strong>애널리틱스 엔지니어링</strong> 업무에 집중하고 있어요.</p>

<pre><code class="language-plain">- (1) 데이터 웨어하우스 &amp; 데이터 마트 설계 및 개발
- (2) BI 대시보드
- (3) Ad-hoc 데이터 알림 봇 개발
- (4) 이벤트 택소노미 설계 + 정의서 관리
- (5) (Finance/HR/CX) 업무 자동화 환경 구축
</code></pre>

<p>그런데, 시간이 흐를수록 “<strong>(3) Ad-hoc 데이터 알림 봇 개발</strong>” 역할에 문제가 발생하기 시작했어요. 동료들이 적시에 중요한 핵심 지표를 슬랙으로 빠르게 확인할 수 있도록 지원하는 과정에서, 서서히 Python 파일이 많아졌고 관리 리소스도 제법 늘어나게 된 것이죠.</p>

<p><img src="/assets/2024-12-28-implementing-airflow/1.webp" alt="" /></p>

<p>구체적으로는, 아래와 같이 <code class="language-plaintext highlighter-rouge">tmux</code>를 통해 세션 레벨에서 각 Python 파일을 직접 실행하여 모든 슬랙 알림을 관리하고 있었어요. <code class="language-plaintext highlighter-rouge">tmux</code>는 단일 터미널에서 여러 세션을 독립적으로 관리할 수 있도록 해주는 오픈소스 터미널 자동화 도구예요. (<a href="https://en.wikipedia.org/wiki/Tmux">Wikipedia</a>)</p>

<p><img src="/assets/2024-12-28-implementing-airflow/2.webp" alt="" /></p>

<p>점차 Python 파일이 많아지고 복잡해지면서 구체적으로 다음과 같은 문제가 발생하기 시작했어요.</p>

<p><strong>(1) 유지보수 부담이 늘어났어요.</strong></p>

<p>Python 파일의 오류가 발생하면 실행이 즉시 중단되어 디버깅이 완료되기 전까지는 동료들이 알림을 받을 수 없었어요. 작업 재시도 기능이 없었기 때문이죠.</p>

<p>또한, 디버깅 과정에서 제법 많은 시간을 허비했어요. 의존성이 있는 각 파이프라인 단계를 main() 함수 하나로 관리하다 보니, 정확한 실패 원인을 찾는 데 상당한 시간이 소요되었던 것이죠. 그러다보니 중요한 일에 몰입하지 못하고 업무가 산만해지기 쉬웠죠.</p>

<p><strong>(2) 세션 기반 관리의 안정성이 부족했어요.</strong></p>

<p>서버 재부팅이나 네트워크 문제로 인해 작업이 중단될 여지가 높았고, 실제로 알 수 없는 이유로 세션이 모두 종료되어 복구 작업을 해야 했던 적도 있었어요.</p>

<p>또한, 각 세션이 동일한 환경을 공유하기 때문에 <a href="https://docs.python.org/3/library/venv.html">Python Venv</a>를 사용하더라도 의도치 않은 충돌이나 종속성 문제가 발생할 여지가 있었어요.</p>

<p><strong>이런 이유로 Airflow를 통한 워크플로우 관리 필요성이 점차 커지게 되었어요.</strong></p>

<ul>
  <li>컨테이너만 재시작하면 각 작업을 자동으로 복구할 수 있어요.</li>
  <li>각 작업별로 독립된 환경을 제공해요.</li>
  <li>지속적으로 작업을 확장할 수 있어요.</li>
  <li>웹서버 UI를 통해 관리를 용이하게 할 수 있어요.</li>
</ul>

<p>사실, “<strong>Ad-hoc 데이터 알림 봇 개발</strong>” 업무 초기에 이미 Airflow 도입을 적극적으로 검토했었습니다. 하지만 당시 워크플로우의 규모가 매우 작았기 때문에, <strong>YAGNI</strong> 원칙에 따라 굳이 도입할 필요가 없다고 판단했죠.</p>

<p><a href="https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it">YAGNI</a>는 “<strong>You Aren’t Gonna Need It</strong>”의 준말로, 필요하지 않은 기능이나 복잡성을 미리 추가하지 말라는 애자일 소프트웨어 개발의 핵심 원칙 중 하나입니다. 당시에는 현재 요구 사항을 충족하는 적절한 수준에서만 워크플로우 환경을 구축하는 것이 중요하다고 생각해, 세션 기반 관리 방식을 선택했어요.</p>

<p>그러나 워크플로우 규모가 점차 커지면서 세션 관리 방식에서 발생하는 리소스 낭비와 비효율성이 눈에 띄게 늘어났어요. 이에 따라, Airflow 도입이 필요하다고 판단하게 되었습니다.</p>

<hr />

<h1 id="2-도입-후기">2. 도입 후기</h1>

<h3 id="21-작업-계획">2.1. 작업 계획</h3>

<p><img src="/assets/2024-12-28-implementing-airflow/3.webp" alt="" /></p>

<p>먼저 위 그림과 같이 계획을 세웠어요.</p>

<p>(1) 기존 Python 파일들을 <strong>DAG 포맷</strong>에 맞게 코드를 수정합니다.</p>

<p>(2) <strong>로컬 환경</strong>에서 Airflow 프로젝트를 Docker Compose로 빌드하여, 알림이 슬랙 테스트 채널에 제대로 전송되는지 확인합니다.</p>

<p>(3) <strong>VM Instance 환경</strong>에서도 Airflow 프로젝트를 Docker Compose로 빌드하여, 최종적으로 알림 환경을 배포합니다.</p>

<h3 id="22-로컬-환경-세팅">2.2. 로컬 환경 세팅</h3>

<p>(0) 기본적으로 Docker가 설치되어 있어야 해요.</p>

<ul>
  <li>저는 Docker Desktop 앱을 설치하는 방향으로 준비했어요. 정확한 설치 방법은 <a href="https://www.docker.com/get-started/">이 문서</a>를 참고해주세요.</li>
</ul>

<p>(1) Python Venv를 생성했어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> venv venv
<span class="nb">source </span>venv/bin/activate
</code></pre></div></div>

<p>(2) <code class="language-plaintext highlighter-rouge">airflow</code> 이름의 디렉토리에서 아래 명령어를 통해 Airflow 이미지를 로드했어요. (<code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> 파일이 생성될 거예요.)</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-LfO</span> <span class="s1">'https://airflow.apache.org/docs/apache-airflow/2.9.1/docker-compose.yaml'</span>
</code></pre></div></div>

<p>(3) <code class="language-plaintext highlighter-rouge">dags</code>, <code class="language-plaintext highlighter-rouge">logs</code>, <code class="language-plaintext highlighter-rouge">plugins</code> 하위 디렉토리를 생성하고, <strong>AIRFLOW_UID</strong> 환경 변수를 지닌 <code class="language-plaintext highlighter-rouge">.env</code> 파일을 생성했어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> ./dags ./logs ./plugins
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"AIRFLOW_UID=</span><span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span><span class="s2">"</span> <span class="o">&gt;</span> .env
</code></pre></div></div>

<p>(4) 아래 내용을 지닌 <code class="language-plaintext highlighter-rouge">Dockerfile</code> 파일을 생성했어요.</p>

<div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># First-time build can take upto 10 mins.</span>

<span class="k">FROM</span><span class="s"> apache/airflow:2.9.1</span>

<span class="k">ENV</span><span class="s"> AIRFLOW_HOME=/opt/airflow</span>

<span class="k">USER</span><span class="s"> root</span>
<span class="k">RUN </span>apt-get update <span class="nt">-qq</span> <span class="o">&amp;&amp;</span> apt-get <span class="nb">install </span>vim <span class="nt">-qqq</span>
<span class="c"># git gcc g++ -qqq</span>

<span class="k">COPY</span><span class="s"> requirements.txt .</span>
<span class="k">RUN </span>pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Ref: https://airflow.apache.org/docs/docker-stack/recipes.html</span>

<span class="k">SHELL</span><span class="s"> ["/bin/bash", "-o", "pipefail", "-e", "-u", "-x", "-c"]</span>

<span class="k">ARG</span><span class="s"> CLOUD_SDK_VERSION=322.0.0</span>
<span class="k">ENV</span><span class="s"> GCLOUD_HOME=/home/google-cloud-sdk</span>

<span class="k">ENV</span><span class="s"> PATH="${GCLOUD_HOME}/bin/:${PATH}"</span>

<span class="k">RUN </span><span class="nv">DOWNLOAD_URL</span><span class="o">=</span><span class="s2">"https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-</span><span class="k">${</span><span class="nv">CLOUD_SDK_VERSION</span><span class="k">}</span><span class="s2">-linux-x86_64.tar.gz"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nv">TMP_DIR</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span><span class="nb">mktemp</span> <span class="nt">-d</span><span class="si">)</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> curl <span class="nt">-fL</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DOWNLOAD_URL</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--output</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/google-cloud-sdk.tar.gz"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">tar </span>xzf <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/google-cloud-sdk.tar.gz"</span> <span class="nt">-C</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--strip-components</span><span class="o">=</span>1 <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">/install.sh"</span> <span class="se">\
</span>       <span class="nt">--bash-completion</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--path-update</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--usage-reporting</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--quiet</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> gcloud <span class="nt">--version</span>

<span class="k">WORKDIR</span><span class="s"> $AIRFLOW_HOME</span>

<span class="k">COPY</span><span class="s"> scripts scripts</span>
<span class="k">RUN </span><span class="nb">chmod</span> +x scripts

<span class="k">USER</span><span class="s"> $AIRFLOW_UID</span>
</code></pre></div></div>

<p>(5) 아래 내용을 지닌 <code class="language-plaintext highlighter-rouge">requirements.txt</code> 파일을 생성했어요.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apache-airflow-providers-google
pyarrow
</code></pre></div></div>

<p>(6) <code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> 파일에서 다음 항목들을 추가/편집했어요.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">/keys</code>: 구글 클라우드 서비스 계정 json key 파일을 보관하는 용도</li>
  <li><code class="language-plaintext highlighter-rouge">.env</code>: Airflow Admin 로그인 정보와 슬랙 API 토큰을 보관하는 용도</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">x-airflow-common</span><span class="pi">:</span>
  <span class="s">...</span>
  <span class="s">environment</span><span class="err">:</span>
    <span class="s">...</span>
    <span class="s">AIRFLOW__CORE__LOAD_EXAMPLES</span><span class="err">:</span> <span class="s1">'</span><span class="s">false'</span> <span class="c1"># 샘플 DAG가 생성되지 않도록 했어요.</span>
    <span class="s">...</span>
    <span class="s">GOOGLE_APPLICATION_CREDENTIALS</span><span class="err">:</span> <span class="s">/keys/airflow_credentials.json</span> <span class="c1"># 구글 클라우드 서비스 계정 json key 파일의 경로를 입력했어요.</span>
    <span class="na">AIRFLOW_CONN_GOOGLE_CLOUD_DEFAULT</span><span class="pi">:</span> <span class="s1">'</span><span class="s">google-cloud-platform://?extra__google_cloud_platform__key_path=/keys/airflow_credentials.json'</span> <span class="c1"># 여기도 마찬가지에요.</span>
    <span class="na">GCP_PROJECT_ID</span><span class="pi">:</span> <span class="s1">'</span><span class="s">gcp_project_id'</span> <span class="c1"># 구글 클라우드 프로젝트 ID를 입력했어요.</span>
    <span class="na">AIRFLOW_CONN_SLACK_DEFAULT</span><span class="pi">:</span> <span class="s1">'</span><span class="s">slack://:${SLACK_TOKEN}@'</span> <span class="c1"># 슬랙 API 토큰은 .env 파일에서 관리했어요.</span>
    <span class="s">...</span>
  <span class="na">volumes</span><span class="pi">:</span>
    <span class="s">...</span>
    <span class="s">- ./keys:/keys:ro</span> <span class="c1"># 구글 클라우드 서비스 계정 json key 파일이 담긴 /keys 디렉토리를 Docker 상에 매핑해줬어요.</span>
<span class="nn">...</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="s">...</span>
  <span class="s">airflow-init</span><span class="err">:</span>
    <span class="s">...</span>
    <span class="s">environment</span><span class="err">:</span>
      <span class="s">...</span>
      <span class="s">_AIRFLOW_WWW_USER_USERNAME</span><span class="err">:</span> <span class="s">${_AIRFLOW_WWW_USER_USERNAME}</span> <span class="c1"># Airflow Webserver 로그인 정보는 .env 파일에서 관리했어요.</span>
      <span class="na">_AIRFLOW_WWW_USER_PASSWORD</span><span class="pi">:</span> <span class="s">${_AIRFLOW_WWW_USER_PASSWORD}</span> <span class="c1"># Airflow Webserver 로그인 정보는 .env 파일에서 관리했어요.</span>
      <span class="s">...</span>
</code></pre></div></div>

<p>(7) Docker Compose를 빌드하고, Initialize Airflow 했어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose build
docker-compose up airflow-init
</code></pre></div></div>

<p>(8) 마지막으로 Docker Compose를 실행했어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose up <span class="nt">-d</span>
docker-compose ps
</code></pre></div></div>

<p>(9) 브라우저에서 Airflow Webserver에 접속하여 로그인했어요.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) http://0.0.0.0:8080 로 접속해요.
2) docker-compose.yaml에서 설정했던 아래의 환경 변수로 로그인하면 돼요.
  - _AIRFLOW_WWW_USER_USERNAME
  - _AIRFLOW_WWW_USER_PASSWORD
</code></pre></div></div>

<p><img src="/assets/2024-12-28-implementing-airflow/4.webp" alt="" /></p>

<p>(10) <code class="language-plaintext highlighter-rouge">airflow</code> 디렉토리에 Initialize Git을 한 후, GitHub Remote Repo에 연동했어요. (물론, 연동하면 안되는 파일들은 <code class="language-plaintext highlighter-rouge">.gitignore</code>에 리스트업했어요.)</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git init
git remote add origin https://github.com/.../airflow.git
git branch <span class="nt">-m</span> main
git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s2">"created airflow project"</span>
git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<h3 id="23-vm-instance-환경-세팅">2.3. VM Instance 환경 세팅</h3>

<p>(1) 방화벽 규칙을 생성했어요. (VM Instance에서 운영 중인 Airflow Webserver에 사내 로컬에서도 접속할 수 있도록 해야 하거든요.)</p>

<p><img src="/assets/2024-12-28-implementing-airflow/5.webp" alt="" /></p>

<ul>
  <li><strong>방향</strong>: Ingress</li>
  <li><strong>대상 태그</strong>: airflow (원하는 이름으로 적으셔도 돼요.)</li>
  <li><strong>소스 필터 &gt; IP 범위</strong>: 사내 IP Address Range를 입력했어요.</li>
  <li><strong>프로토콜 및 포트</strong>: tcp-8080 (Webserver는 8080 포트를 통해 Host Machine과 소통하기 때문이에요. <code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> 파일에서 포트를 수정할 수도 있어요.)</li>
</ul>

<p>(2) <code class="language-plaintext highlighter-rouge">airflow</code> 이름의 VM Instance를 만들었어요.</p>

<p><img src="/assets/2024-12-28-implementing-airflow/6.webp" alt="" /></p>

<ul>
  <li><strong>Machine</strong>: E2 시리즈 중 vCPU 2개 이상, 메모리 8GB 이상을 추천해요. (메모리 4GB를 선택하면 서버가 네트워크 트래픽을 견디지 못해 쉽게 먹통이 될 거예요.)</li>
  <li><strong>OS &amp; Storage</strong>: OS는 Debian, 스토리지 사이즈는 10GB를 선택했어요.</li>
  <li><strong>방화벽</strong>: HTTP &amp; HTTPS 트래픽을 “사용”으로 설정한 후, 방화벽 규칙에서 생성했던 태그인 <code class="language-plaintext highlighter-rouge">airflow</code>를 입력했어요.</li>
</ul>

<p>(3) 로컬 환경에서 세팅한 것과 마찬가지로 Docker를 설치하고, Python Venv를 생성했어요.</p>

<ul>
  <li>2.2. 로컬 환경 세팅의 (0), (1)을 참고해주세요.</li>
</ul>

<p>(4) <code class="language-plaintext highlighter-rouge">airflow</code> 디렉토리를 만들고 Remote Repo를 Clone한 후, <code class="language-plaintext highlighter-rouge">/keys</code>, <code class="language-plaintext highlighter-rouge">.env</code> 파일은 직접 작성해줬어요.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/.../airflow.git
</code></pre></div></div>

<p>(5) 로컬 환경에서 세팅한 것과 마찬가지로 Docker Compose를 빌드한 후 실행했어요.</p>

<ul>
  <li>2.2. 로컬 환경 세팅의 (7), (8)을 참고해주세요.</li>
</ul>

<p>(6) 로컬 환경에서 VM Instance Airflow Webserver에 접속하여 로그인했어요.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) http://{VM Instance의 외부 IP 주소}:8080 로 접속해요.
2) docker-compose.yaml에서 설정했던 아래의 환경 변수로 로그인하면 돼요.
  - _AIRFLOW_WWW_USER_USERNAME
  - _AIRFLOW_WWW_USER_PASSWORD
</code></pre></div></div>

<h3 id="24-dag-만들기">2.4. DAG 만들기</h3>

<p>제가 작성한 DAG 중 가장 간단한 것은 “<strong>매일 빅쿼리 사용량 알림</strong>”입니다. 구글 클라우드를 관리하고 있는 저의 안심(?)을 도모하기 위한 셀프 알림 목적을 지니고 있는데요. <code class="language-plaintext highlighter-rouge">DAG.py</code> 코드를 단계를 나누어 서술해드릴게요.</p>

<p>(1) 필요한 라이브러리 및 오퍼레이터를 불러왔어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# 라이브러리 및 환경변수 불러오기
# ========================================================================
</span>
<span class="kn">from</span> <span class="n">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="n">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="n">airflow.providers.slack.operators.slack</span> <span class="kn">import</span> <span class="n">SlackAPIPostOperator</span>
<span class="kn">from</span> <span class="n">airflow.models</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="kn">from</span> <span class="n">google.cloud</span> <span class="kn">import</span> <span class="n">bigquery</span>

<span class="kn">from</span> <span class="n">pendulum</span> <span class="kn">import</span> <span class="n">timezone</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
</code></pre></div></div>

<ul>
  <li>BigQuery 관련 오퍼레이터를 사용하지 않고, <code class="language-plaintext highlighter-rouge">google.cloud.bigquery</code>와 <code class="language-plaintext highlighter-rouge">PythonOperator</code>를 사용했어요. Create, Insert, Update 작업이 아닌, Select 작업의 경우 응답 받아야 하는 데이터가 많으므로 Xcom을 활용하기에는 부적절하다고 판단했기 때문이에요.</li>
</ul>

<p>(2) 중요한 변수들과 클라이언트를 정의했어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# 클라이언트 및 중요한 변수 정의
# ========================================================================
</span>
<span class="n">bigquery_client</span> <span class="o">=</span> <span class="n">bigquery</span><span class="p">.</span><span class="nc">Client</span><span class="p">()</span>
<span class="n">kst</span> <span class="o">=</span> <span class="nf">timezone</span><span class="p">(</span><span class="sh">'</span><span class="s">Asia/Seoul</span><span class="sh">'</span><span class="p">)</span>

<span class="n">SLACK_CHANNEL_TEST</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">slack-channel-test</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SLACK_CHANNEL</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">slack-channel-prod</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">default_var</span><span class="o">=</span><span class="n">SLACK_CHANNEL_TEST</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><strong>kst</strong>: Airflow의 시간대를 한국 기준으로 명시하기 위해 <code class="language-plaintext highlighter-rouge">pendulum.timezone</code>을 사용했어요. (Airflow는 기본적으로 UTC 기준의 시간대를 바라보고 있는데, 작업시 상당히 혼동스러울 수 있거든요.)</li>
  <li><strong>슬랙 채널</strong>: 본 DAG는 최종적으로 슬랙 채널에 알림을 전송하는 Task로 끝나요. 따라서, “<strong>테스트 목적으로 만든 슬랙 채널</strong>”에 기본적으로 DAG를 실행한 후 문제가 없다면 비로소 타겟 슬랙 채널에 배포하는 것이 알림을 받아보는 동료들에게 좋은 인상을 줄 수 있을 거예요. 다음과 같이, Airflow Webserver 상에서 Variable을 추가해서 관리했어요.</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/7.webp" alt="" /></p>
<blockquote>
  <p><a href="https://airflow.apache.org/docs/apache-airflow/stable/howto/variable.html">Apache Airflow Docs</a></p>
</blockquote>

<p>(3) DAG의 기본 Arguments를 Dictionary로 정의해줬어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# DAG Default Arguments 정의
# ========================================================================
</span>
<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">owner</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">김진석의 이메일 주소</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">:</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tzinfo</span><span class="o">=</span><span class="n">kst</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">depends_on_past</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="bp">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>(4) 쿼리문을 동적으로 실행할 수 있도록 함수화했어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# 쿼리문 정의
# ========================================================================
</span>
<span class="bp">...</span>

<span class="c1"># 총 사용량 (사용자별)
</span><span class="k">def</span> <span class="nf">query_usage_by_user</span><span class="p">(</span><span class="n">date</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT
            user_email AS user,
            SUM(total_bytes_billed) / POW(2, 30) AS gibibyte
        FROM
            `</span><span class="si">{</span><span class="n">project_id</span><span class="si">}</span><span class="s">.</span><span class="si">{</span><span class="n">region</span><span class="si">}</span><span class="s">.INFORMATION_SCHEMA.JOBS`
        WHERE
            DATE(TIMESTAMP(creation_time), </span><span class="sh">"</span><span class="s">Asia/Seoul</span><span class="sh">"</span><span class="s">) = </span><span class="sh">'</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="sh">'</span><span class="s">
            AND job_type = </span><span class="sh">'</span><span class="s">QUERY</span><span class="sh">'</span><span class="s">
        GROUP BY
            1
        ORDER BY
            2 DESC
    </span><span class="sh">"""</span>

<span class="bp">...</span>
</code></pre></div></div>

<p>(5) Task들을 실행할 주요 함수들을 작성했어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# 함수 정의
# ========================================================================
</span>
<span class="c1"># BigQuery 데이터 추출
</span><span class="k">def</span> <span class="nf">fetch_bigquery_data</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="c1"># 어제 날짜 구하기
</span>    <span class="n">today_kst</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">execution_date</span><span class="sh">'</span><span class="p">].</span><span class="nf">in_timezone</span><span class="p">(</span><span class="n">kst</span><span class="p">)</span>
    <span class="n">yesterday_kst</span> <span class="o">=</span> <span class="n">today_kst</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">to_date_string</span><span class="p">()</span>

    <span class="bp">...</span>

    <span class="c1"># 어제 총 사용량 (사용자별)
</span>    <span class="n">usage_by_user_df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="nf">query_usage_by_user</span><span class="p">(</span><span class="n">yesterday_kst</span><span class="p">)).</span><span class="nf">to_dataframe</span><span class="p">()</span>
    <span class="n">usage_by_user_dict</span> <span class="o">=</span> <span class="n">usage_by_user_df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">user</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">gibibyte</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_dict</span><span class="p">()</span>

    <span class="c1"># XComm으로 데이터 전달
</span>    <span class="bp">...</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">ti</span><span class="sh">'</span><span class="p">].</span><span class="nf">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="sh">'</span><span class="s">usage_by_user_dict</span><span class="sh">'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">usage_by_user_dict</span><span class="p">)</span>
    <span class="bp">...</span>

<span class="c1"># Slack 메시지 작성
</span><span class="k">def</span> <span class="nf">write_slack_message</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="c1"># BigQuery 결과 읽어오기
</span>    <span class="bp">...</span>
    <span class="n">usage_by_user_dict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">ti</span><span class="sh">'</span><span class="p">].</span><span class="nf">xcom_pull</span><span class="p">(</span><span class="n">task_ids</span><span class="o">=</span><span class="sh">'</span><span class="s">fetch_bigquery_data</span><span class="sh">'</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="sh">'</span><span class="s">usage_by_user_dict</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># 메시지 만들기
</span>    <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">:bigquery: *전일 BigQuery 사용량 요약* (한국시각 기준)</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>
    <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">*:busts_in_silhouette: 사용자별*</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>
    <span class="k">for</span> <span class="n">user</span><span class="p">,</span> <span class="n">usage</span> <span class="ow">in</span> <span class="n">usage_by_user_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">   - *</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s">*: `</span><span class="si">{</span><span class="nf">float</span><span class="p">(</span><span class="n">usage</span><span class="p">)</span><span class="si">:</span><span class="p">,.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">`GiB</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>

    <span class="k">return</span> <span class="n">message</span>
</code></pre></div></div>

<p>(6) 마지막으로 DAG를 정의했어요.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# DAG 정의
# ========================================================================
</span>
<span class="k">with</span> <span class="nc">DAG</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">DAG.py 파일 이름과 동일하게 작성</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">default_args</span> <span class="o">=</span> <span class="n">default_args</span><span class="p">,</span>
    <span class="n">description</span> <span class="o">=</span> <span class="sh">'</span><span class="s">BigQuery 사용량 알림</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">schedule_interval</span> <span class="o">=</span> <span class="sh">'</span><span class="s">5 0 * * *</span><span class="sh">'</span><span class="p">,</span> <span class="c1"># 매일 00:05 AM KST
</span>    <span class="n">catchup</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
    
    <span class="c1"># BigQuery 데이터 추출
</span>    <span class="n">task_fetch_bigquery_data</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">fetch_bigquery_data</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">python_callable</span> <span class="o">=</span> <span class="n">fetch_bigquery_data</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Slack 메시지 작성
</span>    <span class="n">task_write_slack_message</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">write_slack_message</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">python_callable</span> <span class="o">=</span> <span class="n">write_slack_message</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Slack 메시지 전송
</span>    <span class="n">task_send_slack_message</span> <span class="o">=</span> <span class="nc">SlackAPIPostOperator</span><span class="p">(</span>
        <span class="n">task_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">send_slack_message</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">text</span> <span class="o">=</span> <span class="sh">''</span><span class="p">,</span>
        <span class="n">slack_conn_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">slack_default</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">channel</span> <span class="o">=</span> <span class="n">SLACK_CHANNEL</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Task 간의 실행 순서 정의
</span>    <span class="n">task_fetch_bigquery_data</span> <span class="o">&gt;&gt;</span> <span class="n">task_write_slack_message</span> <span class="o">&gt;&gt;</span> <span class="n">task_send_slack_message</span>
</code></pre></div></div>

<ul>
  <li>이 DAG는 다음과 같은 흐름으로 각 Task들을 실행해요.</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/8.webp" alt="" /></p>

<ul>
  <li>다음과 같은 슬랙 메시지가 전송되었어요.</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/9.webp" alt="" /></p>

<hr />

<h1 id="3-앞으로의-과제">3. 앞으로의 과제</h1>

<p>사실, Linux나 Docker 환경에 익숙하지 않은 사람들에게 Airflow는 러닝 커브가 상당히 가파른 편이에요. 여러 가지 Orchestration 관리 도구 중 Airflow가 가장 자유도가 높은 만큼 어렵기 때문인데요. 하지만 Python에 상당히 익숙한 데이터 분석가, 애널리틱스 엔지니어, 그리고 백엔드 개발자라면 서로 커뮤니케이션을 하는 데 상당히 도움이 될 거예요.</p>

<p>사내에 본격적으로 Airflow를 도입한 후, 다음과 같은 “<strong>응용 버전</strong>”의 고민들이 추가로 생겼어요. 꼭 풀어가고 싶은 것들입니다.</p>

<ul>
  <li>외부 데이터 수집을 위한 파이프라인을 설계한 후, 정제된 데이터를 이해관계자 동료들에게 이메일이나 슬랙 DM으로 전송하기</li>
  <li>dbt의 각 테이블 의존성이나 최신화 주기 차이에 따라 배치 실행을 분리한 후 Airflow DAG로 관리하기</li>
  <li>이 외에도 여러 가지 고민들</li>
</ul>

<p>Airflow를 통해 유지보수 부담을 줄이고, 워크플로우의 안정성을 제고함으로써 개인적인 업무 효율화를 극대화할 수 있을 것으로 기대하고 있어요. 늘어난 가용 시간만큼 더욱 중요한 일에 몰입하여 동료들이 데이터를 더욱 잘 활용할 수 있는 환경을 만들 수 있기를 바라요. 개인적인 학습 뿐만 아니라, 기업의 성장과 고객의 만족을 위한 방향일테니까요.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>

<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (Korean)" /><category term="Article (Project)" /><category term="Level (1. Beginner)" /><category term="Field (Data Engineering)" /><category term="Skills (Airflow)" /><summary type="html"><![CDATA[“Airflow 도입을 통해 사내 데이터 알림 시스템을 효율적으로 관리하고자 기존 Python 기반 세션 방식에서 벗어나 DAG 기반 워크플로우를 구축했습니다. Docker Compose를 활용해 로컬 및 VM 환경에서 Airflow를 설정하고, Slack 알림을 포함한 다양한 데이터 파이프라인을 자동화했습니다. 이를 통해 유지보수 부담을 줄이고, 안정성을 높이며, 확장 가능한 데이터 처리 환경을 마련할 수 있었습니다.”]]></summary></entry><entry><title type="html">Review of Implementing Airflow</title><link href="http://localhost:4000/implementing-airflow-en/" rel="alternate" type="text/html" title="Review of Implementing Airflow" /><published>2024-12-28T00:00:00+09:00</published><updated>2024-12-28T00:00:00+09:00</updated><id>http://localhost:4000/implementing-airflow-en</id><content type="html" xml:base="http://localhost:4000/implementing-airflow-en/"><![CDATA[<blockquote>
  <p>“By adopting Airflow, we transitioned from a traditional Python-based session approach to a DAG-based workflow to efficiently manage our internal data notification system. Using Docker Compose, we set up Airflow in both local and VM environments and automated various data pipelines, including Slack notifications. This implementation reduced maintenance overhead, improved stability, and established a scalable data processing environment.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>Background of Adoption</li>
  <li>Review of Implementation
    <ul>
      <li>2.1. Project Plan</li>
      <li>2.2. Local Environment Setup</li>
      <li>2.3. VM Instance Environment Setup</li>
      <li>2.4. Creating a DAG</li>
    </ul>
  </li>
  <li>Future Challenges</li>
</ol>

<hr />

<h1 id="1-background-of-adoption">1. Background of Adoption</h1>

<p>As a Data Engineer at IoTrust, I mainly focus on <strong>Analytics Engineering</strong> tasks such as:</p>

<pre><code class="language-plain">- (1) Designing and developing the data warehouse &amp; data mart
- (2) BI dashboards
- (3) Ad-hoc data notification bot development
- (4) Event taxonomy design and documentation management
- (5) Automation of (Finance/HR/CX) tasks
</code></pre>

<p>However, over time, problems began to arise with my role in “<strong>(3) Ad-hoc data notification bot development</strong>”. As I worked to enable colleagues to quickly check key metrics on Slack in real-time, the number of Python files gradually increased, and managing them became more resource-intensive.</p>

<p><img src="/assets/2024-12-28-implementing-airflow/1.webp" alt="" /></p>

<p>Specifically, I was managing all Slack notifications by running individual Python files directly in separate sessions using <code class="language-plaintext highlighter-rouge">tmux</code>. <code class="language-plaintext highlighter-rouge">tmux</code> is an open-source terminal multiplexer that allows managing multiple sessions independently within a single terminal. (<a href="https://en.wikipedia.org/wiki/Tmux">Wikipedia</a>)</p>

<p><img src="/assets/2024-12-28-implementing-airflow/2.webp" alt="" /></p>

<p>As the number of Python files grew and the complexity increased, the following issues emerged:</p>

<p><strong>(1) Increased Maintenance Burden</strong></p>

<p>When a Python script encountered an error, execution stopped immediately, and colleagues would not receive notifications until debugging was complete. There was no retry mechanism in place.</p>

<p>Additionally, debugging took a significant amount of time. Since dependent pipeline steps were all managed within a single main() function, identifying the exact failure point was difficult, leading to considerable time wasted. As a result, it became harder to stay focused on more important tasks.</p>

<p><strong>(2) Lack of Stability in Session-Based Management</strong></p>

<p>Server reboots or network issues could disrupt tasks, and there were instances where sessions were unexpectedly terminated, requiring recovery efforts.</p>

<p>Moreover, since all sessions shared the same environment, dependency conflicts could occur even when using <a href="https://docs.python.org/3/library/venv.html">Python Venv</a>.</p>

<p><strong>Due to these reasons, the need for Airflow as a workflow management tool grew stronger.</strong></p>

<ul>
  <li>Tasks can be automatically recovered simply by restarting containers.</li>
  <li>Each task operates in an isolated environment.</li>
  <li>The system is scalable for future workflow expansions.</li>
  <li>The web UI makes task monitoring and management easier.</li>
</ul>

<p>Initially, I had considered introducing Airflow when starting “<strong>Ad-hoc data notification bot development</strong>”. However, since the workflow was small at the time, I followed the <strong>YAGNI</strong> principle and decided against premature adoption.</p>

<p><a href="https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it">YAGNI</a> stands for “<strong>You Aren’t Gonna Need It</strong>,” an Agile software development principle that advises against adding unnecessary complexity. At that time, I believed in setting up a workflow that only met current needs, so I opted for a session-based approach.</p>

<p>However, as the workflow scaled, inefficiencies and resource waste in session management became more evident. This led me to finally decide on adopting Airflow.</p>

<hr />

<h1 id="2-review-of-implementation">2. Review of Implementation</h1>

<h3 id="21-project-plan">2.1. Project Plan</h3>

<p><img src="/assets/2024-12-28-implementing-airflow/3.webp" alt="" /></p>

<p>First, I established a plan as shown above.</p>

<p>(1) Modify existing Python scripts to fit the <strong>DAG format</strong>.</p>

<p>(2) Build the Airflow project in a <strong>local environment</strong> using Docker Compose and verify that notifications are correctly sent to a Slack test channel.</p>

<p>(3) Deploy the Airflow project on a <strong>VM instance</strong> using Docker Compose to finalize the notification system.</p>

<h3 id="22-local-environment-setup">2.2. Local Environment Setup</h3>

<p>(0) Docker must be installed.</p>

<ul>
  <li>I installed the Docker Desktop app. You can refer to <a href="https://www.docker.com/get-started/">this guide</a> for installation instructions.</li>
</ul>

<p>(1) Created a Python virtual environment.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> venv venv
<span class="nb">source </span>venv/bin/activate
</code></pre></div></div>

<p>(2) Loaded the Airflow image by running the following command in a directory named <code class="language-plaintext highlighter-rouge">airflow</code> (this will generate a <code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> file).</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-LfO</span> <span class="s1">'https://airflow.apache.org/docs/apache-airflow/2.9.1/docker-compose.yaml'</span>
</code></pre></div></div>

<p>(3) Created <code class="language-plaintext highlighter-rouge">dags</code>, <code class="language-plaintext highlighter-rouge">logs</code>, <code class="language-plaintext highlighter-rouge">plugins</code> directories and an <code class="language-plaintext highlighter-rouge">.env</code> file with the <strong>AIRFLOW_UID</strong> environment variable.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> ./dags ./logs ./plugins
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"AIRFLOW_UID=</span><span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span><span class="s2">"</span> <span class="o">&gt;</span> .env
</code></pre></div></div>

<p>(4) Created a <code class="language-plaintext highlighter-rouge">Dockerfile</code> with the following content.</p>

<div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># First-time build can take upto 10 mins.</span>

<span class="k">FROM</span><span class="s"> apache/airflow:2.9.1</span>

<span class="k">ENV</span><span class="s"> AIRFLOW_HOME=/opt/airflow</span>

<span class="k">USER</span><span class="s"> root</span>
<span class="k">RUN </span>apt-get update <span class="nt">-qq</span> <span class="o">&amp;&amp;</span> apt-get <span class="nb">install </span>vim <span class="nt">-qqq</span>
<span class="c"># git gcc g++ -qqq</span>

<span class="k">COPY</span><span class="s"> requirements.txt .</span>
<span class="k">RUN </span>pip <span class="nb">install</span> <span class="nt">--no-cache-dir</span> <span class="nt">-r</span> requirements.txt

<span class="c"># Ref: https://airflow.apache.org/docs/docker-stack/recipes.html</span>

<span class="k">SHELL</span><span class="s"> ["/bin/bash", "-o", "pipefail", "-e", "-u", "-x", "-c"]</span>

<span class="k">ARG</span><span class="s"> CLOUD_SDK_VERSION=322.0.0</span>
<span class="k">ENV</span><span class="s"> GCLOUD_HOME=/home/google-cloud-sdk</span>

<span class="k">ENV</span><span class="s"> PATH="${GCLOUD_HOME}/bin/:${PATH}"</span>

<span class="k">RUN </span><span class="nv">DOWNLOAD_URL</span><span class="o">=</span><span class="s2">"https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-</span><span class="k">${</span><span class="nv">CLOUD_SDK_VERSION</span><span class="k">}</span><span class="s2">-linux-x86_64.tar.gz"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nv">TMP_DIR</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span><span class="nb">mktemp</span> <span class="nt">-d</span><span class="si">)</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> curl <span class="nt">-fL</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DOWNLOAD_URL</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--output</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/google-cloud-sdk.tar.gz"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">mkdir</span> <span class="nt">-p</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">tar </span>xzf <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">/google-cloud-sdk.tar.gz"</span> <span class="nt">-C</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--strip-components</span><span class="o">=</span>1 <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="s2">"</span><span class="k">${</span><span class="nv">GCLOUD_HOME</span><span class="k">}</span><span class="s2">/install.sh"</span> <span class="se">\
</span>       <span class="nt">--bash-completion</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--path-update</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--usage-reporting</span><span class="o">=</span><span class="nb">false</span> <span class="se">\
</span>       <span class="nt">--quiet</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TMP_DIR</span><span class="k">}</span><span class="s2">"</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> gcloud <span class="nt">--version</span>

<span class="k">WORKDIR</span><span class="s"> $AIRFLOW_HOME</span>

<span class="k">COPY</span><span class="s"> scripts scripts</span>
<span class="k">RUN </span><span class="nb">chmod</span> +x scripts

<span class="k">USER</span><span class="s"> $AIRFLOW_UID</span>
</code></pre></div></div>

<p>(5) Created a <code class="language-plaintext highlighter-rouge">requirements.txt</code> file.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apache-airflow-providers-google
pyarrow
</code></pre></div></div>

<p>(6) Edited <code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> to include environment variables for Google Cloud and Slack authentication.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">/keys</code>: Used to store the Google Cloud service account JSON key file.</li>
  <li><code class="language-plaintext highlighter-rouge">.env</code>: Stores Airflow Admin login credentials and Slack API token.</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">x-airflow-common</span><span class="pi">:</span>
  <span class="s">...</span>
  <span class="s">environment</span><span class="err">:</span>
    <span class="s">...</span>
    <span class="s">AIRFLOW__CORE__LOAD_EXAMPLES</span><span class="err">:</span> <span class="s1">'</span><span class="s">false'</span> <span class="c1"># Prevents sample DAGs from being created.</span>
    <span class="s">...</span>
    <span class="s">GOOGLE_APPLICATION_CREDENTIALS</span><span class="err">:</span> <span class="s">/keys/airflow_credentials.json</span> <span class="c1"># Path to Google Cloud service account JSON key file.</span>
    <span class="na">AIRFLOW_CONN_GOOGLE_CLOUD_DEFAULT</span><span class="pi">:</span> <span class="s1">'</span><span class="s">google-cloud-platform://?extra__google_cloud_platform__key_path=/keys/airflow_credentials.json'</span> <span class="c1"># Same as above.</span>
    <span class="na">GCP_PROJECT_ID</span><span class="pi">:</span> <span class="s1">'</span><span class="s">gcp_project_id'</span> <span class="c1"># Google Cloud project ID.</span>
    <span class="na">AIRFLOW_CONN_SLACK_DEFAULT</span><span class="pi">:</span> <span class="s1">'</span><span class="s">slack://:${SLACK_TOKEN}@'</span> <span class="c1"># Slack API token managed in the .env file.</span>
    <span class="s">...</span>
  <span class="na">volumes</span><span class="pi">:</span>
    <span class="s">...</span>
    <span class="s">- ./keys:/keys:ro</span> <span class="c1"># Maps the `/keys` directory containing the Google Cloud service account JSON key file to Docker.</span>
<span class="nn">...</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="s">...</span>
  <span class="s">airflow-init</span><span class="err">:</span>
    <span class="s">...</span>
    <span class="s">environment</span><span class="err">:</span>
      <span class="s">...</span>
      <span class="s">_AIRFLOW_WWW_USER_USERNAME</span><span class="err">:</span> <span class="s">${_AIRFLOW_WWW_USER_USERNAME}</span> <span class="c1"># Airflow Webserver login credentials stored in .env.</span>
      <span class="na">_AIRFLOW_WWW_USER_PASSWORD</span><span class="pi">:</span> <span class="s">${_AIRFLOW_WWW_USER_PASSWORD}</span> <span class="c1"># Airflow Webserver login credentials stored in .env.</span>
      <span class="s">...</span>
</code></pre></div></div>

<p>(7) Building Docker Compose and Initializing Airflow</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose build
docker-compose up airflow-init
</code></pre></div></div>

<p>(8) Running Docker Compose</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose up <span class="nt">-d</span>
docker-compose ps
</code></pre></div></div>

<p>(9) Accessing the Airflow Webserver</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) Open http://0.0.0.0:8080 in a browser.
2) Log in using the credentials set in the `docker-compose.yaml` file:
  - _AIRFLOW_WWW_USER_USERNAME
  - _AIRFLOW_WWW_USER_PASSWORD
</code></pre></div></div>

<p><img src="/assets/2024-12-28-implementing-airflow/4.webp" alt="" /></p>

<p>(10) Initializing Git and Linking to GitHub</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git init
git remote add origin https://github.com/.../airflow.git
git branch <span class="nt">-m</span> main
git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s2">"created airflow project"</span>
git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<h3 id="23-vm-instance-environment-setup">2.3. VM Instance Environment Setup</h3>

<p>(1) Creating Firewall Rules (To allow internal access to the Airflow Webserver running on the VM Instance, I configured firewall rules.)</p>

<p><img src="/assets/2024-12-28-implementing-airflow/5.webp" alt="" /></p>

<ul>
  <li><strong>Direction</strong>: Ingress</li>
  <li><strong>Target Tags</strong>: airflow (You can name this as needed.)</li>
  <li><strong>Source Filter &gt; IP Range</strong>: Internal company IP address range.</li>
  <li><strong>Protocol and Port</strong>: tcp-8080 (The webserver communicates with the host machine via port 8080, which can be modified in <code class="language-plaintext highlighter-rouge">docker-compose.yaml</code>.)</li>
</ul>

<p>(2) Creating the <code class="language-plaintext highlighter-rouge">airflow</code> VM Instance</p>

<p><img src="/assets/2024-12-28-implementing-airflow/6.webp" alt="" /></p>

<ul>
  <li><strong>Machine Type</strong>: E2 series with at least 2 vCPUs and 8GB of memory (If using 4GB, the server may struggle with network traffic.)</li>
  <li><strong>OS &amp; Storage</strong>: Debian OS, 10GB storage.</li>
  <li><strong>Firewall</strong>: Enabled HTTP &amp; HTTPS traffic, and assigned the <code class="language-plaintext highlighter-rouge">airflow</code> tag created in the firewall settings.</li>
</ul>

<p>(3) Installing Docker and Python Virtual Environment (Following the same setup as in the local environment)</p>

<ul>
  <li>Refer to steps (0) and (1) from Section 2.2 for installing Docker and setting up a Python virtual environment.</li>
</ul>

<p>(4) Cloning the Repository and Configuring Environment Files (Created the <code class="language-plaintext highlighter-rouge">airflow</code> directory and cloned the remote repository. Then, manually added <code class="language-plaintext highlighter-rouge">/keys</code> and <code class="language-plaintext highlighter-rouge">.env</code> files.)</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/.../airflow.git
</code></pre></div></div>

<p>(5) Building and Running Airflow on the VM (Following the same procedure as the local environment)</p>

<ul>
  <li>Refer to steps (7) and (8) from Section 2.2 to build and execute Docker Compose.</li>
</ul>

<p>(6) Accessing the Airflow Webserver on the VM</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) Open http://{VM Instance External IP}:8080 in a browser.
2) Log in using the credentials set in the docker-compose.yaml file:
  - _AIRFLOW_WWW_USER_USERNAME
  - _AIRFLOW_WWW_USER_PASSWORD
</code></pre></div></div>

<h3 id="24-creating-a-dag">2.4. Creating a DAG</h3>

<p>The simplest DAG I created is <strong>the Daily BigQuery Usage Notification</strong>. This is primarily a self-notification system to help me manage Google Cloud resources efficiently. Below, I will break down the <code class="language-plaintext highlighter-rouge">DAG.py</code> code step by step.</p>

<p>(1) Importing Required Libraries and Operators</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# Importing Required Libraries and Environment Variables
# ========================================================================
</span>
<span class="kn">from</span> <span class="n">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>
<span class="kn">from</span> <span class="n">airflow.operators.python</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
<span class="kn">from</span> <span class="n">airflow.providers.slack.operators.slack</span> <span class="kn">import</span> <span class="n">SlackAPIPostOperator</span>
<span class="kn">from</span> <span class="n">airflow.models</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="kn">from</span> <span class="n">google.cloud</span> <span class="kn">import</span> <span class="n">bigquery</span>

<span class="kn">from</span> <span class="n">pendulum</span> <span class="kn">import</span> <span class="n">timezone</span>
<span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
</code></pre></div></div>

<ul>
  <li>Instead of using BigQuery-specific Airflow operators, I opted for <code class="language-plaintext highlighter-rouge">google.cloud.bigquery</code> and <code class="language-plaintext highlighter-rouge">PythonOperator</code>. Since this DAG primarily involves SELECT queries that return large datasets, using XCom to pass data between tasks would be inefficient.</li>
</ul>

<p>(2) Defining Key Variables and Clients</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# Defining Clients and Key Variables
# ========================================================================
</span>
<span class="n">bigquery_client</span> <span class="o">=</span> <span class="n">bigquery</span><span class="p">.</span><span class="nc">Client</span><span class="p">()</span>
<span class="n">kst</span> <span class="o">=</span> <span class="nf">timezone</span><span class="p">(</span><span class="sh">'</span><span class="s">Asia/Seoul</span><span class="sh">'</span><span class="p">)</span>

<span class="n">SLACK_CHANNEL_TEST</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">slack-channel-test</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SLACK_CHANNEL</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">slack-channel-prod</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">default_var</span><span class="o">=</span><span class="n">SLACK_CHANNEL_TEST</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><strong>kst</strong>: Since Airflow uses UTC as its default timezone, I explicitly set it to Korean Standard Time using <code class="language-plaintext highlighter-rouge">pendulum.timezone</code>.</li>
  <li><strong>Slack Channel</strong>: The final step in this DAG sends a notification to a Slack channel. To prevent unnecessary alerts, I first test the DAG using <strong>a dedicated Slack test channel</strong> before deploying it to the production channel.</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/7.webp" alt="" /></p>
<blockquote>
  <p><a href="https://airflow.apache.org/docs/apache-airflow/stable/howto/variable.html">Apache Airflow Docs</a></p>
</blockquote>

<p>(3) Defining DAG Default Arguments</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# Defining DAG Default Arguments
# ========================================================================
</span>
<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">owner</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Joshua Kim</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">:</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2025</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tzinfo</span><span class="o">=</span><span class="n">kst</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">depends_on_past</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="bp">...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>(4) Writing Dynamic Query Functions</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# Query Definitions
# ========================================================================
</span>
<span class="bp">...</span>

<span class="c1"># Query Usage (by user)
</span><span class="k">def</span> <span class="nf">query_usage_by_user</span><span class="p">(</span><span class="n">date</span><span class="p">):</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
        SELECT
            user_email AS user,
            SUM(total_bytes_billed) / POW(2, 30) AS gibibyte
        FROM
            `</span><span class="si">{</span><span class="n">project_id</span><span class="si">}</span><span class="s">.</span><span class="si">{</span><span class="n">region</span><span class="si">}</span><span class="s">.INFORMATION_SCHEMA.JOBS`
        WHERE
            DATE(TIMESTAMP(creation_time), </span><span class="sh">"</span><span class="s">Asia/Seoul</span><span class="sh">"</span><span class="s">) = </span><span class="sh">'</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="sh">'</span><span class="s">
            AND job_type = </span><span class="sh">'</span><span class="s">QUERY</span><span class="sh">'</span><span class="s">
        GROUP BY
            1
        ORDER BY
            2 DESC
    </span><span class="sh">"""</span>

<span class="bp">...</span>
</code></pre></div></div>

<p>(5) Writing Core Functions for Task Execution</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# Function Definitions
# ========================================================================
</span>
<span class="c1"># Fetch BigQuery Data
</span><span class="k">def</span> <span class="nf">fetch_bigquery_data</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="c1"># Yesterday
</span>    <span class="n">today_kst</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">execution_date</span><span class="sh">'</span><span class="p">].</span><span class="nf">in_timezone</span><span class="p">(</span><span class="n">kst</span><span class="p">)</span>
    <span class="n">yesterday_kst</span> <span class="o">=</span> <span class="n">today_kst</span><span class="p">.</span><span class="nf">subtract</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">to_date_string</span><span class="p">()</span>

    <span class="bp">...</span>

    <span class="c1"># Query Usage by user Yesterday
</span>    <span class="n">usage_by_user_df</span> <span class="o">=</span> <span class="n">bigquery_client</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="nf">query_usage_by_user</span><span class="p">(</span><span class="n">yesterday_kst</span><span class="p">)).</span><span class="nf">to_dataframe</span><span class="p">()</span>
    <span class="n">usage_by_user_dict</span> <span class="o">=</span> <span class="n">usage_by_user_df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">user</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">gibibyte</span><span class="sh">'</span><span class="p">].</span><span class="nf">to_dict</span><span class="p">()</span>

    <span class="c1"># Push Data to XCom
</span>    <span class="bp">...</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">ti</span><span class="sh">'</span><span class="p">].</span><span class="nf">xcom_push</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="sh">'</span><span class="s">usage_by_user_dict</span><span class="sh">'</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">usage_by_user_dict</span><span class="p">)</span>
    <span class="bp">...</span>

<span class="c1"># Write a Slack Message
</span><span class="k">def</span> <span class="nf">write_slack_message</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="c1"># Read BigQuery Data
</span>    <span class="bp">...</span>
    <span class="n">usage_by_user_dict</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="sh">'</span><span class="s">ti</span><span class="sh">'</span><span class="p">].</span><span class="nf">xcom_pull</span><span class="p">(</span><span class="n">task_ids</span><span class="o">=</span><span class="sh">'</span><span class="s">fetch_bigquery_data</span><span class="sh">'</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="sh">'</span><span class="s">usage_by_user_dict</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># Create a Message
</span>    <span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">:bigquery: *Daily BigQuery Usage Summary* (Korean Timezone)</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>
    <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">*:busts_in_silhouette: By User*</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>
    <span class="k">for</span> <span class="n">user</span><span class="p">,</span> <span class="n">usage</span> <span class="ow">in</span> <span class="n">usage_by_user_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="n">message</span> <span class="o">+=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">   - *</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s">*: `</span><span class="si">{</span><span class="nf">float</span><span class="p">(</span><span class="n">usage</span><span class="p">)</span><span class="si">:</span><span class="p">,.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">`GiB</span><span class="se">\n</span><span class="sh">"</span>
    <span class="bp">...</span>

    <span class="k">return</span> <span class="n">message</span>
</code></pre></div></div>

<p>(6) Defining the DAG</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ========================================================================
# DAG Definition
# ========================================================================
</span>
<span class="k">with</span> <span class="nc">DAG</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">bigquery_usage_alert</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="sh">'</span><span class="s">BigQuery Usage Notification</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">schedule_interval</span><span class="o">=</span><span class="sh">'</span><span class="s">5 0 * * *</span><span class="sh">'</span><span class="p">,</span> <span class="c1"># Runs daily at 12:05 AM KST
</span>    <span class="n">catchup</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
    
    <span class="c1"># Fetch BigQuery Data
</span>    <span class="n">task_fetch_bigquery_data</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="sh">'</span><span class="s">fetch_bigquery_data</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">fetch_bigquery_data</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Write a Slack Message
</span>    <span class="n">task_write_slack_message</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="sh">'</span><span class="s">write_slack_message</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">python_callable</span><span class="o">=</span><span class="n">write_slack_message</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Send a Slack Message
</span>    <span class="n">task_send_slack_message</span> <span class="o">=</span> <span class="nc">SlackAPIPostOperator</span><span class="p">(</span>
        <span class="n">task_id</span><span class="o">=</span><span class="sh">'</span><span class="s">send_slack_message</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">text</span><span class="o">=</span><span class="sh">''</span><span class="p">,</span>
        <span class="n">slack_conn_id</span><span class="o">=</span><span class="sh">'</span><span class="s">slack_default</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">channel</span><span class="o">=</span><span class="n">SLACK_CHANNEL</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Data Lineage
</span>    <span class="n">task_fetch_bigquery_data</span> <span class="o">&gt;&gt;</span> <span class="n">task_write_slack_message</span> <span class="o">&gt;&gt;</span> <span class="n">task_send_slack_message</span>
</code></pre></div></div>

<ul>
  <li>This DAG follows a straightforward workflow:</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/8.webp" alt="" /></p>

<ul>
  <li>And the Slack notification looks like this:</li>
</ul>

<p><img src="/assets/2024-12-28-implementing-airflow/9.webp" alt="" /></p>

<hr />

<h1 id="3-future-challenges">3. Future Challenges</h1>

<p>Airflow presents a steep learning curve, especially for those unfamiliar with Linux or Docker environments. However, its flexibility makes it an excellent orchestration tool for data analysts, analytics engineers, and backend developers.</p>

<p>Following the successful implementation of Airflow in our company, I am now considering <strong>additional enhancements</strong>:</p>

<ul>
  <li>Designing external data collection pipelines and sending refined data to stakeholders via email or Slack.</li>
  <li>Managing dbt table dependencies by setting up separate batch executions using Airflow DAGs.</li>
  <li>Exploring other optimization opportunities.</li>
</ul>

<p>By reducing maintenance overhead and improving workflow stability through Airflow, I aim to maximize my work efficiency and focus more on high-impact tasks that enable my colleagues to better utilize data. Ultimately, this aligns with both my learning goals and my company’s growth objectives.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>

<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (English)" /><category term="Article (Project)" /><category term="Level (1. Beginner)" /><category term="Field (Data Engineering)" /><category term="Skills (Airflow)" /><summary type="html"><![CDATA[“By adopting Airflow, we transitioned from a traditional Python-based session approach to a DAG-based workflow to efficiently manage our internal data notification system. Using Docker Compose, we set up Airflow in both local and VM environments and automated various data pipelines, including Slack notifications. This implementation reduced maintenance overhead, improved stability, and established a scalable data processing environment.”]]></summary></entry><entry><title type="html">dbt Docs 사내 공유 방법 (사이트 호스팅 후기)</title><link href="http://localhost:4000/dbt-docs-site-hosting-ko/" rel="alternate" type="text/html" title="dbt Docs 사내 공유 방법 (사이트 호스팅 후기)" /><published>2024-09-21T00:00:00+09:00</published><updated>2024-09-21T00:00:00+09:00</updated><id>http://localhost:4000/dbt-docs-site-hosting-ko</id><content type="html" xml:base="http://localhost:4000/dbt-docs-site-hosting-ko/"><![CDATA[<blockquote>
  <p>“사내에서 dbt Docs를 활용하여 데이터 웨어하우스 문서화를 자동화하고 이를 통해 사내 데이터 접근성과 효율성을 높이기 위한 작업을 수행했습니다. 특히, dbt의 자동 문서화 기능을 활용해 테이블 간 의존성 및 명세서를 최신화함으로써 데이터 활용의 정확성과 속도를 개선했습니다. 이를 위해 VM 인스턴스에서 dbt Docs를 호스팅하고 사내 IP 범위 내 구성원들이 접근할 수 있도록 방화벽 설정을 추가하는 등의 기술적 문제를 해결하며 성공적으로 시스템을 구축했습니다.”</p>
</blockquote>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>dbt Docs란 무엇인가?</li>
  <li>배경</li>
  <li>목표</li>
  <li>진행 과정</li>
  <li>결론</li>
</ol>

<hr />

<h1 id="1-dbt-docs란-무엇인가">1. dbt Docs란 무엇인가?</h1>

<p><a href="https://www.getdbt.com/">dbt</a>는 ELT 파이프라인의 Transformation 단계에 특화된 자동화 프레임워크로, Data Analyst와 Analytics Engineer 분들을 중심으로 널리 사용됩니다.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/1.webp" alt="" />
<img src="/assets/2024-09-21-dbt-docs-site-hosting/2.webp" alt="" /></p>

<p>dbt는 테이블 간의 의존 관계를 바탕으로 Data Lineage를 분석하고, 그 결과를 DAG (Directed Acyclic Graph) 형태로 컴파일하여 전체 Transformation 과정을 자동으로 실행해줍니다. 이를 통해 데이터 웨어하우스의 Orchestration 관리를 보다 효율적으로 진행할 수 있는데요. dbt의 가장 큰 장점 중 하나는 “자동 문서화” 기능입니다.</p>

<p>(1) <strong>Lineage Graph</strong>: 테이블 간의 의존성을 시각적으로 보여주어, 유지보수 작업시 영향을 받는 테이블들을 한 눈에 파악할 수 있도록 도와줍니다.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/3.webp" alt="" /></p>

<p>(2) <strong>명세서 확인</strong>: 각 테이블과 컬럼의 Description 등 세부적인 명세서를 쉽게 확인할 수 있습니다.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/4.gif" alt="" />
<img src="/assets/2024-09-21-dbt-docs-site-hosting/5.gif" alt="" /></p>

<p>dbt Docs는 데이터팀의 주요 Pain Point를 해결하는 데 큰 도움이 됩니다. 많은 기업이 데이터 활용도를 높이기 위해 데이터 웨어하우스를 도입하지만, 수많은 데이터 마트와 테이블 구조로 인해 혼란스러워 사내 구성원들의 접근성이 떨어지는 아이러니한 상황에 쉽게 직면하곤 합니다. 특히 프로덕트의 급성장에 따라 조직의 데이터 의존도가 높아지면, 데이터 웨어하우스의 빌딩 속도에 집중하느라 품질, 정합성, 접근성, 명세서 작성 관리를 유지하기가 어려워지기도 쉽습니다.</p>

<p>dbt는 데이터 웨어하우스 전체의 명세를 자동으로 문서화해 이러한 문제를 해결하며, 데이터의 품질과 활용성을 높이는 중요한 역할을 하는 것입니다.</p>

<hr />

<h1 id="2-배경">2. 배경</h1>

<p>저는 사내에서 쿼리 작성 역량을 갖춘 구성원 분들이 테이블과 Lineage 문서를 확인하여 Redash 대시보드를 직접 만들 수 있는 환경을 제공하고자 했습니다. 즉, 데이터 웨어하우스 문서화가 필요했던 것이죠. 구글 시트나 노션 페이지 등을 활용하는 것도 고려해봤지만, 애널리틱스 엔지니어링 작업과 문서화 작업이 분리되면 다음과 같은 문제가 발생할 수 있다는 노파심이 들었습니다.</p>

<ul>
  <li>데이터 마트 생성과 문서화 사이의 Latency로 인해 커뮤니케이션 속도가 저하될 수 있다.</li>
  <li>개별적인 문서화 작업 중 휴먼 에러가 발생하여 부정확한 쿼리 결과를 낳을 수 있다.</li>
</ul>

<p>따라서 저는 문서화 환경이 애널리틱스 엔지니어링 본연의 작업과 분리되어 이중으로 진행되는 것은 결코 바람직하지 않다고 판단했으며, 반복적인 작업 루틴을 줄임으로써 더 중요한 가치를 창출하는 데 시간을 쓰고 싶었습니다.</p>

<hr />

<h1 id="3-목표">3. 목표</h1>

<p>dbt Docs 기능을 통해 사내 구성원 분들이 dbt 프로젝트 버전 업데이트 즉시 최신 명세를 확인할 수 있는 Docs 사이트를 호스팅하는 것이 이번 작업의 목표였습니다.</p>

<hr />

<h1 id="4-진행-과정">4. 진행 과정</h1>

<h3 id="41-dbt-프로젝트-관리-현황">4.1. dbt 프로젝트 관리 현황</h3>

<p>BigQuery 프로젝트 내에서 소스 테이블들을 Core Layer, Mart Layer로 변환하는 작업을 실행하고 있습니다.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/6.webp" alt="" /></p>

<p>모든 Transformation 과정은 dbt 프로젝트를 통해 Google Cloud의 VM Instance 내에서 주기적으로 실행되고 있습니다.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/7.webp" alt="" /></p>

<h3 id="42-로컬-호스팅의-문제점">4.2. 로컬 호스팅의 문제점</h3>

<p>여타 프레임워크와 마찬가지로, dbt Docs를 호스팅할 경우 기본적으로 해당 Host Machine에서만 접속이 가능합니다. 즉, dbt 프로젝트가 있는 VM Instance에서 접속하거나, 혹은 SSH Key를 사용해 Remote 연결된 Local Machine에서만 접속할 수 있는 것입니다.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/8.webp" alt="" /></p>

<p>하지만 사내 구성원들도 접속할 수 있는 환경을 마련해야 했습니다. 즉, SSH Key가 없지만 동일한 IP 주소 범위 내에서 접속하는 각 Machine에서 dbt Docs 사이트에 접속할 수 있도록 지원해야 했던 것이죠.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/9.webp" alt="" /></p>

<h3 id="43-dbt-docs-호스팅-시작하기">4.3. dbt Docs 호스팅 시작하기</h3>

<p>다음은 사내 구성원들의 접속 환경을 마련하기 위해 설정한 단계들입니다.</p>

<p>(1) <code class="language-plaintext highlighter-rouge">tmux</code> 세션 생성</p>

<p><code class="language-plaintext highlighter-rouge">tmux</code>를 통해 VM Instance에서 dbt Docs 호스팅을 유지하는 독립 세션을 만들었습니다.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   tmux new <span class="nt">-s</span> dbt_docs <span class="c"># dbt_docs 이름의 세션을 생성합니다.</span>
   tmux attach <span class="nt">-t</span> dbt_docs <span class="c"># dbt_docs 세션에 Attach합니다.</span>
</code></pre></div></div>

<p>(2) 사이트 빌드</p>

<p>dbt 프로젝트의 파일들을 컴파일하여 Docs 사이트를 빌드했습니다.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="nb">source </span>dbt-venv/bin/activate <span class="c"># Python Virtual Environment 활성화</span>
   <span class="nb">export </span><span class="nv">DBT_PROFILES_DIR</span><span class="o">=</span><span class="s2">"path/to/profiles.yml"</span> <span class="c"># DBT_PROFILES_DIR 환경변수 정의</span>
   dbt docs generate <span class="nt">--target</span> prod <span class="c"># prod 스키마 기준으로 dbt Docs 빌드하기</span>
</code></pre></div></div>

<p>(3) 사이트 호스팅 시작</p>

<p>Docs 사이트 호스팅을 시작한 후, 해당 세션으로부터 Detach하여 빠져나왔습니다.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   dbt docs serve <span class="nt">--host</span> 0.0.0.0 <span class="nt">--port</span> 8080 <span class="c"># host 도메인과 port를 파라미터로 명시하기</span>
</code></pre></div></div>

<p>(4) VM Instance 설정</p>

<p>VM Instance의 External IP를 확인하고, 수정 페이지에서 Network Tag를 추가했습니다.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/10.webp" alt="" />
<img src="/assets/2024-09-21-dbt-docs-site-hosting/11.webp" alt="" /></p>

<p>(5) VPC 방화벽 규칙 추가</p>

<p>Firewall policies 콘솔에 들어가서 VPC fire rules를 다음과 같이 추가했습니다.</p>

<ul>
  <li><strong>방향</strong>: 인그레스 (Ingress)</li>
  <li><strong>소스 IPv4 범위</strong>: 사내 IPv4 범위 (CIDR 형식)</li>
  <li><strong>타겟 Tags</strong>: 방금 전 VM Instance에 추가한 Network Tag (dbt-docs-serve)</li>
  <li><strong>프로토콜 및 포트</strong>: 방금 전 호스팅한 dbt Docs의 Port (8080)</li>
</ul>

<p>(6) 접속 주소</p>

<p>이제 사내 IPv4 범위 내에서 다음 주소로 접속하면 됩니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">http://{VM Instance의 External IP}:8080</code></li>
</ul>

<p>(7) 구성된 환경을 요약하면 다음과 같습니다.</p>

<blockquote>
  <p>“사내 IPv4 범위 내에서 VM 인스턴스의 External IP 주소에 Port 8080으로 접속하면, 호스팅 중인 dbt Docs 사이트가 로드됩니다!”</p>
</blockquote>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/12.webp" alt="" /></p>

<hr />

<h1 id="5-결론">5. 결론</h1>

<p>dbt Docs 사이트 링크를 슬랙 채널에 고정(Pin)하여 구성원 분들이 추후 편리하게 접속하실 수 있도록 설정했습니다. 앞으로 기업과 프로덕트가 성장함에 따라 데이터 활용의 수요는 지속적으로 커질 것입니다. dbt의 “자동 문서화” 기능을 통해 문서화 리소스를 절감하고, 데이터 본연의 업무 효율성을 높일 수 있을 것입니다.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>

<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (Korean)" /><category term="Article (Issue Resolution)" /><category term="Level (1. Beginner)" /><category term="Field (Analytics Engineering)" /><category term="Skills (Linux)" /><summary type="html"><![CDATA[“사내에서 dbt Docs를 활용하여 데이터 웨어하우스 문서화를 자동화하고 이를 통해 사내 데이터 접근성과 효율성을 높이기 위한 작업을 수행했습니다. 특히, dbt의 자동 문서화 기능을 활용해 테이블 간 의존성 및 명세서를 최신화함으로써 데이터 활용의 정확성과 속도를 개선했습니다. 이를 위해 VM 인스턴스에서 dbt Docs를 호스팅하고 사내 IP 범위 내 구성원들이 접근할 수 있도록 방화벽 설정을 추가하는 등의 기술적 문제를 해결하며 성공적으로 시스템을 구축했습니다.”]]></summary></entry><entry><title type="html">How to Share dbt Docs Internally (Site Hosting Review)</title><link href="http://localhost:4000/dbt-docs-site-hosting-en/" rel="alternate" type="text/html" title="How to Share dbt Docs Internally (Site Hosting Review)" /><published>2024-09-21T00:00:00+09:00</published><updated>2024-09-21T00:00:00+09:00</updated><id>http://localhost:4000/dbt-docs-site-hosting-en</id><content type="html" xml:base="http://localhost:4000/dbt-docs-site-hosting-en/"><![CDATA[<blockquote>
  <p>“I worked on automating data warehouse documentation using dbt Docs within the company, aiming to improve internal data accessibility and efficiency. Specifically, I utilized dbt’s automated documentation feature to keep dependencies between tables and specifications up to date, thereby improving the accuracy and speed of data usage. I successfully built the system by resolving technical issues, such as hosting dbt Docs on a VM instance and adding firewall settings to allow internal team members to access it within the company’s IP range.”</p>
</blockquote>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>What is dbt Docs?</li>
  <li>Background</li>
  <li>Objective</li>
  <li>Process</li>
  <li>Conclusion</li>
</ol>

<hr />

<h1 id="1-what-is-dbt-docs">1. What is dbt Docs?</h1>

<p><a href="https://www.getdbt.com/">dbt</a> is an automation framework specialized in the transformation phase of the ELT pipeline, widely used by data analysts and analytics engineers.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/1.webp" alt="" />
<img src="/assets/2024-09-21-dbt-docs-site-hosting/2.webp" alt="" /></p>

<p>dbt analyzes data lineage based on table dependencies and compiles it into a DAG (Directed Acyclic Graph) to automatically execute the entire transformation process. This enables more efficient orchestration management of data warehouses. One of dbt’s key strengths is its “automated documentation” feature.</p>

<p>(1) <strong>Lineage Graph</strong>: Visually displays table dependencies, allowing you to easily identify the tables affected during maintenance tasks.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/3.webp" alt="" /></p>

<p>(2) <strong>View Specifications</strong>: Easily check detailed specifications, such as descriptions of each table and column.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/4.gif" alt="" />
<img src="/assets/2024-09-21-dbt-docs-site-hosting/5.gif" alt="" /></p>

<p>dbt Docs is highly effective in addressing major pain points for data teams. While many companies adopt data warehouses to enhance data utilization, they often face the ironic situation where the complexity of numerous data marts and table structures reduces internal accessibility. As the organization’s dependence on data increases with the rapid growth of its products, maintaining quality, accuracy, accessibility, and documentation can become increasingly difficult.</p>

<p>dbt solves this problem by automatically documenting the entire data warehouse, playing a key role in improving data quality and usability.</p>

<hr />

<h1 id="2-background">2. Background</h1>

<p>I wanted to provide an environment where internal members with query-writing skills could view table and lineage documentation and directly create Redash dashboards. In other words, data warehouse documentation was necessary. Although I considered using Google Sheets or Notion pages, I was concerned that separating analytics engineering and documentation tasks could lead to the following issues:</p>

<ul>
  <li>Communication could slow down due to latency between data mart creation and documentation.</li>
  <li>Human error during individual documentation could result in inaccurate query outcomes.</li>
</ul>

<p>Thus, I concluded that it was not ideal for the documentation environment to be separated from the core analytics engineering work. I wanted to reduce repetitive tasks and spend more time creating value in more critical areas.</p>

<hr />

<h1 id="3-objective">3. Objective</h1>

<p>The goal of this project was to host a dbt Docs site where internal members could check the latest specifications as soon as the dbt project version was updated.</p>

<hr />

<h1 id="4-process">4. Process</h1>

<h3 id="41-current-dbt-project-management">4.1. Current dbt Project Management</h3>

<p>I’ve been working on converting source tables into Core Layer and Mart Layer within the BigQuery project.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/6.webp" alt="" /></p>

<p>All transformation processes are periodically executed via a dbt project on a Google Cloud VM instance.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/7.webp" alt="" /></p>

<h3 id="42-issues-with-local-hosting">4.2. Issues with Local Hosting</h3>

<p>As with other frameworks, hosting dbt Docs is, by default, only accessible from the host machine. In other words, you can only access it from the VM instance where the dbt project is located or from a locally connected machine via SSH.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/8.webp" alt="" /></p>

<p>However, I needed to create an environment where internal members could also access it. In short, I had to allow machines within the same IP range, but without SSH keys, to access the dbt Docs site.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/9.webp" alt="" /></p>

<h3 id="43-starting-dbt-docs-hosting">4.3. Starting dbt Docs Hosting</h3>

<p>Here are the steps I followed to set up the internal access environment:</p>

<p>(1) Create a <code class="language-plaintext highlighter-rouge">tmux</code> session</p>

<p>I used <code class="language-plaintext highlighter-rouge">tmux</code> to create an independent session on the VM instance to maintain the dbt Docs hosting.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   tmux new <span class="nt">-s</span> dbt_docs <span class="c"># Create a session named dbt_docs</span>
   tmux attach <span class="nt">-t</span> dbt_docs <span class="c"># Attach to the dbt_docs session</span>
</code></pre></div></div>

<p>(2) Build the site</p>

<p>I compiled the dbt project files to build the Docs site.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="nb">source </span>dbt-venv/bin/activate <span class="c"># Activate Python Virtual Environment</span>
   <span class="nb">export </span><span class="nv">DBT_PROFILES_DIR</span><span class="o">=</span><span class="s2">"path/to/profiles.yml"</span> <span class="c"># Define the DBT_PROFILES_DIR environment variable</span>
   dbt docs generate <span class="nt">--target</span> prod <span class="c"># Build dbt Docs based on the prod schema</span>
</code></pre></div></div>

<p>(3) Start hosting the site</p>

<p>I started hosting the Docs site and detached from the session.</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   dbt docs serve <span class="nt">--host</span> 0.0.0.0 <span class="nt">--port</span> 8080 <span class="c"># Specify the host domain and port as parameters</span>
</code></pre></div></div>

<p>(4) Set up the VM Instance</p>

<p>I checked the VM instance’s external IP and added a network tag on the modification page.</p>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/10.webp" alt="" />
<img src="/assets/2024-09-21-dbt-docs-site-hosting/11.webp" alt="" /></p>

<p>(5) Add VPC firewall rules</p>

<p>I went to the firewall policies console and added VPC firewall rules as follows:</p>

<ul>
  <li><strong>Direction</strong>: Ingress</li>
  <li><strong>Source IPv4 Range</strong>: Internal IPv4 range (CIDR format)</li>
  <li><strong>Target Tags</strong>: The network tag added to the VM instance earlier (dbt-docs-serve)</li>
  <li><strong>Protocol and Port</strong>: Port for the dbt Docs hosting (8080)</li>
</ul>

<p>(6) Access address</p>

<p>Now, from within the internal IPv4 range, you can access the site via the following address:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">http://{VM Instance의 External IP}:8080</code></li>
</ul>

<p>(7) In summary, the configured environment is as follows:</p>

<blockquote>
  <p>“Within the internal IPv4 range, you can access the hosted dbt Docs site by connecting to the VM instance’s external IP address on port 8080!”</p>
</blockquote>

<p><img src="/assets/2024-09-21-dbt-docs-site-hosting/12.webp" alt="" /></p>

<hr />

<h1 id="5-conclusion">5. Conclusion</h1>

<p>I pinned the dbt Docs site link in the Slack channel to allow team members to easily access it later. As the company and product continue to grow, the demand for data utilization will increase. By leveraging dbt’s “automated documentation” feature, we can save documentation resources and enhance the efficiency of data-related tasks.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>

<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (English)" /><category term="Article (Issue Resolution)" /><category term="Level (1. Beginner)" /><category term="Field (Analytics Engineering)" /><category term="Skills (Linux)" /><summary type="html"><![CDATA[“I worked on automating data warehouse documentation using dbt Docs within the company, aiming to improve internal data accessibility and efficiency. Specifically, I utilized dbt’s automated documentation feature to keep dependencies between tables and specifications up to date, thereby improving the accuracy and speed of data usage. I successfully built the system by resolving technical issues, such as hosting dbt Docs on a VM instance and adding firewall settings to allow internal team members to access it within the company’s IP range.”]]></summary></entry><entry><title type="html">구매 전환율 급상승 후기</title><link href="http://localhost:4000/how-we-dramatically-improved-conversion-rates-ko/" rel="alternate" type="text/html" title="구매 전환율 급상승 후기" /><published>2024-08-29T00:00:00+09:00</published><updated>2024-08-29T00:00:00+09:00</updated><id>http://localhost:4000/how-we-dramatically-improved-conversion-rates-ko</id><content type="html" xml:base="http://localhost:4000/how-we-dramatically-improved-conversion-rates-ko/"><![CDATA[<blockquote>
  <p>“외부 요인으로 인해 증가한 신규 방문자 데이터를 분석하여 구매 전환율의 급상승을 달성했습니다. 데이터를 통해 신규 방문자 수와 이들의 구매 의향이 크게 증가했음을 발견했지만, 결제 단계에서 이탈률이 높다는 문제를 파악했습니다. 이에 결제 과정의 불편함이 주요 원인임을 가설로 설정하고, PayPal Express Checkout을 도입하여 사용자 경험을 개선했습니다. 그 결과, 결제 전환율이 32%p 상승하여 이전보다 훨씬 높은 수준을 기록했으며, 이는 지속적으로 유지되고 있습니다. 이를 통해 분석 기반의 문제 해결과 성과 향상을 이뤄냈습니다.”</p>
</blockquote>

<hr />

<table>
  <thead>
    <tr>
      <th><strong>Performance Summary</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>- 전환율 (<code class="language-plaintext highlighter-rouge">add_payment_info</code> → <code class="language-plaintext highlighter-rouge">purchase</code>): 32%p ↑</td>
    </tr>
  </tbody>
</table>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>2023년, 글로벌 시장 점유율 1위의 경쟁사가 사업적 논란에 휘말리면서 당사는 <strong>예상치 못한 매출 증가</strong>를 경험하게 되었습니다.</li>
  <li>이로 인해 자사몰의 신규 방문자가 급증했으며, 이는 당사 내부 마케팅 활동의 결과가 아닌 외부 시장 변화에 따른 현상으로 파악되었습니다.</li>
  <li>데이터 분석가로서 저는 이러한 비정상적인 시장 움직임을 깊이 있게 분석하기 위해 자발적으로 데이터 모니터링을 했고, 특히 <strong>신규 방문자들의 유입 경로와 구매 행동 패턴</strong>을 집중적으로 추적했습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>신규 방문자 수가 급증한 상황에서 <strong>결제 프로세스의 이탈률이 높다는 문제</strong>를 발견했습니다.</li>
  <li>구체적으로 구매 퍼널의 각 단계에서 이탈 지점을 분석한 결과, 많은 고객들이 <strong>구매 정보를 입력한 후 결제 단계에서 이탈</strong>하는 것으로 나타났습니다.</li>
  <li>특히, <strong>결제 과정에서의 UX</strong>가 구매 전환에 큰 영향을 미친다는 점을 인지하고, 문제를 명확히 하여 사용자 경험을 개선할 필요가 있었습니다.</li>
  <li>또한, 이번 전환율 저하는 외부 요인에 의한 자연적 유입 사용자 증가와 세그먼트 변화와 관련이 있을 것으로 판단했습니다.</li>
</ul>

<h3 id="actions">Actions</h3>
<ul>
  <li>발견된 문제를 바탕으로 결제 프로세스 개선을 위해 사내 구성원들과 문제를 공유하고, 여러 가지 액션 플랜을 논의했습니다.</li>
  <li>논의 결과, 결제 프로세스에서의 이탈률을 낮추기 위해 우선적으로 <strong>간편 결제 서비스인 PayPal Express Checkout 기능을 도입</strong>하기로 결정했습니다.</li>
  <li>이는 결제 단계를 단축하고 사용자에게 편리한 결제 경험을 제공하여 전환율을 높일 수 있는 가장 현실적이고 효율적인 방안으로 판단되었습니다.</li>
  <li>이후 해당 기능을 적용하여 사용자의 결제 과정에서 불편함을 최소화하고 보안 신뢰도를 높이는 등 UX 개선을 추진했습니다.</li>
</ul>

<h3 id="results">Results</h3>
<ul>
  <li>PayPal Express Checkout 기능 도입 후, 결제 과정에서 이탈하던 문제가 크게 개선되어 <strong><code class="language-plaintext highlighter-rouge">add_payment_info</code>에서 <code class="language-plaintext highlighter-rouge">purchase</code>로 넘어가는 전환율이 이전보다 32%p 상승</strong>했습니다.</li>
  <li>이 조치는 결제 프로세스를 간소화하고 사용자 경험을 향상시켜 전환율을 원상태로 회복시켰을 뿐만 아니라, <strong>현재까지도 높은 수준을 유지</strong>하고 있습니다.</li>
  <li>이 결과는 결제 옵션의 다양화와 간편 결제 도입이 효과적인 전략임을 입증하며, 분석을 바탕으로 한 문제 해결이 매출 성과에 긍정적인 영향을 미쳤습니다.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>
<blockquote>
  <ul>
    <li>2023년, 글로벌 시장 점유율 1위의 경쟁사가 사업적 논란에 휘말리면서 당사는 <strong>예상치 못한 매출 증가</strong>를 경험하게 되었습니다.</li>
    <li>이로 인해 자사몰의 신규 방문자가 급증했으며, 이는 당사 내부 마케팅 활동의 결과가 아닌 외부 시장 변화에 따른 현상으로 파악되었습니다.</li>
    <li>데이터 분석가로서 저는 이러한 비정상적인 시장 움직임을 깊이 있게 분석하기 위해 자발적으로 데이터 모니터링을 했고, 특히 <strong>신규 방문자들의 유입 경로와 구매 행동 패턴</strong>을 집중적으로 추적했습니다.</li>
  </ul>
</blockquote>

<h3 id="구체적인-상황">구체적인 상황</h3>
<ul>
  <li>2023년, 글로벌 시장 점유율 TOP1인 모 경쟁사가 사업적 논란에 크게 휩싸이면서 당사가 반사이익 수혜를 입어 자사몰 매출이 급증하고 있었습니다. 이는 내부적인 마케팅 활동의 결과가 아닌, 시장 자체의 외부 영향 덕분이었습니다.</li>
  <li>데이터 분석가였던 저 역시 “<strong>흔치 않은 시장의 흐름으로 인한 이상 현상</strong>“을 깊이 모니터링해보고 싶어 자발적으로 함께 데이터를 팔로업했습니다.</li>
</ul>

<h3 id="데이터-팔로업">데이터 팔로업</h3>

<ol>
  <li>신규 방문자 수가 급증했습니다.
    <details>
<summary>View Query</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">user_pseudo_id</span><span class="p">,</span>
         <span class="p">(</span><span class="k">SELECT</span> <span class="n">value</span><span class="p">.</span><span class="n">int_value</span> <span class="k">FROM</span> <span class="k">UNNEST</span> <span class="p">(</span><span class="n">event_params</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">key</span> <span class="o">=</span> <span class="s1">'ga_session_number'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ga_session_number</span>
      <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
      <span class="k">WHERE</span>
         <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
   <span class="p">),</span>

   <span class="n">CTE_users_min_gsn</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">user_pseudo_id</span><span class="p">,</span>
         <span class="k">MIN</span><span class="p">(</span><span class="n">ga_session_number</span><span class="p">)</span> <span class="k">AS</span> <span class="n">min_gsn</span>
      <span class="k">FROM</span>
         <span class="n">CTE_raw</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
   <span class="p">)</span>

   <span class="k">SELECT</span>
      <span class="n">event_date</span><span class="p">,</span>
      <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
   <span class="k">FROM</span>
      <span class="n">CTE_users_min_gsn</span>
   <span class="k">WHERE</span>
      <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
</details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/1.png" alt="" /></p>
  </li>
  <li>이들은 주로 미국과 Organic 트래픽을 통해 유입되었습니다.
    <ul>
      <li>신규 방문자 수 (국가별 분류)
        <details>
 <summary>View Query</summary>
 <div>
            <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">WITH</span>
 <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="n">user_pseudo_id</span><span class="p">,</span>
       <span class="p">(</span><span class="k">SELECT</span> <span class="n">value</span><span class="p">.</span><span class="n">int_value</span> <span class="k">FROM</span> <span class="k">UNNEST</span> <span class="p">(</span><span class="n">event_params</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">key</span> <span class="o">=</span> <span class="s1">'ga_session_number'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ga_session_number</span><span class="p">,</span>
       <span class="n">geo</span><span class="p">.</span><span class="n">country</span>
    <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
    <span class="k">WHERE</span>
       <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
 <span class="p">),</span>

 <span class="n">CTE_users_min_gsn</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="n">user_pseudo_id</span><span class="p">,</span>
       <span class="n">country</span><span class="p">,</span>
       <span class="k">MIN</span><span class="p">(</span><span class="n">ga_session_number</span><span class="p">)</span> <span class="k">AS</span> <span class="n">min_gsn</span>
    <span class="k">FROM</span>
       <span class="n">CTE_raw</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span>
 <span class="p">),</span>

 <span class="n">CTE_top20_countries</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">country</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
       <span class="n">CTE_users_min_gsn</span>
    <span class="k">WHERE</span>
       <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
       <span class="mi">2</span> <span class="k">DESC</span>
    <span class="k">LIMIT</span>
       <span class="mi">20</span>
 <span class="p">),</span>

 <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="k">CASE</span>
             <span class="k">WHEN</span> <span class="n">country</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">country</span> <span class="k">FROM</span> <span class="n">CTE_top20_countries</span><span class="p">)</span> <span class="k">THEN</span> <span class="n">country</span>
             <span class="k">ELSE</span> <span class="s1">'(Others)'</span>
       <span class="k">END</span> <span class="k">AS</span> <span class="n">country</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
       <span class="n">CTE_users_min_gsn</span>
    <span class="k">WHERE</span>
       <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
 <span class="p">)</span>

 <span class="k">SELECT</span>
    <span class="o">*</span>
 <span class="k">FROM</span>
    <span class="n">CTE_result</span>
 <span class="k">ORDER</span> <span class="k">BY</span>
    <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span> <span class="k">DESC</span>
</code></pre></div>            </div>
          </div>
 </details>
        <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/3.png" alt="" /></p>
      </li>
      <li>신규 방문자 수 (First UTM Parameters별 분류)
        <details>
 <summary>View Query</summary>
 <div>
            <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">WITH</span>
 <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="n">user_pseudo_id</span><span class="p">,</span>
       <span class="p">(</span><span class="k">SELECT</span> <span class="n">value</span><span class="p">.</span><span class="n">int_value</span> <span class="k">FROM</span> <span class="k">UNNEST</span> <span class="p">(</span><span class="n">event_params</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">key</span> <span class="o">=</span> <span class="s1">'ga_session_number'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ga_session_number</span><span class="p">,</span>
       <span class="n">traffic_source</span><span class="p">.</span><span class="n">name</span> <span class="k">AS</span> <span class="n">first_campaign</span><span class="p">,</span>
       <span class="n">traffic_source</span><span class="p">.</span><span class="n">medium</span> <span class="k">AS</span> <span class="n">first_medium</span><span class="p">,</span>
       <span class="n">traffic_source</span><span class="p">.</span><span class="k">source</span> <span class="k">AS</span> <span class="n">first_source</span>
    <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
    <span class="k">WHERE</span>
       <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
 <span class="p">),</span>

 <span class="n">CTE_users_min_gsn</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="n">user_pseudo_id</span><span class="p">,</span>
       <span class="n">first_campaign</span><span class="p">,</span>
       <span class="n">first_medium</span><span class="p">,</span>
       <span class="n">first_source</span><span class="p">,</span>
       <span class="k">MIN</span><span class="p">(</span><span class="n">ga_session_number</span><span class="p">)</span> <span class="k">AS</span> <span class="n">min_gsn</span>
    <span class="k">FROM</span>
       <span class="n">CTE_raw</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span>
 <span class="p">),</span>

 <span class="n">CTE_top20_utms</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_campaign</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_medium</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_source</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">utm</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
       <span class="n">CTE_users_min_gsn</span>
    <span class="k">WHERE</span>
       <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
       <span class="mi">2</span> <span class="k">DESC</span>
    <span class="k">LIMIT</span>
       <span class="mi">20</span>
 <span class="p">),</span>

 <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="k">CASE</span>
             <span class="k">WHEN</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_campaign</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_medium</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_source</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">utm</span> <span class="k">FROM</span> <span class="n">CTE_top20_utms</span><span class="p">)</span> <span class="k">THEN</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_campaign</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_medium</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_source</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span>
             <span class="k">ELSE</span> <span class="s1">'(Others)'</span>
       <span class="k">END</span> <span class="k">AS</span> <span class="n">utm</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
       <span class="n">CTE_users_min_gsn</span>
    <span class="k">WHERE</span>
       <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
 <span class="p">)</span>

 <span class="k">SELECT</span>
    <span class="o">*</span>
 <span class="k">FROM</span>
    <span class="n">CTE_result</span>
 <span class="k">ORDER</span> <span class="k">BY</span>
    <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span> <span class="k">DESC</span>
</code></pre></div>            </div>
          </div>
 </details>
        <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/4.png" alt="" /></p>
      </li>
    </ul>
  </li>
  <li>신규 방문자들의 구매 의향은 과거에 비해 매우 높은 편이었습니다.
    <details>
<summary>View Query</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">user_pseudo_id</span><span class="p">,</span>
         <span class="p">(</span><span class="k">SELECT</span> <span class="n">value</span><span class="p">.</span><span class="n">int_value</span> <span class="k">FROM</span> <span class="k">UNNEST</span> <span class="p">(</span><span class="n">event_params</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">key</span> <span class="o">=</span> <span class="s1">'ga_session_number'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ga_session_number</span><span class="p">,</span>
         <span class="n">event_name</span>
      <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
      <span class="k">WHERE</span>
         <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
   <span class="p">),</span>

<span class="n">CTE_users</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">event_date</span><span class="p">,</span>
      <span class="n">user_pseudo_id</span><span class="p">,</span>
      <span class="n">event_name</span><span class="p">,</span>
      <span class="k">MIN</span><span class="p">(</span><span class="n">ga_session_number</span><span class="p">)</span> <span class="k">AS</span> <span class="n">min_gsn</span>
   <span class="k">FROM</span>
      <span class="n">CTE_raw</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span>
<span class="p">),</span>

<span class="n">CTE_new_users</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">event_date</span><span class="p">,</span>
      <span class="n">user_pseudo_id</span>
   <span class="k">FROM</span>
      <span class="n">CTE_users</span>
   <span class="k">WHERE</span>
      <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span>

<span class="k">SELECT</span>
   <span class="n">U</span><span class="p">.</span><span class="n">event_date</span><span class="p">,</span>
   <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">NU</span><span class="p">.</span><span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">new_users_cnt</span><span class="p">,</span>
   <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">U</span><span class="p">.</span><span class="n">event_name</span> <span class="o">=</span> <span class="s1">'view_item'</span> <span class="k">THEN</span> <span class="n">NU</span><span class="p">.</span><span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">new_users_cnt_view_item</span><span class="p">,</span>
   <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">U</span><span class="p">.</span><span class="n">event_name</span> <span class="o">=</span> <span class="s1">'begin_checkout'</span> <span class="k">THEN</span> <span class="n">NU</span><span class="p">.</span><span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">new_users_cnt_begin_checkout</span>    
<span class="k">FROM</span>
   <span class="n">CTE_users</span> <span class="n">U</span>
<span class="k">LEFT</span> <span class="k">JOIN</span> 
   <span class="n">CTE_new_users</span> <span class="n">NU</span>
   <span class="k">ON</span> <span class="n">U</span><span class="p">.</span><span class="n">event_date</span> <span class="o">=</span> <span class="n">NU</span><span class="p">.</span><span class="n">event_date</span>
   <span class="k">AND</span> <span class="n">U</span><span class="p">.</span><span class="n">user_pseudo_id</span> <span class="o">=</span> <span class="n">NU</span><span class="p">.</span><span class="n">user_pseudo_id</span>
<span class="k">GROUP</span> <span class="k">BY</span>
   <span class="mi">1</span>
<span class="k">ORDER</span> <span class="k">BY</span>
   <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
</details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/2.png" alt="" /></p>
  </li>
</ol>

<h3 id="문제-발견">문제 발견</h3>

<ol>
  <li>그러나, 배송지+이메일+연락처 등 구매 관련 정보 입력을 완료한 후 결제 프로세스 상에서의 이탈률이 급격히 높아졌습니다.
    <details>
<summary>View Query</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">user_pseudo_id</span><span class="p">,</span>
         <span class="n">event_name</span>
      <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
      <span class="k">WHERE</span>
         <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
   <span class="p">),</span>

   <span class="n">CTE_funnel</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cnt</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'view_item'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_users_cnt</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'begin_checkout'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'add_payment_info'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'purchase'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_users_cnt</span>
      <span class="k">FROM</span>
         <span class="n">CTE_raw</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>

   <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">all_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cvr</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">view_item_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_cvr</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_cvr</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_cvr</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">purchase_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_cvr</span>
      <span class="k">FROM</span>
         <span class="n">CTE_funnel</span>
      <span class="k">ORDER</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">)</span>

   <span class="k">SELECT</span>
      <span class="o">*</span>
   <span class="k">FROM</span>
      <span class="n">CTE_result</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
</details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/5.png" alt="" /></p>

    <ul>
      <li>구매 전환 단계의 주요 이벤트는 다음과 같았습니다.
        <ul>
          <li><code class="language-plaintext highlighter-rouge">view_item</code>: 아이템 페이지를 조회한다.</li>
          <li><code class="language-plaintext highlighter-rouge">begin_checkout</code>: 구매를 시작한다.</li>
          <li><code class="language-plaintext highlighter-rouge">add_payment_info</code>: 배송지, 이메일, 연락처 등 구매 관련 정보 입력을 완료한 후 결제 프로세스로 넘어간다.</li>
          <li><code class="language-plaintext highlighter-rouge">purchase</code>: 최종 결제를 완료한 후 Thank You 페이지를 조회한다.</li>
        </ul>
      </li>
      <li>위 네 단계 중, <code class="language-plaintext highlighter-rouge">add_payment_info</code>로부터 <code class="language-plaintext highlighter-rouge">purchase</code>로 넘어가는 지점에서 전환율이 오히려 감소하고 있음을 확인하게 된 것입니다.</li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>신규 방문자 수가 급증한 상황에서 <strong>결제 프로세스의 이탈률이 높다는 문제</strong>를 발견했습니다.</li>
    <li>구체적으로 구매 퍼널의 각 단계에서 이탈 지점을 분석한 결과, 많은 고객들이 <strong>구매 정보를 입력한 후 결제 단계에서 이탈</strong>하는 것으로 나타났습니다.</li>
    <li>특히, <strong>결제 과정에서의 UX</strong>가 구매 전환에 큰 영향을 미친다는 점을 인지하고, 문제를 명확히 하여 사용자 경험을 개선할 필요가 있었습니다.</li>
    <li>또한, 이번 전환율 저하는 외부 요인에 의한 자연적 유입 사용자 증가와 세그먼트 변화와 관련이 있을 것으로 판단했습니다.</li>
  </ul>
</blockquote>

<h3 id="문제-구체화">문제 구체화</h3>

<ol>
  <li>결제 프로세스의 UX 개선이 필요했습니다.
    <ul>
      <li>구매 퍼널에서 이탈률이 높은 지점을 분석한 결과, 많은 고객들이 배송지, 이메일, 연락처 등 구매 정보를 입력했음에도 불구하고 결제 프로세스 상에서 크게 이탈하는 것으로 나타났습니다.</li>
      <li><strong>상당히 성가신 구매 정보 입력 과정까지 완료했다면, “구매 의향”이 매우 높은 심리 상태였을 텐데, 상당수가 이탈하고 만 것입니다.</strong></li>
      <li>이는 <strong>구매 의향 자체를 흔들어 놓을 만한 결제 프로세스 불만족</strong>을 느꼈을 가능성이 컸을 것입니다.</li>
    </ul>
  </li>
  <li>구체적으로는 다음 과정에서 이탈률이 매우 높았습니다.
    <ul>
      <li>아래 UI는 <code class="language-plaintext highlighter-rouge">add_payment_info</code> 이벤트 발생 직후 나타나는 PG사의 결제 프로세스입니다.</li>
      <li>이 프로세스 과정에서 결제를 완료하지 못하고 이탈하고 있었던 것입니다.
<img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/6.png" alt="" /></li>
    </ul>
  </li>
  <li>유입 사용자 세그먼트가 변했습니다.
    <ul>
      <li>
        <p>웹사이트 UI에는 변동이 전혀 없었는데도 불구하고 전환율이 갑자기 이전과 괴리된다면 세그먼트의 변동 때문인 것으로 판단했습니다.</p>

        <ul>
          <li>
            <p>그동안 마케팅 유입 활동에 반응하여 방문한 “<strong>인위적 유입</strong>“이 아니라, 이벤에는 시장의 영향으로 인해 Organic하게 방문한 “<strong>자연적 유입</strong>“이 주를 이루었기 때문입니다.
 <img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/4.png" alt="" /></p>
          </li>
          <li>
            <p>구매 의향 자체가 과거에 비해 높은 속성/행동 패턴을 지녔기 때문입니다. (이전보다 확연히 높아진 <strong>아이템 페이지 조회율</strong>)
 <img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/2.png" alt="" /></p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="4-actions">4. Actions</h1>
<blockquote>
  <ul>
    <li>발견된 문제를 바탕으로 결제 프로세스 개선을 위해 사내 구성원들과 문제를 공유하고, 여러 가지 액션 플랜을 논의했습니다.</li>
    <li>논의 결과, 결제 프로세스에서의 이탈률을 낮추기 위해 우선적으로 <strong>간편 결제 서비스인 PayPal Express Checkout 기능을 도입</strong>하기로 결정했습니다.</li>
    <li>이는 결제 단계를 단축하고 사용자에게 편리한 결제 경험을 제공하여 전환율을 높일 수 있는 가장 현실적이고 효율적인 방안으로 판단되었습니다.</li>
    <li>이후 해당 기능을 적용하여 사용자의 결제 과정에서 불편함을 최소화하고 보안 신뢰도를 높이는 등 UX 개선을 추진했습니다.</li>
  </ul>
</blockquote>

<h3 id="사내-공유">사내 공유</h3>
<ul>
  <li>문제를 구체화하여 우선 사내 구성원 분들께 해당 내용을 공유 드렸고, 많은 분들께서 이 문제에 대해 공감을 표현해주셨습니다.</li>
  <li>결국, 임원 분들 및 마케팅 팀원 분들과 함께 미팅을 하여 문제를 개선할 만한 <strong>액션 플랜을 논의</strong>하기 시작했습니다.
 <img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/7.png" alt="" /></li>
</ul>

<h3 id="데이터-분석의-한계">데이터 분석의 한계</h3>
<ul>
  <li>안타깝게도, <code class="language-plaintext highlighter-rouge">add_payment_info</code> 이벤트와 <code class="language-plaintext highlighter-rouge">purchase</code> 이벤트 사이에 발생한 사용자 행동까지는 데이터로 확인할 수 없었습니다.
    <ul>
      <li>당사가 사용 중인 이커머스 플랫폼의 Plan 하에서는 소스코드에 GTM 커스텀 이벤트 트리거를 삽입할 수 없었기 때문에 기본적인 GA4 이벤트 수집만 가능했기 때문입니다.</li>
    </ul>
  </li>
  <li>따라서 단순히 데이터만으로는 이 문제의 구체적인 원인을 해명할 수 없었습니다.</li>
  <li><strong>그래서 지금부터는 국내/해외 시장에 대한 안목이 높은 사내 구성원 분들의 직관적 판단이 중요해지기 시작했습니다.</strong></li>
</ul>

<h3 id="가설-설정">가설 설정</h3>

<ol>
  <li>깊은 논의 끝에, 다음과 같은 의견들이 공유되었습니다.
    <ul>
      <li><strong>가설 1</strong>: “결제 수단을 다양화해야 돼요. 잠재 구매 고객이 자신이 원하는 결제 수단을 찾지 못해 이탈했을 가능성이 클 거예요.”</li>
      <li><strong>가설 2</strong>: “간편 결제 서비스를 추가하는 건 어때요? 구매 의향이 줄어들기 전에 빠르게 결제가 마무리될 수 있을 거예요.”</li>
      <li><strong>가설 3</strong>: “가상자산 결제 방식을 지원하는 것도 고려해봐요. 우리 고객들의 특성상 선호도가 높을 것 같거든요.”</li>
      <li><strong>가설 4</strong>: “PG사의 결제 프로세스 UI를 개선해보는 것도 좋을 것 같아요.”</li>
    </ul>
  </li>
  <li>이 중, “<strong>간편 결제 서비스 추가하기</strong>“를 우선적으로 테스트하기로 결정했습니다.
    <ul>
      <li>실행 비용, 시장에 대한 안목 등 측면에서 현실적으로 가장 바람직한 액션이라고 느꼈기 때문입니다.</li>
    </ul>
  </li>
  <li>최종 가설 수립
    <blockquote>
      <p>“<strong>PayPal Express Checkout 기능을 도입하면 결제 프로세스 상에서의 전환율이 높아질 것이다!</strong>”</p>
    </blockquote>
  </li>
</ol>

<h3 id="액션-실행">액션 실행</h3>

<ol>
  <li>
    <p><strong>PayPal Express Checkout</strong>은 고객이 배송지, 이메일, 연락처는 물론, 신용카드 정보 조차도 일일이 입력하지 않은 상태에서, PayPal 로그인을 통해 기존에 저장된 정보를 토대로 빠르게 결제할 수 있는 기능입니다.</p>
  </li>
  <li>사실 당사는 연동된 PG사를 통해 이미 PayPal을 결제 수단을 제공하고 있었지만, 다음과 같은 불편함을 초래하고 있었던 것으로 추측했습니다.
    <ul>
      <li>“여러 가지 옵션 중 하나로만 표시되어 있으므로 눈에 잘 띄지 않았을 것이다.”</li>
      <li>“이미 배송지, 이메일, 연락처 정보를 입력했는데 다시 한 번 PayPal 로그인을 유도하는 것이 불필요한 시간 낭비로 느껴졌을 것이다.”
<img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/6.png" alt="" /></li>
    </ul>
  </li>
  <li>따라서 PayPal Express Checkout 기능을 다음의 측면에서 UX 향상 방법이라고 생각하게 되었습니다.
    <ul>
      <li><strong>고객의 구매 전환 단계를 단축하여 간편한 결제를 지원한다.</strong></li>
      <li><strong>개인정보를 일일이 입력하지 않아도 되므로, 보안에 대한 신뢰도를 높인다.</strong>
<img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/8.png" alt="" /></li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>PayPal Express Checkout 기능 도입 후, 결제 과정에서 이탈하던 문제가 크게 개선되어 <strong><code class="language-plaintext highlighter-rouge">add_payment_info</code>에서 <code class="language-plaintext highlighter-rouge">purchase</code>로 넘어가는 전환율이 이전보다 32%p 상승</strong>했습니다.</li>
    <li>이 조치는 결제 프로세스를 간소화하고 사용자 경험을 향상시켜 전환율을 원상태로 회복시켰을 뿐만 아니라, <strong>현재까지도 높은 수준을 유지</strong>하고 있습니다.</li>
    <li>이 결과는 결제 옵션의 다양화와 간편 결제 도입이 효과적인 전략임을 입증하며, 분석을 바탕으로 한 문제 해결이 매출 성과에 긍정적인 영향을 미쳤습니다.</li>
  </ul>
</blockquote>

<h3 id="결과">결과</h3>

<ul>
  <li>해당 액션을 실행한 후, <strong><code class="language-plaintext highlighter-rouge">add_payment_info</code>로부터 <code class="language-plaintext highlighter-rouge">purchase</code>로 넘어가는 지점의 전환율은 원상태로 회복되었을 뿐만 아니라 이전보다 훨씬 높은 수준을 기록했습니다.</strong></li>
  <li>2023년 8월말 현재까지도 여전히 높은 전환율 수준을 유지하고 있습니다.
    <details>
 <summary>View Query</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">WITH</span>
    <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">event_date</span><span class="p">,</span>
          <span class="n">user_pseudo_id</span><span class="p">,</span>
          <span class="n">event_name</span>
       <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
       <span class="k">WHERE</span>
          <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
    <span class="p">),</span>

    <span class="n">CTE_funnel</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">event_date</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'view_item'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'begin_checkout'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'add_payment_info'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'purchase'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_users_cnt</span>
       <span class="k">FROM</span>
          <span class="n">CTE_raw</span>
       <span class="k">GROUP</span> <span class="k">BY</span>
          <span class="mi">1</span>
    <span class="p">),</span>

    <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">event_date</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">all_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cvr</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">view_item_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_cvr</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_cvr</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_cvr</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">purchase_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_cvr</span>
       <span class="k">FROM</span>
          <span class="n">CTE_funnel</span>
       <span class="k">ORDER</span> <span class="k">BY</span>
          <span class="mi">1</span>
    <span class="p">)</span>

    <span class="k">SELECT</span>
       <span class="o">*</span>
    <span class="k">FROM</span>
       <span class="n">CTE_result</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
       <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
 </details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/9.png" alt="" /></p>
  </li>
</ul>

<h3 id="효과">효과</h3>

<ul>
  <li>해당 액션을 실행한 후, <strong><code class="language-plaintext highlighter-rouge">add_payment_info</code>로부터 <code class="language-plaintext highlighter-rouge">purchase</code>로 넘어가는 지점의 전환율은 기존에 비해 32%p 상승했습니다.</strong>
    <details>
 <summary>View Query</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">WITH</span>
    <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">event_date</span><span class="p">,</span>
          <span class="n">user_pseudo_id</span><span class="p">,</span>
          <span class="n">event_name</span>
       <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
       <span class="k">WHERE</span>
          <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
    <span class="p">),</span>

    <span class="n">CTE_funnel</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="k">CASE</span>
                <span class="k">WHEN</span> <span class="n">event_date</span> <span class="o">&lt;=</span> <span class="s1">'YYYY-MM-DD'</span> <span class="k">THEN</span> <span class="s1">'AS-IS'</span>
                <span class="k">ELSE</span> <span class="s1">'TO-BE'</span>
          <span class="k">END</span> <span class="k">AS</span> <span class="n">period</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'view_item'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'begin_checkout'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'add_payment_info'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'purchase'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_users_cnt</span>
       <span class="k">FROM</span>
          <span class="n">CTE_raw</span>
       <span class="k">GROUP</span> <span class="k">BY</span>
          <span class="mi">1</span>
    <span class="p">),</span>

    <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">period</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">purchase_users_cnt</span><span class="p">,</span> <span class="n">add_payment_info_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_cvr</span>
       <span class="k">FROM</span>
          <span class="n">CTE_funnel</span>
    <span class="p">)</span>

    <span class="k">SELECT</span>
       <span class="o">*</span>
    <span class="k">FROM</span>
       <span class="n">CTE_result</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
       <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
 </details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/10.png" alt="" /></p>
  </li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>

<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (Korean)" /><category term="Article (Project)" /><category term="Level (1. Beginner)" /><category term="Field (Data Analysis)" /><category term="Skills (SQL)" /><summary type="html"><![CDATA[“외부 요인으로 인해 증가한 신규 방문자 데이터를 분석하여 구매 전환율의 급상승을 달성했습니다. 데이터를 통해 신규 방문자 수와 이들의 구매 의향이 크게 증가했음을 발견했지만, 결제 단계에서 이탈률이 높다는 문제를 파악했습니다. 이에 결제 과정의 불편함이 주요 원인임을 가설로 설정하고, PayPal Express Checkout을 도입하여 사용자 경험을 개선했습니다. 그 결과, 결제 전환율이 32%p 상승하여 이전보다 훨씬 높은 수준을 기록했으며, 이는 지속적으로 유지되고 있습니다. 이를 통해 분석 기반의 문제 해결과 성과 향상을 이뤄냈습니다.”]]></summary></entry><entry><title type="html">Dramatic Increase in E-commerce Conversion Rates</title><link href="http://localhost:4000/how-we-dramatically-improved-conversion-rates-en/" rel="alternate" type="text/html" title="Dramatic Increase in E-commerce Conversion Rates" /><published>2024-08-29T00:00:00+09:00</published><updated>2024-08-29T00:00:00+09:00</updated><id>http://localhost:4000/how-we-dramatically-improved-conversion-rates-en</id><content type="html" xml:base="http://localhost:4000/how-we-dramatically-improved-conversion-rates-en/"><![CDATA[<blockquote>
  <p>“By analyzing the data of new visitors that increased due to external factors, I achieved a significant rise in purchase conversion rates. The data revealed a substantial increase in the number of new visitors and their purchasing intent, but also identified a high dropout rate at the payment stage. Based on the hypothesis that the inconvenience in the payment process was the main cause, I introduced PayPal Express Checkout to enhance user experience. As a result, the payment conversion rate increased by 32%p, reaching a much higher level than before, and this improvement has been sustained. This demonstrates effective problem-solving and performance enhancement based on data analysis.”</p>
</blockquote>

<hr />

<table>
  <thead>
    <tr>
      <th><strong>Performance Summary</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>- Conversion Rate (<code class="language-plaintext highlighter-rouge">add_payment_info</code> → <code class="language-plaintext highlighter-rouge">purchase</code>): 32%p ↑</td>
    </tr>
  </tbody>
</table>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>In 2023, our company experienced <strong>an unexpected increase in sales</strong> due to a major competitor, who holds the largest market share globally, becoming embroiled in business controversy.</li>
  <li>As a result, there was a surge in new visitors to our online store, which was identified as a phenomenon driven by changes in the external market, rather than the outcome of our internal marketing efforts.</li>
  <li>As a data analyst, I proactively monitored the data to deeply analyze these unusual market movements, focusing particularly on <strong>the acquisition channels and purchasing behavior patterns of new visitors.</strong></li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>In the context of a surge in new visitors, I discovered <strong>a high dropout rate in the payment process.</strong></li>
  <li>A detailed analysis of the dropout points at each stage of the purchase funnel revealed that many customers were <strong>abandoning their processes after entering their payment information.</strong></li>
  <li>Recognizing that <strong>UX in the payment process</strong> significantly affects purchase conversion, I identified a need to improve the user experience by clearly defining the problem.</li>
  <li>Additionally, I concluded that the decline in conversion rates might be related to the natural increase in organic user acquisition due to external factors and changes in user segments.</li>
</ul>

<h3 id="actions">Actions</h3>
<ul>
  <li>Based on the identified problem, I shared it with internal stakeholders and discussed several action plans to improve the payment process.</li>
  <li>As a result of the discussions, we decided to <strong>first introduce the easy payment service, PayPal Express Checkout</strong>, to reduce the dropout rate in the payment process.</li>
  <li>This was deemed the most realistic and effective solution to streamline the payment steps and provide a convenient payment experience to users, thereby increasing conversion rates.</li>
  <li>After implementing this feature, I focused on minimizing user discomfort during the payment process and enhancing security trustworthiness, thereby improving UX.</li>
</ul>

<h3 id="results">Results</h3>
<ul>
  <li>After introducing the PayPal Express Checkout feature, the dropout issue during the payment process significantly improved, and <strong>the conversion rate from <code class="language-plaintext highlighter-rouge">add_payment_info</code> to <code class="language-plaintext highlighter-rouge">purchase</code> increased by 32 percentage points compared to before.</strong></li>
  <li>This action not only restored the conversion rate to its original level by simplifying the payment process and improving the user experience but <strong>also maintained a high level to this day</strong>.</li>
  <li>This result demonstrates that diversifying payment options and introducing easy payment methods are effective strategies, showing that problem-solving based on data analysis has had a positive impact on sales performance.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>
<blockquote>
  <ul>
    <li>In 2023, our company experienced <strong>an unexpected increase in sales</strong> due to a major competitor, who holds the largest market share globally, becoming embroiled in business controversy.</li>
    <li>As a result, there was a surge in new visitors to our online store, which was identified as a phenomenon driven by changes in the external market, rather than the outcome of our internal marketing efforts.</li>
    <li>As a data analyst, I proactively monitored the data to deeply analyze these unusual market movements, focusing particularly on <strong>the acquisition channels and purchasing behavior patterns of new visitors.</strong></li>
  </ul>
</blockquote>

<h3 id="detailed-situation">Detailed Situation</h3>
<ul>
  <li>In 2023, a competitor with the top market share globally became heavily embroiled in business controversy, resulting in a windfall for our company, with a significant increase in sales on our own website. This was due to external market influences rather than the results of our internal marketing efforts.</li>
  <li>As a data analyst, I also wanted to deeply monitor and follow up on this “<strong>abnormal phenomenon caused by unusual market flows.</strong>”</li>
</ul>

<h3 id="data-follow-up">Data Follow-up</h3>

<ol>
  <li>The number of new visitors surged.
    <details>
<summary>View Query</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">user_pseudo_id</span><span class="p">,</span>
         <span class="p">(</span><span class="k">SELECT</span> <span class="n">value</span><span class="p">.</span><span class="n">int_value</span> <span class="k">FROM</span> <span class="k">UNNEST</span> <span class="p">(</span><span class="n">event_params</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">key</span> <span class="o">=</span> <span class="s1">'ga_session_number'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ga_session_number</span>
      <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
      <span class="k">WHERE</span>
         <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
   <span class="p">),</span>

   <span class="n">CTE_users_min_gsn</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">user_pseudo_id</span><span class="p">,</span>
         <span class="k">MIN</span><span class="p">(</span><span class="n">ga_session_number</span><span class="p">)</span> <span class="k">AS</span> <span class="n">min_gsn</span>
      <span class="k">FROM</span>
         <span class="n">CTE_raw</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
   <span class="p">)</span>

   <span class="k">SELECT</span>
      <span class="n">event_date</span><span class="p">,</span>
      <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
   <span class="k">FROM</span>
      <span class="n">CTE_users_min_gsn</span>
   <span class="k">WHERE</span>
      <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
</details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/1.png" alt="" /></p>
  </li>
  <li>These visitors primarily entered through organic traffic and from the United States.
    <ul>
      <li>Number of New Users (by Country)
        <details>
 <summary>View Query</summary>
 <div>
            <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">WITH</span>
 <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="n">user_pseudo_id</span><span class="p">,</span>
       <span class="p">(</span><span class="k">SELECT</span> <span class="n">value</span><span class="p">.</span><span class="n">int_value</span> <span class="k">FROM</span> <span class="k">UNNEST</span> <span class="p">(</span><span class="n">event_params</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">key</span> <span class="o">=</span> <span class="s1">'ga_session_number'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ga_session_number</span><span class="p">,</span>
       <span class="n">geo</span><span class="p">.</span><span class="n">country</span>
    <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
    <span class="k">WHERE</span>
       <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
 <span class="p">),</span>

 <span class="n">CTE_users_min_gsn</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="n">user_pseudo_id</span><span class="p">,</span>
       <span class="n">country</span><span class="p">,</span>
       <span class="k">MIN</span><span class="p">(</span><span class="n">ga_session_number</span><span class="p">)</span> <span class="k">AS</span> <span class="n">min_gsn</span>
    <span class="k">FROM</span>
       <span class="n">CTE_raw</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span>
 <span class="p">),</span>

 <span class="n">CTE_top20_countries</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">country</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
       <span class="n">CTE_users_min_gsn</span>
    <span class="k">WHERE</span>
       <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
       <span class="mi">2</span> <span class="k">DESC</span>
    <span class="k">LIMIT</span>
       <span class="mi">20</span>
 <span class="p">),</span>

 <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="k">CASE</span>
             <span class="k">WHEN</span> <span class="n">country</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">country</span> <span class="k">FROM</span> <span class="n">CTE_top20_countries</span><span class="p">)</span> <span class="k">THEN</span> <span class="n">country</span>
             <span class="k">ELSE</span> <span class="s1">'(Others)'</span>
       <span class="k">END</span> <span class="k">AS</span> <span class="n">country</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
       <span class="n">CTE_users_min_gsn</span>
    <span class="k">WHERE</span>
       <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
 <span class="p">)</span>

 <span class="k">SELECT</span>
    <span class="o">*</span>
 <span class="k">FROM</span>
    <span class="n">CTE_result</span>
 <span class="k">ORDER</span> <span class="k">BY</span>
    <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span> <span class="k">DESC</span>
</code></pre></div>            </div>
          </div>
 </details>
        <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/3.png" alt="" /></p>
      </li>
      <li>Number of New Users (by First UTM Parameters)
        <details>
 <summary>View Query</summary>
 <div>
            <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">WITH</span>
 <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="n">user_pseudo_id</span><span class="p">,</span>
       <span class="p">(</span><span class="k">SELECT</span> <span class="n">value</span><span class="p">.</span><span class="n">int_value</span> <span class="k">FROM</span> <span class="k">UNNEST</span> <span class="p">(</span><span class="n">event_params</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">key</span> <span class="o">=</span> <span class="s1">'ga_session_number'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ga_session_number</span><span class="p">,</span>
       <span class="n">traffic_source</span><span class="p">.</span><span class="n">name</span> <span class="k">AS</span> <span class="n">first_campaign</span><span class="p">,</span>
       <span class="n">traffic_source</span><span class="p">.</span><span class="n">medium</span> <span class="k">AS</span> <span class="n">first_medium</span><span class="p">,</span>
       <span class="n">traffic_source</span><span class="p">.</span><span class="k">source</span> <span class="k">AS</span> <span class="n">first_source</span>
    <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
    <span class="k">WHERE</span>
       <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
 <span class="p">),</span>

 <span class="n">CTE_users_min_gsn</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="n">user_pseudo_id</span><span class="p">,</span>
       <span class="n">first_campaign</span><span class="p">,</span>
       <span class="n">first_medium</span><span class="p">,</span>
       <span class="n">first_source</span><span class="p">,</span>
       <span class="k">MIN</span><span class="p">(</span><span class="n">ga_session_number</span><span class="p">)</span> <span class="k">AS</span> <span class="n">min_gsn</span>
    <span class="k">FROM</span>
       <span class="n">CTE_raw</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span>
 <span class="p">),</span>

 <span class="n">CTE_top20_utms</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_campaign</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_medium</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_source</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">utm</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
       <span class="n">CTE_users_min_gsn</span>
    <span class="k">WHERE</span>
       <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
       <span class="mi">2</span> <span class="k">DESC</span>
    <span class="k">LIMIT</span>
       <span class="mi">20</span>
 <span class="p">),</span>

 <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
    <span class="k">SELECT</span>
       <span class="n">event_date</span><span class="p">,</span>
       <span class="k">CASE</span>
             <span class="k">WHEN</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_campaign</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_medium</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_source</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="n">utm</span> <span class="k">FROM</span> <span class="n">CTE_top20_utms</span><span class="p">)</span> <span class="k">THEN</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_campaign</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_medium</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span> <span class="o">||</span> <span class="s1">' &gt; '</span> <span class="o">||</span> <span class="n">COALESCE</span><span class="p">(</span><span class="n">first_source</span><span class="p">,</span> <span class="s1">'(Unknown)'</span><span class="p">)</span>
             <span class="k">ELSE</span> <span class="s1">'(Others)'</span>
       <span class="k">END</span> <span class="k">AS</span> <span class="n">utm</span><span class="p">,</span>
       <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">users_cnt</span>
    <span class="k">FROM</span>
       <span class="n">CTE_users_min_gsn</span>
    <span class="k">WHERE</span>
       <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">GROUP</span> <span class="k">BY</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
 <span class="p">)</span>

 <span class="k">SELECT</span>
    <span class="o">*</span>
 <span class="k">FROM</span>
    <span class="n">CTE_result</span>
 <span class="k">ORDER</span> <span class="k">BY</span>
    <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span> <span class="k">DESC</span>
</code></pre></div>            </div>
          </div>
 </details>
        <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/4.png" alt="" /></p>
      </li>
    </ul>
  </li>
  <li>The purchasing intent of new visitors was significantly higher than in the past.
    <details>
<summary>View Query</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">user_pseudo_id</span><span class="p">,</span>
         <span class="p">(</span><span class="k">SELECT</span> <span class="n">value</span><span class="p">.</span><span class="n">int_value</span> <span class="k">FROM</span> <span class="k">UNNEST</span> <span class="p">(</span><span class="n">event_params</span><span class="p">)</span> <span class="k">WHERE</span> <span class="k">key</span> <span class="o">=</span> <span class="s1">'ga_session_number'</span><span class="p">)</span> <span class="k">AS</span> <span class="n">ga_session_number</span><span class="p">,</span>
         <span class="n">event_name</span>
      <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
      <span class="k">WHERE</span>
         <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
   <span class="p">),</span>

<span class="n">CTE_users</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">event_date</span><span class="p">,</span>
      <span class="n">user_pseudo_id</span><span class="p">,</span>
      <span class="n">event_name</span><span class="p">,</span>
      <span class="k">MIN</span><span class="p">(</span><span class="n">ga_session_number</span><span class="p">)</span> <span class="k">AS</span> <span class="n">min_gsn</span>
   <span class="k">FROM</span>
      <span class="n">CTE_raw</span>
   <span class="k">GROUP</span> <span class="k">BY</span>
      <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span>
<span class="p">),</span>

<span class="n">CTE_new_users</span> <span class="k">AS</span> <span class="p">(</span>
   <span class="k">SELECT</span>
      <span class="n">event_date</span><span class="p">,</span>
      <span class="n">user_pseudo_id</span>
   <span class="k">FROM</span>
      <span class="n">CTE_users</span>
   <span class="k">WHERE</span>
      <span class="n">min_gsn</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span>

<span class="k">SELECT</span>
   <span class="n">U</span><span class="p">.</span><span class="n">event_date</span><span class="p">,</span>
   <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">NU</span><span class="p">.</span><span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">new_users_cnt</span><span class="p">,</span>
   <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">U</span><span class="p">.</span><span class="n">event_name</span> <span class="o">=</span> <span class="s1">'view_item'</span> <span class="k">THEN</span> <span class="n">NU</span><span class="p">.</span><span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">new_users_cnt_view_item</span><span class="p">,</span>
   <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">U</span><span class="p">.</span><span class="n">event_name</span> <span class="o">=</span> <span class="s1">'begin_checkout'</span> <span class="k">THEN</span> <span class="n">NU</span><span class="p">.</span><span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">new_users_cnt_begin_checkout</span>    
<span class="k">FROM</span>
   <span class="n">CTE_users</span> <span class="n">U</span>
<span class="k">LEFT</span> <span class="k">JOIN</span> 
   <span class="n">CTE_new_users</span> <span class="n">NU</span>
   <span class="k">ON</span> <span class="n">U</span><span class="p">.</span><span class="n">event_date</span> <span class="o">=</span> <span class="n">NU</span><span class="p">.</span><span class="n">event_date</span>
   <span class="k">AND</span> <span class="n">U</span><span class="p">.</span><span class="n">user_pseudo_id</span> <span class="o">=</span> <span class="n">NU</span><span class="p">.</span><span class="n">user_pseudo_id</span>
<span class="k">GROUP</span> <span class="k">BY</span>
   <span class="mi">1</span>
<span class="k">ORDER</span> <span class="k">BY</span>
   <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
</details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/2.png" alt="" /></p>
  </li>
</ol>

<h3 id="problem-discovery">Problem Discovery</h3>

<ol>
  <li>However, there was a sharp increase in dropout rates in the payment process after completing the purchase-related information such as shipping address, email, and contact information.
    <details>
<summary>View Query</summary>
<div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="k">WITH</span>
   <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">user_pseudo_id</span><span class="p">,</span>
         <span class="n">event_name</span>
      <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
      <span class="k">WHERE</span>
         <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
   <span class="p">),</span>

   <span class="n">CTE_funnel</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cnt</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'view_item'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_users_cnt</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'begin_checkout'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'add_payment_info'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span>
         <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'purchase'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_users_cnt</span>
      <span class="k">FROM</span>
         <span class="n">CTE_raw</span>
      <span class="k">GROUP</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">),</span>

   <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
      <span class="k">SELECT</span>
         <span class="n">event_date</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">all_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cvr</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">view_item_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_cvr</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_cvr</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_cvr</span><span class="p">,</span>
         <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">purchase_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_cvr</span>
      <span class="k">FROM</span>
         <span class="n">CTE_funnel</span>
      <span class="k">ORDER</span> <span class="k">BY</span>
         <span class="mi">1</span>
   <span class="p">)</span>

   <span class="k">SELECT</span>
      <span class="o">*</span>
   <span class="k">FROM</span>
      <span class="n">CTE_result</span>
   <span class="k">ORDER</span> <span class="k">BY</span>
      <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
</details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/5.png" alt="" /></p>

    <ul>
      <li>The major events in the purchase conversion stages were as follows:
        <ul>
          <li><code class="language-plaintext highlighter-rouge">view_item</code>: Viewing the item page.</li>
          <li><code class="language-plaintext highlighter-rouge">begin_checkout</code>: Starting the purchase process.</li>
          <li><code class="language-plaintext highlighter-rouge">add_payment_info</code>: Completing the entry of purchase-related information such as shipping address, email, and contact information, the nproceeding to the payment process.</li>
          <li><code class="language-plaintext highlighter-rouge">purchase</code>: Completing the final payment and vewing the Thank you page.</li>
        </ul>
      </li>
      <li>Among these four stages, it was confirmed that there was a drop in conversion rates at the point of moving from <code class="language-plaintext highlighter-rouge">add_payment_info</code> to <code class="language-plaintext highlighter-rouge">purchase</code>.</li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="3-tasks">3. Tasks</h1>
<blockquote>
  <ul>
    <li>In the context of a surge in new visitors, I discovered <strong>a high dropout rate in the payment process.</strong></li>
    <li>A detailed analysis of the dropout points at each stage of the purchase funnel revealed that many customers were <strong>abandoning their processes after entering their payment information.</strong></li>
    <li>Recognizing that <strong>UX in the payment process</strong> significantly affects purchase conversion, I identified a need to improve the user experience by clearly defining the problem.</li>
    <li>Additionally, I concluded that the decline in conversion rates might be related to the natural increase in organic user acquisition due to external factors and changes in user segments.</li>
  </ul>
</blockquote>

<h3 id="clarifying-the-problem">Clarifying the Problem</h3>

<ol>
  <li>There was a need to improve the UX of the payment process.
    <ul>
      <li>An analysis of the points with high dropout rates in the purchase funnel revealed that many customers were abandoning their carts in the payment process, even after completing the entry of purchase-related information such as shipping address, email, and contact information.</li>
      <li><strong>Given that they had completed such a cumbersome process of entering purchase information, they must have been in a state of “high purchase intent,” yet a significant number still abandoned their carts.</strong></li>
      <li>This suggested a high possibility that <strong>the dissatisfaction with the payment process was strong enough to undermine the purchase intent itself.</strong></li>
    </ul>
  </li>
  <li>Specifically, the dropout rate was very high at the following stage:
    <ul>
      <li>The UI below appears right after the <code class="language-plaintext highlighter-rouge">add_payment_info</code> event occurs during the payment process by the payment gateway provider.</li>
      <li>Users were not completing the payment and abandoning their carts during this process.
<img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/6.png" alt="" /></li>
    </ul>
  </li>
  <li>The user segments of incoming visitors had changed.
    <ul>
      <li>
        <p>If the conversion rate suddenly diverges from the past without any changes to the website UI, it was determined that this was due to changes in user segments.</p>

        <ul>
          <li>
            <p>This was because it was primarily “<strong>natural inflow</strong>” caused by market influences, rather than the “<strong>artificial inflow</strong>” that previously visited in response to marketing activities.
 <img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/4.png" alt="" /></p>
          </li>
          <li>
            <p>It was due to the nature/behavior pattern with high purchase intent compared to the past (significantly increased <strong>item page view rate</strong> compared to before).
 <img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/2.png" alt="" /></p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="4-actions">4. Actions</h1>
<blockquote>
  <ul>
    <li>Based on the identified problem, I shared it with internal stakeholders and discussed several action plans to improve the payment process.</li>
    <li>As a result of the discussions, we decided to <strong>first introduce the easy payment service, PayPal Express Checkout</strong>, to reduce the dropout rate in the payment process.</li>
    <li>This was deemed the most realistic and effective solution to streamline the payment steps and provide a convenient payment experience to users, thereby increasing conversion rates.</li>
    <li>After implementing this feature, I focused on minimizing user discomfort during the payment process and enhancing security trustworthiness, thereby improving UX.</li>
  </ul>
</blockquote>

<h3 id="internal-sharing">Internal Sharing</h3>
<ul>
  <li>I clarified the problem and shared the details with internal stakeholders, and many expressed agreement with the issue.</li>
  <li>Eventually, I held a meeting with executives and marketing team members to <strong>discuss possible action plans</strong> to address the issue.
 <img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/7-eng.png" alt="" /></li>
</ul>

<h3 id="limitations-of-data-analysis">Limitations of Data Analysis</h3>
<ul>
  <li>Unfortunately, the user behavior that occurred between the <code class="language-plaintext highlighter-rouge">add_payment_info</code> event and the <code class="language-plaintext highlighter-rouge">purchase</code> event could not be confirmed through the data.
    <ul>
      <li>This was because, under the plan for the e-commerce platform we were using, only basic GA4 event collection was possible as we couldn’t insert GTM custom event triggers into the source code.</li>
    </ul>
  </li>
  <li>Therefore, it was not possible to explain the specific cause of this problem solely with data.</li>
  <li><strong>Therefore, moving forward, the intuitive judgment of internal stakeholders with insight into domestic and overseas markets became important.</strong></li>
</ul>

<h3 id="hypothesis-establishment">Hypothesis Establishment</h3>

<ol>
  <li>After deep discussions, the following opinions were shared:
    <ul>
      <li><strong>Hypothesis 1</strong>: “We need to diversify payment methods. Potential customers might have abandoned their carts because they couldn’t find their preferred payment method.”</li>
      <li><strong>Hypothesis 2</strong>: “How about adding an easy payment service? It could quickly complete the payment before the purchase intent declines.”</li>
      <li><strong>Hypothesis 3</strong>: “Consider supporting cryptocurrency payment methods. Given the characteristics of our customers, it could be highly preferred.”</li>
      <li><strong>Hypothesis 4</strong>: “Improving the UI of the payment gateway’s payment process might also be a good idea.”</li>
    </ul>
  </li>
  <li>Among these, we decided to first test “<strong>adding an easy payment service</strong>”.
    <ul>
      <li>This was considered the most feasible action in terms of implementation costs, market insights, etc.</li>
    </ul>
  </li>
  <li>Final Hypothesis Establishment
    <blockquote>
      <p>“<strong>Introducing the PayPal Express Checkout feature will increase the conversion rate in the payment process!</strong>”</p>
    </blockquote>
  </li>
</ol>

<h3 id="action-implementation">Action Implementation</h3>

<ol>
  <li>
    <p><strong>PayPal Express Checkout</strong> is a feature that allows customers to quickly complete a payment using information already stored through PayPal login, without needing to individually enter their shipping address, email, contact information, or even credit card details.</p>
  </li>
  <li>In fact, our company had already offered PayPal as a payment method through the linked payment gateway, but it was suspected that this caused the following inconveniences:
    <ul>
      <li>“It was only displayed as one of several options, so it might not have been easily noticeable.”</li>
      <li>“After entering shipping, email, and contact information, prompting for PayPal login again might have been perceived as an unnecessary waste of time.”
<img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/6.png" alt="" /></li>
    </ul>
  </li>
  <li>Therefore, the PayPal Express Checkout feature was considered a UX improvement method for the following reasons:
    <ul>
      <li><strong>It supports easy payments by shortening the customer’s purchase conversion steps.</strong></li>
      <li><strong>It enhances trust in security by eliminating the need to enter personal information individually.</strong>
<img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/8.png" alt="" /></li>
    </ul>
  </li>
</ol>

<hr />

<h1 id="5-results">5. Results</h1>
<blockquote>
  <ul>
    <li>After introducing the PayPal Express Checkout feature, the dropout issue during the payment process significantly improved, and <strong>the conversion rate from <code class="language-plaintext highlighter-rouge">add_payment_info</code> to <code class="language-plaintext highlighter-rouge">purchase</code> increased by 32 percentage points compared to before.</strong></li>
    <li>This action not only restored the conversion rate to its original level by simplifying the payment process and improving the user experience but <strong>also maintained a high level to this day</strong>.</li>
    <li>This result demonstrates that diversifying payment options and introducing easy payment methods are effective strategies, showing that problem-solving based on data analysis has had a positive impact on sales performance.</li>
  </ul>
</blockquote>

<h3 id="results-1">Results</h3>

<ul>
  <li>After executing the action, <strong>the conversion rate at the point of moving from <code class="language-plaintext highlighter-rouge">add_payment_info</code> to <code class="language-plaintext highlighter-rouge">purchase</code> not only recovered to its original state but also reached a much higher level than before.</strong></li>
  <li>As of the end of August 2023, it continues to maintain a high conversion rate.
    <details>
 <summary>View Query</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">WITH</span>
    <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">event_date</span><span class="p">,</span>
          <span class="n">user_pseudo_id</span><span class="p">,</span>
          <span class="n">event_name</span>
       <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
       <span class="k">WHERE</span>
          <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
    <span class="p">),</span>

    <span class="n">CTE_funnel</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">event_date</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'view_item'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'begin_checkout'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'add_payment_info'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'purchase'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_users_cnt</span>
       <span class="k">FROM</span>
          <span class="n">CTE_raw</span>
       <span class="k">GROUP</span> <span class="k">BY</span>
          <span class="mi">1</span>
    <span class="p">),</span>

    <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">event_date</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">all_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cvr</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">view_item_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_cvr</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_cvr</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_cvr</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">purchase_users_cnt</span><span class="p">,</span> <span class="n">all_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_cvr</span>
       <span class="k">FROM</span>
          <span class="n">CTE_funnel</span>
       <span class="k">ORDER</span> <span class="k">BY</span>
          <span class="mi">1</span>
    <span class="p">)</span>

    <span class="k">SELECT</span>
       <span class="o">*</span>
    <span class="k">FROM</span>
       <span class="n">CTE_result</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
       <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
 </details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/9.png" alt="" /></p>
  </li>
</ul>

<h3 id="impact">Impact</h3>

<ul>
  <li>After implementing the action, <strong>the conversion rate at the point of moving from <code class="language-plaintext highlighter-rouge">add_payment_info</code> to <code class="language-plaintext highlighter-rouge">purchase</code> increased by 32 percentage points compared to before.</strong>
    <details>
 <summary>View Query</summary>
 <div>
        <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">WITH</span>
    <span class="n">CTE_raw</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">event_date</span><span class="p">,</span>
          <span class="n">user_pseudo_id</span><span class="p">,</span>
          <span class="n">event_name</span>
       <span class="k">FROM</span> <span class="nv">`project_id.dataset_id.events_*`</span>
       <span class="k">WHERE</span>
          <span class="n">_table_suffix</span> <span class="k">BETWEEN</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'START DATE'</span><span class="p">)</span> <span class="k">AND</span> <span class="n">FORMAT_DATE</span><span class="p">(</span><span class="s1">'%Y%m%d'</span><span class="p">,</span> <span class="s1">'END DATE'</span><span class="p">)</span>
    <span class="p">),</span>

    <span class="n">CTE_funnel</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="k">CASE</span>
                <span class="k">WHEN</span> <span class="n">event_date</span> <span class="o">&lt;=</span> <span class="s1">'YYYY-MM-DD'</span> <span class="k">THEN</span> <span class="s1">'AS-IS'</span>
                <span class="k">ELSE</span> <span class="s1">'TO-BE'</span>
          <span class="k">END</span> <span class="k">AS</span> <span class="n">period</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="n">user_pseudo_id</span><span class="p">)</span> <span class="k">AS</span> <span class="n">all_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'view_item'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">view_item_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'begin_checkout'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">begin_checkout_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'add_payment_info'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">add_payment_info_users_cnt</span><span class="p">,</span>
          <span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span> <span class="k">CASE</span> <span class="k">WHEN</span> <span class="n">event_name</span> <span class="o">=</span> <span class="s1">'purchase'</span> <span class="k">THEN</span> <span class="n">user_pseudo_id</span> <span class="k">END</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_users_cnt</span>
       <span class="k">FROM</span>
          <span class="n">CTE_raw</span>
       <span class="k">GROUP</span> <span class="k">BY</span>
          <span class="mi">1</span>
    <span class="p">),</span>

    <span class="n">CTE_result</span> <span class="k">AS</span> <span class="p">(</span>
       <span class="k">SELECT</span>
          <span class="n">period</span><span class="p">,</span>
          <span class="n">SAFE_DIVIDE</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">purchase_users_cnt</span><span class="p">,</span> <span class="n">add_payment_info_users_cnt</span><span class="p">)</span> <span class="k">AS</span> <span class="n">purchase_cvr</span>
       <span class="k">FROM</span>
          <span class="n">CTE_funnel</span>
    <span class="p">)</span>

    <span class="k">SELECT</span>
       <span class="o">*</span>
    <span class="k">FROM</span>
       <span class="n">CTE_result</span>
    <span class="k">ORDER</span> <span class="k">BY</span>
       <span class="mi">1</span>
</code></pre></div>        </div>
      </div>
 </details>
    <p><img src="/assets/2024-08-29-how-we-dramatically-improved-conversion-rates/10.png" alt="" /></p>
  </li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>

<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (English)" /><category term="Article (Project)" /><category term="Level (1. Beginner)" /><category term="Field (Data Analysis)" /><category term="Skills (SQL)" /><summary type="html"><![CDATA[“By analyzing the data of new visitors that increased due to external factors, I achieved a significant rise in purchase conversion rates. The data revealed a substantial increase in the number of new visitors and their purchasing intent, but also identified a high dropout rate at the payment stage. Based on the hypothesis that the inconvenience in the payment process was the main cause, I introduced PayPal Express Checkout to enhance user experience. As a result, the payment conversion rate increased by 32%p, reaching a much higher level than before, and this improvement has been sustained. This demonstrates effective problem-solving and performance enhancement based on data analysis.”]]></summary></entry><entry><title type="html">Query Optimization by Using JOIN Instead of NOT IN</title><link href="http://localhost:4000/join-instead-of-not-in-en/" rel="alternate" type="text/html" title="Query Optimization by Using JOIN Instead of NOT IN" /><published>2024-08-13T00:00:00+09:00</published><updated>2024-08-13T00:00:00+09:00</updated><id>http://localhost:4000/join-instead-of-not-in-en</id><content type="html" xml:base="http://localhost:4000/join-instead-of-not-in-en/"><![CDATA[<blockquote>
  <p>“In this project, I optimized the incremental update strategy for the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table to address query performance issues in our Enterprise Data Warehouse (EDW) environment. By replacing the inefficient <code class="language-plaintext highlighter-rouge">NOT IN</code> clause with a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>, I streamlined the duplicate data check process, reducing the overall orchestration time from 50 minutes to 2 minutes. This resulted in approximately a 96% performance improvement, significantly enhancing data processing efficiency and system resource utilization, thereby strengthening service stability and scalability.”</p>
</blockquote>

<hr />

<table>
  <thead>
    <tr>
      <th><strong>Performance Summary</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>- Orchestration Time: <code class="language-plaintext highlighter-rouge">50 mins</code> → <code class="language-plaintext highlighter-rouge">2 mins</code> (96% ↓)</td>
    </tr>
  </tbody>
</table>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>In our Enterprise Data Warehouse (EDW), <strong>the orchestration process of the ELT pipeline was taking significantly longer than expected.</strong> Specifically, there were performance issues during the update process of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li>The goal was to optimize the incremental strategy of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table to <strong>reduce the overall orchestration time</strong>. This would enable us to handle increasing data traffic more efficiently and enhance service reliability.</li>
</ul>

<h3 id="actions">Actions</h3>
<ul>
  <li>I <strong>replaced the <code class="language-plaintext highlighter-rouge">NOT IN</code> clause with a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code></strong> to effectively filter duplicate data while optimizing performance.</li>
</ul>

<h3 id="results">Results</h3>
<ul>
  <li>Through query optimization, the total orchestration time was <strong>reduced from 50 minutes to 2 minutes</strong>, achieving approximately <strong>96% performance improvement</strong> and significantly enhancing data processing efficiency.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>In our Enterprise Data Warehouse (EDW), <strong>the orchestration process of the ELT pipeline was taking significantly longer than expected.</strong> Specifically, there were performance issues during the update process of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/1.webp" alt="" /></p>

<h3 id="specific-situation">Specific Situation</h3>
<ul>
  <li>Our company operates an Enterprise Data Warehouse (EDW) environment to provide B2B BI services. Every midnight, a complex data transformation process based on user event data is performed. <strong>However, this process was taking longer than expected.</strong> In particular, <strong>the incremental update process of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table, a key event table</strong>, was taking up most of the orchestration time. This delay in data refresh posed a risk of negatively impacting service quality.</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>

<blockquote>
  <ul>
    <li>The goal was to optimize the incremental strategy of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table to <strong>reduce the overall orchestration time</strong>. This would enable us to handle increasing data traffic more efficiently and enhance service reliability.</li>
  </ul>
</blockquote>

<h3 id="root-causes-of-the-problem">Root Causes of the Problem</h3>
<ul>
  <li>I identified three major issues in the update process of the <code class="language-plaintext highlighter-rouge">core_fct_events</code> table.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">WITH</span>
    <span class="n">CTE_src_events</span> <span class="k">AS</span> <span class="p">(</span>
        <span class="k">SELECT</span>
            <span class="k">DISTINCT</span>
            <span class="nb">datetime</span><span class="p">,</span>
            <span class="n">app_id</span><span class="p">,</span>
            <span class="n">user_id</span><span class="p">,</span>
            <span class="n">event_name</span>
        <span class="k">FROM</span>
            <span class="n">src_events</span>
        <span class="c1">-- Incremental Strategy: Read rows with a datetime greater than the maximum datetime currently stored in the table.</span>
        <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
        <span class="k">WHERE</span>
            <span class="p">(</span><span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="nb">datetime</span><span class="p">)</span> <span class="k">FROM</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span> <span class="o">&lt;</span> <span class="nb">datetime</span>
        <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">SELECT</span>
        <span class="o">*</span>
    <span class="k">FROM</span>
        <span class="n">CTE_src_events</span>
    <span class="c1">-- Incremental Strategy: Exclude data that already exists in the table. Do not insert those rows.</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">WHERE</span>
        <span class="p">(</span><span class="nb">datetime</span><span class="p">,</span> <span class="n">app_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">event_name</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="nb">datetime</span><span class="p">,</span> <span class="n">app_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">event_name</span> <span class="k">FROM</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="1-large-data-volume">1. Large Data Volume</h5>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">core_fct_events</code> table contained all user event log data, making the table size very large.</li>
</ul>

<h5 id="2-presence-of-duplicate-rows">2. Presence of Duplicate Rows</h5>
<ul>
  <li>Due to the existence of duplicate data in the source table itself, the <code class="language-plaintext highlighter-rouge">DISTINCT</code> keyword had to be used to remove duplicates.</li>
</ul>

<h5 id="3-inefficient-duplicate-check-method">3. Inefficient Duplicate Check Method</h5>
<ul>
  <li>The existing query used the <code class="language-plaintext highlighter-rouge">NOT IN</code> clause to compare new data with existing data, which was the main cause of the performance bottleneck. This clause triggers nested loop searches, causing performance degradation as the table size increases.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ul>
    <li><strong>I replaced the <code class="language-plaintext highlighter-rouge">NOT IN</code> clause with a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code></strong> to effectively filter duplicate data while optimizing performance.</li>
  </ul>
</blockquote>

<h3 id="specific-actions-taken">Specific Actions Taken</h3>

<h5 id="1-problem-analysis-and-alternative-exploration">1. Problem Analysis and Alternative Exploration</h5>
<ul>
  <li>First, I identified that the <code class="language-plaintext highlighter-rouge">NOT IN</code> clause was the primary cause of the performance bottleneck. The <code class="language-plaintext highlighter-rouge">NOT IN</code> clause requires the database engine to check all possible combinations through <strong>nested loops</strong>, making it highly inefficient.</li>
</ul>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/2.webp" alt="" /></p>

<h5 id="2-query-refactoring">2. Query Refactoring</h5>
<ul>
  <li>I replaced the existing <code class="language-plaintext highlighter-rouge">NOT IN</code> clause with a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>. Using a <code class="language-plaintext highlighter-rouge">LEFT JOIN</code> allows for more efficient comparison between the existing table and the new data. Specifically, <strong>after performing the <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>, only new data that does not exist in the existing data is inserted by filtering for <code class="language-plaintext highlighter-rouge">NULL</code> values.</strong></li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="n">MAIN</span><span class="p">.</span><span class="o">*</span>
    <span class="k">FROM</span> 
        <span class="n">CTE_src_events</span> <span class="n">MAIN</span>
    <span class="c1">-- Incremental Strategy: Exclude data that already exists in the table. Do not insert those rows.</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
        <span class="p">{{</span> <span class="n">this</span> <span class="p">}}</span> <span class="n">THIS</span>
        <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">datetime</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="nb">datetime</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">app_id</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">app_id</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">user_id</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_name</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">event_name</span>
    <span class="k">WHERE</span>
        <span class="n">THIS</span><span class="p">.</span><span class="nb">datetime</span> <span class="k">IS</span> <span class="k">NULL</span>    
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="3-performance-testing-and-validation">3. Performance Testing and Validation</h5>
<ul>
  <li>After modifying the query, I conducted performance tests using various data sets. This confirmed that the query execution time was significantly reduced. <strong>The optimized query execution time was reduced from 50 minutes to approximately 2 minutes.</strong></li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>

<blockquote>
  <ul>
    <li>Through query optimization, the total orchestration time was <strong>reduced from 50 minutes to 2 minutes</strong>, achieving approximately <strong>96% performance improvement</strong> and significantly enhancing data processing efficiency.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/3.webp" alt="" /></p>

<h3 id="1-performance-improvement">1. Performance Improvement</h3>
<ul>
  <li>The total orchestration time was reduced <strong>from 50 minutes to 2 minutes</strong>, representing approximately <strong>96% performance improvement</strong>, drastically enhancing data processing speed.</li>
</ul>

<h3 id="2-improved-resource-efficiency">2. Improved Resource Efficiency</h3>
<ul>
  <li>Efficient use of database resources reduced system load, allowing other queries and tasks to execute more smoothly.</li>
</ul>

<h3 id="3-enhanced-service-reliability">3. Enhanced Service Reliability</h3>
<ul>
  <li>Faster and more reliable data updates provided a more dependable service to users.</li>
</ul>

<h3 id="4-future-scalability-secured">4. Future Scalability Secured</h3>
<ul>
  <li>The optimization efforts in preparation for increased traffic and data expansion have laid a foundation for easily meeting future data processing requirements.</li>
</ul>

<h3 id="conclusion">Conclusion</h3>
<ul>
  <li>This query optimization project significantly enhanced the performance of our data warehouse while also strengthening our analytics engineering capabilities. It was a valuable contribution to maximizing data processing efficiency and improving the quality of our BI services.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (English)" /><category term="Article (Issue Resolution)" /><category term="Level (2. Intermediate)" /><category term="Field (Analytics Engineering)" /><category term="Skills (SQL)" /><category term="Skills (dbt)" /><summary type="html"><![CDATA[“In this project, I optimized the incremental update strategy for the core_fct_events table to address query performance issues in our Enterprise Data Warehouse (EDW) environment. By replacing the inefficient NOT IN clause with a LEFT JOIN, I streamlined the duplicate data check process, reducing the overall orchestration time from 50 minutes to 2 minutes. This resulted in approximately a 96% performance improvement, significantly enhancing data processing efficiency and system resource utilization, thereby strengthening service stability and scalability.”]]></summary></entry><entry><title type="html">NOT IN 대신 JOIN을 통한 쿼리 최적화</title><link href="http://localhost:4000/join-instead-of-not-in-ko/" rel="alternate" type="text/html" title="NOT IN 대신 JOIN을 통한 쿼리 최적화" /><published>2024-08-13T00:00:00+09:00</published><updated>2024-08-13T00:00:00+09:00</updated><id>http://localhost:4000/join-instead-of-not-in-ko</id><content type="html" xml:base="http://localhost:4000/join-instead-of-not-in-ko/"><![CDATA[<blockquote>
  <p>“이번 프로젝트에서는 엔터프라이즈 데이터 웨어하우스(EDW) 환경에서 발생한 쿼리 성능 문제를 해결하기 위해, <code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 Incremental 업데이트 전략을 최적화했습니다. 기존의 비효율적인 <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>으로 대체하여 데이터 중복 검사를 최적화함으로써, 오케스트레이션 전체 소요 시간을 50분에서 2분으로 단축했습니다. 이로 인해 약 96%의 성능 개선을 이루었으며, 데이터 처리 효율성과 시스템 자원 활용도를 크게 향상시켜 서비스의 안정성과 확장성을 강화했습니다.”</p>
</blockquote>

<hr />

<table>
  <thead>
    <tr>
      <th><strong>Performance Summary</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>- 오케스트레이션 소요 시간: <code class="language-plaintext highlighter-rouge">50분</code> → <code class="language-plaintext highlighter-rouge">2분</code> (96% ↓)</td>
    </tr>
  </tbody>
</table>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>STAR Summary</li>
  <li>Situation</li>
  <li>Tasks</li>
  <li>Actions</li>
  <li>Results</li>
</ol>

<hr />

<h1 id="1-star-summary">1. STAR Summary</h1>

<h3 id="situation">Situation</h3>
<ul>
  <li>엔터프라이즈 데이터 웨어하우스(EDW)에서 <strong>ELT 파이프라인의 오케스트레이션 작업이 예상보다 많은 시간을 소요</strong>하고 있었습니다. 특히, <code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 업데이트 과정에서 성능 문제가 발생하고 있었습니다.</li>
</ul>

<h3 id="tasks">Tasks</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 Incremental Strategy를 개선하여 오케스트레이션 작업의 <strong>전체 소요 시간을 줄이는 것</strong>을 목표로 삼았습니다. 이를 통해 증가하는 데이터 트래픽을 원활하게 처리하고, 서비스의 신뢰성을 높이려 했습니다.</li>
</ul>

<h3 id="actions">Actions</h3>
<ul>
  <li>쿼리 성능을 저하시키던 <strong><code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>으로 변경</strong>하여, 중복 데이터를 효과적으로 필터링하는 동시에 성능을 최적화했습니다.</li>
</ul>

<h3 id="results">Results</h3>
<ul>
  <li>쿼리 최적화를 통해 오케스트레이션 전체 소요 시간이 <strong>50분에서 2분으로 대폭 감소</strong>했습니다. 이는 약 <strong>96%의 성능 개선</strong>을 의미하며, 데이터 처리 효율성을 크게 향상시켰습니다.</li>
</ul>

<hr />

<h1 id="2-situation">2. Situation</h1>

<blockquote>
  <ul>
    <li>엔터프라이즈 데이터 웨어하우스(EDW)에서 <strong>ELT 파이프라인의 오케스트레이션 작업이 예상보다 많은 시간을 소요</strong>하고 있었습니다. 특히, <code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 업데이트 과정에서 성능 문제가 발생하고 있었습니다.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/1.webp" alt="" /></p>

<h3 id="구체적인-상황">구체적인 상황</h3>
<ul>
  <li>회사에서 B2B BI 서비스를 제공하기 위해 엔터프라이즈 데이터 웨어하우스(EDW) 환경을 운영하고 있었습니다. 매일 자정 무렵, 사용자 이벤트 데이터를 기반으로 한 복잡한 데이터 변환(Transformation) 작업이 수행되고 있었습니다. <strong>그러나 이 과정에서 예상보다 시간이 오래 걸리는 문제</strong>가 발생했습니다. 특히, <strong><code class="language-plaintext highlighter-rouge">core_fct_events</code>라는 주요 이벤트 테이블의 Incremental 업데이트 과정</strong>이 전체 오케스트레이션 시간의 대부분을 차지하고 있었습니다. 이로 인해 데이터 갱신이 지연되고, 서비스 품질에 부정적인 영향을 줄 우려가 있었습니다.</li>
</ul>

<hr />

<h1 id="3-tasks">3. Tasks</h1>

<blockquote>
  <ul>
    <li><code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 Incremental Strategy를 개선하여 오케스트레이션 작업의 <strong>전체 소요 시간을 줄이는 것</strong>을 목표로 삼았습니다. 이를 통해 증가하는 데이터 트래픽을 원활하게 처리하고, 서비스의 신뢰성을 높이려 했습니다.</li>
  </ul>
</blockquote>

<h3 id="문제의-근본-원인">문제의 근본 원인</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블의 업데이트 과정에서 발생하는 세 가지 주요 문제를 확인했습니다.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">WITH</span>
    <span class="n">CTE_src_events</span> <span class="k">AS</span> <span class="p">(</span>
        <span class="k">SELECT</span>
            <span class="k">DISTINCT</span>
            <span class="nb">datetime</span><span class="p">,</span>
            <span class="n">app_id</span><span class="p">,</span>
            <span class="n">user_id</span><span class="p">,</span>
            <span class="n">event_name</span>
        <span class="k">FROM</span>
            <span class="n">src_events</span>
        <span class="c1">-- Incremental Strategy: Read rows with a datetime greater than the maximum datetime currently stored in the table.</span>
        <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
        <span class="k">WHERE</span>
            <span class="p">(</span><span class="k">SELECT</span> <span class="k">MAX</span><span class="p">(</span><span class="nb">datetime</span><span class="p">)</span> <span class="k">FROM</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span> <span class="o">&lt;</span> <span class="nb">datetime</span>
        <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">SELECT</span>
        <span class="o">*</span>
    <span class="k">FROM</span>
        <span class="n">CTE_src_events</span>
    <span class="c1">-- Incremental Strategy: Exclude data that already exists in the table. Do not insert those rows.</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">WHERE</span>
        <span class="p">(</span><span class="nb">datetime</span><span class="p">,</span> <span class="n">app_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">event_name</span><span class="p">)</span> <span class="k">NOT</span> <span class="k">IN</span> <span class="p">(</span><span class="k">SELECT</span> <span class="nb">datetime</span><span class="p">,</span> <span class="n">app_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">event_name</span> <span class="k">FROM</span> <span class="p">{{</span> <span class="n">this</span> <span class="p">}})</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="1-데이터의-대용량성">1. 데이터의 대용량성</h5>
<ul>
  <li><code class="language-plaintext highlighter-rouge">core_fct_events</code> 테이블은 모든 사용자 이벤트 로그 데이터를 포함하고 있어 테이블 크기가 매우 컸습니다.</li>
</ul>

<h5 id="2-중복-데이터의-존재">2. 중복 데이터의 존재</h5>
<ul>
  <li>소스 테이블 자체에 중복 데이터가 존재하므로 <code class="language-plaintext highlighter-rouge">DISTINCT</code> 키워드를 사용해 중복 제거를 해야 했습니다.</li>
</ul>

<h5 id="3-비효율적인-중복-검사-방법">3. 비효율적인 중복 검사 방법</h5>
<ul>
  <li>기존 쿼리에서 <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 사용하여 새로운 데이터와 기존 데이터를 비교하는 작업이 성능 병목의 주된 원인이었습니다. 이 구문은 Nested Loop 검색을 유발하여 테이블이 커질수록 성능이 저하될 수밖에 없었습니다.</li>
</ul>

<hr />

<h1 id="4-actions">4. Actions</h1>

<blockquote>
  <ul>
    <li>쿼리 성능을 저하시키던 <strong><code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>으로 변경</strong>하여, 중복 데이터를 효과적으로 필터링하는 동시에 성능을 최적화했습니다.</li>
  </ul>
</blockquote>

<h3 id="구체적인-조치-사항">구체적인 조치 사항</h3>

<h5 id="1-문제-분석-및-대안-탐색">1. 문제 분석 및 대안 탐색</h5>
<ul>
  <li>먼저 기존의 <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문이 성능 병목을 일으키는 주요 원인임을 확인했습니다. <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문은 데이터베이스 엔진이 <strong>Nested Loop</strong>를 통해 모든 가능한 조합을 확인해야 하므로, 매우 비효율적입니다.</li>
</ul>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/2.webp" alt="" /></p>

<h5 id="2-쿼리-리팩토링">2. 쿼리 리팩토링</h5>
<ul>
  <li>기존 <code class="language-plaintext highlighter-rouge">NOT IN</code> 구문을 <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>으로 변경했습니다. <code class="language-plaintext highlighter-rouge">LEFT JOIN</code>을 사용하면 기존 테이블과 새 데이터 간의 비교를 보다 효율적으로 수행할 수 있습니다. 구체적으로, <strong><code class="language-plaintext highlighter-rouge">LEFT JOIN</code> 후 <code class="language-plaintext highlighter-rouge">NULL</code> 값을 필터링하여 기존 데이터에 없는 새로운 데이터만 삽입</strong>하도록 했습니다.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="n">MAIN</span><span class="p">.</span><span class="o">*</span>
    <span class="k">FROM</span> 
        <span class="n">CTE_src_events</span> <span class="n">MAIN</span>
    <span class="c1">-- Incremental Strategy: Exclude data that already exists in the table. Do not insert those rows.</span>
    <span class="p">{</span><span class="o">%</span> <span class="n">if</span> <span class="n">is_incremental</span><span class="p">()</span> <span class="o">%</span><span class="p">}</span>
    <span class="k">LEFT</span> <span class="k">JOIN</span>
        <span class="p">{{</span> <span class="n">this</span> <span class="p">}}</span> <span class="n">THIS</span>
        <span class="k">ON</span> <span class="n">MAIN</span><span class="p">.</span><span class="nb">datetime</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="nb">datetime</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">app_id</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">app_id</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">user_id</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">user_id</span>
        <span class="k">AND</span> <span class="n">MAIN</span><span class="p">.</span><span class="n">event_name</span> <span class="o">=</span> <span class="n">THIS</span><span class="p">.</span><span class="n">event_name</span>
    <span class="k">WHERE</span>
        <span class="n">THIS</span><span class="p">.</span><span class="nb">datetime</span> <span class="k">IS</span> <span class="k">NULL</span>    
    <span class="p">{</span><span class="o">%</span> <span class="n">endif</span> <span class="o">%</span><span class="p">}</span>
</code></pre></div></div>

<h5 id="3-성능-테스트-및-검증">3. 성능 테스트 및 검증</h5>
<ul>
  <li>쿼리 변경 후, 다양한 데이터 세트를 사용하여 성능 테스트를 진행했습니다. 이를 통해 쿼리 실행 시간이 크게 단축되었음을 확인하였습니다. <strong>최적화된 쿼리 실행 시간은 기존의 50분에서 약 2분으로 줄어들었습니다.</strong></li>
</ul>

<hr />

<h1 id="5-results">5. Results</h1>

<blockquote>
  <ul>
    <li>쿼리 최적화를 통해 오케스트레이션 전체 소요 시간이 <strong>50분에서 2분으로 대폭 감소</strong>했습니다. 이는 약 <strong>96%의 성능 개선</strong>을 의미하며, 데이터 처리 효율성을 크게 향상시켰습니다.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-13-join-instead-of-not-in/3.webp" alt="" /></p>

<h3 id="1-성능-개선">1. 성능 개선</h3>
<ul>
  <li>오케스트레이션 전체 소요 시간이 <strong>50분에서 2분으로</strong> 대폭 감소했습니다. 이는 약 <strong>96%의 성능 개선</strong>으로, 데이터 처리 속도를 획기적으로 향상시켰습니다.</li>
</ul>

<h3 id="2-리소스-효율성-향상">2. 리소스 효율성 향상</h3>
<ul>
  <li>데이터베이스 자원의 효율적인 사용을 통해 시스템 부하가 감소하였으며, 이로 인해 다른 쿼리 및 작업도 더욱 원활하게 실행될 수 있었습니다.</li>
</ul>

<h3 id="3-서비스-신뢰성-강화">3. 서비스 신뢰성 강화</h3>
<ul>
  <li>데이터 갱신이 빠르고 안정적으로 이루어짐으로써 사용자에게 보다 신뢰성 있는 서비스를 제공할 수 있었습니다.</li>
</ul>

<h3 id="4-미래-확장성-확보">4. 미래 확장성 확보</h3>
<ul>
  <li>트래픽 증가와 데이터 확장에 대비한 최적화 작업을 통해, 향후 데이터 처리 요구 사항을 보다 쉽게 충족할 수 있는 기반을 마련했습니다.</li>
</ul>

<h3 id="결론">결론</h3>
<ul>
  <li>이번 쿼리 최적화 프로젝트는 데이터 웨어하우스의 성능을 크게 향상시키는 동시에, 애널리틱스 엔지니어링 역량을 한층 강화하는 계기가 되었습니다. 데이터 처리 효율성을 극대화하고, BI 서비스의 품질을 높이는 데 중요한 기여를 했습니다.</li>
</ul>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (Korean)" /><category term="Article (Issue Resolution)" /><category term="Level (2. Intermediate)" /><category term="Field (Analytics Engineering)" /><category term="Skills (SQL)" /><category term="Skills (dbt)" /><summary type="html"><![CDATA[“이번 프로젝트에서는 엔터프라이즈 데이터 웨어하우스(EDW) 환경에서 발생한 쿼리 성능 문제를 해결하기 위해, core_fct_events 테이블의 Incremental 업데이트 전략을 최적화했습니다. 기존의 비효율적인 NOT IN 구문을 LEFT JOIN으로 대체하여 데이터 중복 검사를 최적화함으로써, 오케스트레이션 전체 소요 시간을 50분에서 2분으로 단축했습니다. 이로 인해 약 96%의 성능 개선을 이루었으며, 데이터 처리 효율성과 시스템 자원 활용도를 크게 향상시켜 서비스의 안정성과 확장성을 강화했습니다.”]]></summary></entry><entry><title type="html">Redash 대시보드 활용 후기</title><link href="http://localhost:4000/redash-dashboard-ko/" rel="alternate" type="text/html" title="Redash 대시보드 활용 후기" /><published>2024-08-09T00:00:00+09:00</published><updated>2024-08-09T00:00:00+09:00</updated><id>http://localhost:4000/redash-dashboard-ko</id><content type="html" xml:base="http://localhost:4000/redash-dashboard-ko/"><![CDATA[<blockquote>
  <p>“오픈소스 BI 도구인 Redash를 활용해 데이터를 시각화하고, 조직 내 다양한 구성원이 데이터를 쉽게 활용할 수 있도록 대시보드를 체계적으로 관리했습니다. 높은 접근성과 데이터 리터러시를 확보하기 위해 관리 규칙을 설정하고, 쿼리 파라미터 기능을 적극적으로 활용했습니다. 그 결과, Redash의 사용 빈도가 크게 증가하여 조직의 BI 중심 역할을 강화했습니다. (전체 Redash 계정 보유자 중 대략 DAU <code class="language-plaintext highlighter-rouge">39%</code>, WAU <code class="language-plaintext highlighter-rouge">52%</code>, MAU <code class="language-plaintext highlighter-rouge">77%</code>)”</p>
</blockquote>

<hr />

<table>
  <thead>
    <tr>
      <th><strong>Performance Summary</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>- Redash DAU: 약 <code class="language-plaintext highlighter-rouge">39%</code> (사내 전체 Redash 계정 보유자 수 대비 비율)</td>
    </tr>
    <tr>
      <td>- Redash WAU: 약 <code class="language-plaintext highlighter-rouge">52%</code> (사내 전체 Redash 계정 보유자 수 대비 비율)</td>
    </tr>
    <tr>
      <td>- Redash MAU: 약 <code class="language-plaintext highlighter-rouge">77%</code> (사내 전체 Redash 계정 보유자 수 대비 비율)</td>
    </tr>
  </tbody>
</table>

<hr />

<h1 id="목차">목차</h1>
<ol>
  <li>Summary</li>
  <li>Introduction</li>
  <li>Background</li>
  <li>How I Used Redash</li>
  <li>Conclusion</li>
</ol>

<hr />

<h1 id="1-summary">1. Summary</h1>

<h3 id="introduction">Introduction</h3>
<ul>
  <li>제가 근무하고 있는 기업은 프로덕트 데이터 분석을 할 수 있는 환경이 조성되어 있습니다. 그 중 Redash를 BI 도구로 도입하여 2년 가까이 사용하고 있습니다. 본 글에서는 <strong>데이터 분석 환경을 조성하고자 Redash를 어떻게 도입하여 활용했는지</strong> 공유 드리고자 합니다.</li>
</ul>

<h3 id="background">Background</h3>
<ul>
  <li>Redash를 도입하기로 결정한 배경은 다음과 같습니다.</li>
  <li>(1) <strong>데이터 추출의 자유도</strong>가 매우 높았기 때문입니다.</li>
  <li>(2) 오픈소스를 통해 별도의 <strong>비용 없이</strong> 이용할 수 있었기 때문입니다.</li>
</ul>

<h3 id="how-i-used-redash">How I Used Redash</h3>
<ol>
  <li>대시보드의 이름과 태그를 정돈하여 사람들이 헤매지 않도록 했습니다.</li>
  <li>Query Parameters를 적극적으로 사용했습니다.</li>
  <li>각 대시보드의 상단에는 제목, 목차, 간단한 가이드를 작성했습니다.</li>
  <li>차트에 대한 설명은 좌측에, 각 차트는 우측에 배치했습니다.</li>
  <li>차트의 활용 가이드는 LLM의 도움을 받아 작성했습니다.</li>
  <li>하위 제목은 더 크게, 상위 제목은 더 작게 표현했습니다.</li>
  <li>카테고리의 Cardinality가 높을 경우, 차트에서는 최대 20개까지만 표현하고, 보충 테이블을 통해 전수를 확인할 수 있도록 구성했습니다.</li>
  <li>하이퍼링크를 통해 편의성을 제공했습니다.</li>
  <li>각 쿼리문은 모두 Git Repo에 별도로 보관했습니다.</li>
</ol>

<h3 id="conclusion">Conclusion</h3>
<ul>
  <li>생각을 닫은 채 기계적으로 대시보드를 만드는 행위를 지양했습니다.</li>
  <li>사내 구성원들에게 실질적으로 도움이 되는 방식으로 제공했습니다.</li>
  <li>Redash의 사용 빈도가 크게 증가하여 조직의 BI 중심 역할을 강화했습니다. (전체 Redash 계정 보유자 중 대략 DAU <code class="language-plaintext highlighter-rouge">39%</code>, WAU <code class="language-plaintext highlighter-rouge">52%</code>, MAU <code class="language-plaintext highlighter-rouge">77%</code>)</li>
</ul>

<hr />

<h1 id="2-introduction">2. Introduction</h1>

<blockquote>
  <ul>
    <li>제가 근무하고 있는 기업은 프로덕트 데이터 분석을 할 수 있는 환경이 조성되어 있습니다. 그 중 Redash를 BI 도구로 도입하여 2년 가까이 사용하고 있습니다. 본 글에서는 <strong>데이터 분석 환경을 조성하고자 Redash를 어떻게 도입하여 활용했는지</strong> 공유 드리고자 합니다.</li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-logo.webp" alt="" /></p>

<hr />

<h1 id="3-background">3. Background</h1>

<blockquote>
  <ul>
    <li>Redash를 도입하기로 결정한 배경은 다음과 같습니다.</li>
    <li>(1) <strong>데이터 추출의 자유도</strong>가 매우 높았기 때문입니다.</li>
    <li>(2) 오픈소스를 통해 별도의 <strong>비용 없이</strong> 이용할 수 있었기 때문입니다.</li>
  </ul>
</blockquote>

<p>데이터 분석가가 없던 시절, 원래 GA4와 Amplitude를 통해 아주 기초적인 데이터 현황만을 확인하고 있었을 뿐, 이벤트 정의서 같은 뼈대가 없어 데이터를 적극적으로 활용하기 어려웠습니다.</p>

<p>사내 최초로 데이터 분석가로 입사한 본인은 초반 6개월 동안 이러한 상황을 개선하고자, <strong>일관성과 활용도를 갖춘 환경을 만드는 것</strong>을 목표로 두었습니다. 그 결과, 약 2년 전부터 아래와 같은 파이프라인을 갖추게 되었고, 조직이 예전보다 훨씬 높은 Data-informed Decisions 환경을 누릴 수 있게 되었습니다.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/pipeline.webp" alt="" /></p>
<blockquote>
  <p>사내 데이터 파이프라인</p>
</blockquote>

<p>파이프라인의 최종 BI 도구인 Redash를 도입하기로 결정한 배경은 다음과 같습니다.</p>

<p><strong>(1) 데이터 추출의 자유도가 매우 높았기 때문입니다.</strong></p>

<p>많은 데이터 분석가 분들이 공감하시듯, 노코드 PA 툴의 경우 처음에는 마냥 사용하기 편하지만 깊이를 다져갈수록 분석의 자유도가 떨어져 한계에 부딪히기 마련입니다.</p>

<p>반면 Redash의 경우, 쿼리를 직접 작성한 후 출력된 결과를 기반으로 시각화를 할 수 있기 때문에 조건과 집계를 자유롭게 적용할 수 있습니다. 따라서 <strong>향후 조직의 데이터 기반 의사결정 깊이가 증진될수록 Redash를 지속적으로 활용할 수 있다는 점이 매력적이었습니다.</strong></p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-query.webp" alt="" /></p>
<blockquote>
  <p><a href="https://redash.io/product/">https://redash.io/product/</a></p>
</blockquote>

<p><strong>(2) 오픈소스를 통해 별도의 비용 없이 이용할 수 있었기 때문입니다.</strong></p>

<p><a href="https://hub.docker.com/r/redash/redash">Docker Compose</a>를 빌드하여 Redash 애플리케이션을 매우 쉽게 개발할 수 있으며, VM Instance 운영 외에 추가 비용이 들지 않았습니다.</p>

<hr />

<h1 id="4-how-i-used-redash">4. How I Used Redash</h1>

<blockquote>
  <ol>
    <li>대시보드의 이름과 태그를 정돈하여 사람들이 헤매지 않도록 했습니다.</li>
    <li>Query Parameters를 적극적으로 사용했습니다.</li>
    <li>각 대시보드의 상단에는 제목, 목차, 간단한 가이드를 작성했습니다.</li>
    <li>차트에 대한 설명은 좌측에, 각 차트는 우측에 배치했습니다.</li>
    <li>차트의 활용 가이드는 LLM의 도움을 받아 작성했습니다.</li>
    <li>하위 제목은 더 크게, 상위 제목은 더 작게 표현했습니다.</li>
    <li>카테고리의 Cardinality가 높을 경우, 차트에서는 최대 20개까지만 표현하고, 보충 테이블을 통해 전수를 확인할 수 있도록 구성했습니다.</li>
    <li>하이퍼링크를 통해 편의성을 제공했습니다.</li>
    <li>각 쿼리문은 모두 Git Repo에 별도로 보관했습니다.</li>
  </ol>
</blockquote>

<h3 id="1-대시보드의-이름과-태그를-정돈하여-사람들이-헤매지-않도록-했습니다">1. 대시보드의 이름과 태그를 정돈하여 사람들이 헤매지 않도록 했습니다.</h3>

<p>Redash의 단점 중 하나는 각 대시보드를 디렉토리로 분류할 수 있는 기능이 따로 없다는 점입니다. 특히, 사내 구성원이 확인하는 대시보드는 크게 다음 두 가지 종류로 나뉘게 될 것입니다.</p>
<ul>
  <li>주기적으로 팔로업해야 하는 기본 대시보드 (<strong>범용성</strong>)</li>
  <li>Ad-hoc 분석 요청에 의해 만들어진 대시보드 (<strong>일회성/특수성</strong>)</li>
</ul>

<p>이 때문에 목적이 다른 여러 가지 대시보드들이 시간이 흐를수록 뒤죽박죽 섞이게 되어 탐색하기 매우 복잡해질 것이 뻔합니다. <strong>탐색의 복잡성은 사용성을 해치게 될 것이고, 결국 조직의 데이터 활용 역량과 시간에 악영향을 끼치게 될 것입니다.</strong></p>

<p>이를 어떻게 극복해야 할지 고민하다, 최선의 방법으로 <strong>대시보드의 이름과 태그</strong>를 통해 탐색의 편의성이 유지될 수 있도록 접근했습니다.</p>

<p><strong>(1) 각 대시보드의 제목에 다음과 같은 Prefix를 달았습니다.</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">기본-{프로덕트 이름}</code>: 각 구성원들이 주기적으로 확인해야 하는 범용 대시보드</li>
  <li><code class="language-plaintext highlighter-rouge">Ad-hoc</code>: 특정 구성원이 요청한 분석 내용을 정리한 대시보드</li>
  <li><code class="language-plaintext highlighter-rouge">Private</code>: 민감한 정보를 가지고 있어 특정 구성원들에게만 공유해야 하는 대시보드</li>
  <li><code class="language-plaintext highlighter-rouge">Public</code>: 외부 제공 목적의 공개한 대시보드</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-prefix.webp" alt="" /></p>
<blockquote>
  <p>사내 대시보드 일부</p>
</blockquote>

<p><strong>(2) 대시보드마다 총 2개의 태그를 달아, 필터링하기 용이하도록 만들었습니다.</strong></p>

<ul>
  <li><strong>상위 개념의 태그</strong>: <code class="language-plaintext highlighter-rouge">기본</code>, <code class="language-plaintext highlighter-rouge">Ad-hoc</code>, <code class="language-plaintext highlighter-rouge">Private</code>, <code class="language-plaintext highlighter-rouge">Public</code> 중 하나를 명시</li>
  <li><strong>하위 목적의 태그</strong>: 프로덕트 이름이나 분석을 요청한 구성원 이름을 명시</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-tags.webp" alt="" /></p>
<blockquote>
  <p>사내 대시보드 일부</p>
</blockquote>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-filters.webp" alt="" /></p>
<blockquote>
  <p>Redash 우측의 각 태그를 클릭하면, 해당 대시보드 목록만 필터링하여 탐색할 수 있습니다.</p>
</blockquote>

<h3 id="2-query-parameters를-적극적으로-사용했습니다">2. Query Parameters를 적극적으로 사용했습니다.</h3>

<p>Query Parameters란 Redash가 제공하는 동적 변수 기능입니다. 즉, <strong>사용자가 Redash UI에서 원하는 값을 선택하여 쿼리를 실행할 수 있는 것입니다.</strong> 이를 활용하면 다음과 같은 장점이 있습니다.</p>
<ul>
  <li>각 케이스 별로 일일이 쿼리문을 생성할 필요 없이, 실행 시점에 Query Parameters 값만 변경함으로써 원하는 데이터가 출력되도록 할 수 있어요.</li>
  <li>각 케이스 별로 모든 차트를 대시보드에 추가할 필요가 없으므로 대시보드의 가시성이 좋아지고 복잡도를 방지할 수 있어요.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-query-parameters.webp" alt="" /></p>
<blockquote>
  <p>대시보드 레벨과 각 차트 레벨에 부여한 Query Parameters</p>
</blockquote>

<p>Query Parameters는 Level과 Type 두 가지 차원에서 다음과 같이 분류됩니다.</p>

<p><strong>(1) Level 차원</strong></p>

<ul>
  <li><strong>대시보드 레벨 파라미터 (Dashboard Parameter)</strong>: 파라미터 값을 변경하면 대시보드 내의 모든 차트에 적용됩니다.</li>
  <li><strong>차트 레벨 파라미터 (Widget Parameter)</strong>: 파라미터 값을 변경하면 해당 차트에만 적용됩니다.</li>
  <li><strong>정적인 값을 지닌 파라미터 (Static Value)</strong>: 파라미터를 특정 값에 고정시킵니다.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-query-parameter-level.webp" alt="" /></p>
<blockquote>
  <p>Query Parameters의 Level 지정하기</p>
</blockquote>

<p><strong>(2) Type 차원</strong></p>

<ul>
  <li><strong>Text</strong>: 파라미터 값을 사용자가 자유롭게 텍스트로 입력할 수 있습니다.</li>
  <li><strong>Number</strong>: 파라미터 값을 사용자가 숫자로만 입력할 수 있도록 합니다.</li>
  <li><strong>Dropdown List</strong>: 사전 정의된 리스트에서 값을 선택합니다. (정적 리스트)</li>
  <li><strong>Query Based Dropdown List</strong>: 다른 쿼리 실행 결과 리스트에서 값을 선택합니다. (동적 리스트)</li>
  <li><strong>Date</strong>: 특정 날짜를 선택합니다.</li>
  <li><strong>Date Range</strong>: 특정 날짜 기간을 선택합니다.</li>
</ul>

<p>이제 제가 사용한 대표적인 Query Parameters를 소개해드리도록 하겠습니다.</p>

<p>(A) 간격 파라미터</p>

<p>아래 쿼리문의 <code class="language-plaintext highlighter-rouge">DATE_TRUNC()</code> 함수의 간격을 동적 파라미터로 두었습니다. 이를 통해 사용자가 DAY, WEEK, MONTH, QUARTER, YEAR 기반으로 각 집계 결과를 자유롭게 확인할 수 있습니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="nb">date</span><span class="p">,</span> <span class="p">{{</span> <span class="err">간격</span> <span class="p">}})</span> <span class="k">AS</span> <span class="nb">date</span><span class="p">,</span>
        <span class="p">...</span>
    <span class="k">FROM</span>
        <span class="p">...</span>
</code></pre></div></div>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-interval.webp" alt="" /></p>
<blockquote>
  <p>간격 파라미터</p>
</blockquote>

<p>(B) 기간 파라미터</p>

<p>아래 쿼리문은 파티션 필터인 <code class="language-plaintext highlighter-rouge">date</code>를 통해 조회를 원하는 파티션만 검색하게 됩니다. 이 기간을 특정할 수 있도록 파라미터화했습니다. 이를 통해, 사용자가 아래와 같이 파라미터 값을 입력하여 조회 기간을 선택할 수 있습니다.</p>
<ul>
  <li><strong>정적 기간</strong>: 2024년 1월 1일부터 2024년 1월 10일까지</li>
  <li><strong>동적 기간</strong>: This Week, Last Month, This Year 등</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="p">...</span>
    <span class="k">FROM</span>
        <span class="p">...</span>
    <span class="k">WHERE</span>
        <span class="nb">date</span> <span class="k">BETWEEN</span> <span class="s1">'{{Date Range.start}}'</span> <span class="k">AND</span> <span class="s1">'{{Date Range.end}}'</span>
</code></pre></div></div>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-date-range.webp" alt="" /></p>
<blockquote>
  <p>기간 파라미터</p>
</blockquote>

<p>(C) 국가 파라미터</p>

<p>국가 파라미터의 경우, <strong>Query Based Dropdown List</strong>를 사용했습니다. 프로덕트 사용자 유입에 따라 시간이 흐를수록 접속 국가가 지속적으로 증가하기 때문에 정적인 목록으로 관리하기에는 어려움이 따르기 때문입니다.</p>

<ul>
  <li>먼저, 국가 목록을 동적으로 불러오는 쿼리를 작성했습니다. (트래픽 규모가 큰 순서대로 정렬하고, ALL 항목도 포함될 수 있도록 했어요.)</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-country.webp" alt="" /></p>
<blockquote>
  <p>다음과 같이 country 칼럼만 존재하는 쿼리문을 저장했습니다.</p>
</blockquote>

<ul>
  <li>새로운 접속 국가가 발생할 수 있으니, Scheduled Run을 활성화하여 최신성이 유지될 수 있도록 했어요.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-scheduled-run.webp" alt="" /></p>
<blockquote>
  <p>Scheduled Run 활성화하기</p>
</blockquote>

<p>아래 쿼리문은 Country 파라미터의 값이 <code class="language-plaintext highlighter-rouge">ALL</code>이면 전체를 출력하고, 그렇지 않을 경우 <code class="language-plaintext highlighter-rouge">country</code> 칼럼이 해당 값과 동일한 경우만 출력할 수 있도록 작성한 것입니다.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="p">...</span>
    <span class="k">FROM</span>
        <span class="p">...</span>
    <span class="k">WHERE</span>
        <span class="p">...</span>
        <span class="k">AND</span> <span class="k">CASE</span>
            <span class="k">WHEN</span> <span class="s1">'ALL'</span> <span class="k">IN</span> <span class="p">({{</span><span class="n">Country</span><span class="p">}})</span> <span class="k">THEN</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">ELSE</span> <span class="n">country</span> <span class="k">IN</span> <span class="p">({{</span><span class="n">Country</span><span class="p">}})</span>
        <span class="k">END</span>
</code></pre></div></div>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-country-2.webp" alt="" /></p>

<h3 id="3-각-대시보드의-상단에는-제목-목차-간단한-가이드를-작성했습니다">3. 각 대시보드의 상단에는 제목, 목차, 간단한 가이드를 작성했습니다.</h3>

<p><strong>사내에는 데이터 분석을 업무에 적극적으로 활용하는 분들도 계시는 반면, 여러 가지 이유로 깊게 관여하지 못하는 분들도 계십니다.</strong> 데이터가 업무 관련성이 낮을 수도 있고, 메인 업무만으로도 시간이 부족하실 수도 있고, 혹은 활용은 하고 싶으나 데이터 이해의 어려움을 겪고 계신 것 때문일 수도 있겠죠.</p>

<p><strong>따라서 최대한 많은 구성원들이 빠르고 쉽게 이해할 수 있는 대시보드를 제공하는 것이 가장 중요하다고 생각했습니다.</strong> 조금이라도 장벽을 낮추기 위해 아래 사례와 같이 제목, 목차, 그리고 가이드를 작성했습니다.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-josh-sample-dashboard.webp" alt="" /></p>

<p>Redash에서 차트뿐만 아니라 Textbox도 자유롭게 추가할 수 있는데요. 특히, <a href="https://www.markdownguide.org/cheat-sheet/#basic-syntax">Markdown 문법</a>을 잘 활용하면 시각적으로 보기 편하게 작성할 수 있습니다.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-markdown.webp" alt="" /></p>
<blockquote>
  <p><a href="https://www.markdownguide.org/cheat-sheet/#basic-syntax">https://www.markdownguide.org/cheat-sheet/#basic-syntax</a></p>
</blockquote>

<h3 id="4-차트에-대한-설명은-좌측에-각-차트는-우측에-배치했습니다">4. 차트에 대한 설명은 좌측에, 각 차트는 우측에 배치했습니다.</h3>

<p>디자이너와 프론트엔드 개발자 분들이라면 잘 아시듯이, <strong>한국어와 영어는 LTR(Left to Right) 성격을 지닌 언어입니다.</strong> (<a href="https://developer.apple.com/design/human-interface-guidelines/layout">Apple Developer 페이지 참고</a>) 한국어와 영어를 사용하는 사람들은 텍스트와 숫자는 물론, 이미지를 포함한 컨텐츠 자체를 LTR 방식으로 습득하는 경향을 지니고 있는 것입니다.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-ltr.webp" alt="" /></p>
<blockquote>
  <p><a href="https://www.linkedin.com/pulse/mastering-front-end-development-creating-ltrrtl-guide-limbachiya-17zif/">Mastering Front-End Development: Creating LTR/RTL Layouts - A Comprehensive Guide
</a></p>
</blockquote>

<p>사용자들의 이러한 인지 성향을 반영하여, 대시보드의 UI를 기본적으로 다음과 같이 배치했습니다.</p>
<ul>
  <li><strong>좌측 1/3 영역</strong>: 차트의 제목, 정의, 상세한 활용 방법을 작성한다.</li>
  <li><strong>우측 2/3 영역</strong>: 해당 차트나 테이블을 보여준다.</li>
</ul>

<p>이를 통해, <strong>사용자의 시선 이동 습관</strong>을 자연스럽게 따라갈 수 있도록 한 것입니다.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-topic-trends.webp" alt="" /></p>
<blockquote>
  <p>사내 대시보드 사례</p>
</blockquote>

<h3 id="5-차트의-활용-가이드는-llm의-도움을-받아-작성했습니다">5. 차트의 활용 가이드는 LLM의 도움을 받아 작성했습니다.</h3>

<p>사실, 데이터 분석가 분들끼리는 대시보드에 표현할 지표의 의미를 정의하고 설명하는 것에는 큰 어려움이 없습니다. 다만, 각기 다른 포지션의 사내 구성원들이 이해하기 쉽게 설명하는 것은 어렵기 마련입니다. 다양한 R&amp;R에 대한 이해와 공감, 그리고 데이터 문해력을 함께 갖추어야 하기 때문이죠. <strong>이러한 상호 간의 얼음 장벽을 조금이라도 해소하기 위해 대시보드 사용자 관점에서 UX Writing이 이루어질 수 있도록 LLM을 활용해봤습니다.</strong></p>

<p><strong>(1) 작성한 프롬프트 샘플</strong></p>

<pre><code class="language-plain">    "활성 사용자 수" 차트의 설명 가이드를 작성해주세요.

    배경: 사내 BI 대시보드를 이용하는 사내 임직원들에게 보여주는 차트입니다.

    조건 1: 데이터 지식이 부족한 임직원이 있을 수 있으니 친절하고 명료하게 표현해야 합니다.
    조건 2: 사업 전략, 마케팅, 디자인, 개발 등 각 전문성에 연관된 설명이 있으면 좋습니다.

    작성 포맷:
    # 활성 사용자 수
    &gt; 간략한 정의
    ---
    * 3-5개 Bullet Points 자세한 설명
    ---
    * 3-5개 Bullet Points 차트를 업무에 활용하는 방법 사례
</code></pre>

<p><strong>(2) ChatGPT 4o의 답변 사례</strong></p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-chatgpt.webp" alt="" /></p>

<h3 id="6-하위-제목은-더-크게-상위-제목은-더-작게-표현했습니다">6. 하위 제목은 더 크게, 상위 제목은 더 작게 표현했습니다.</h3>

<p>저를 포함하여 Markdown에 익숙한 분들은 일반적으로 아래와 같이 <strong>대제목은 크게, 소제목은 작게</strong> 표현하곤 하실 것입니다.</p>

<pre><code class="language-plain">    # 1. 대제목
    ## 1.1. 소제목
</code></pre>

<p>그런데, 아래와 같이 각 소제목 파트의 양이 워낙 많아 한 화면에 정보의 Hierarchy를 보여줄 수 없는 경우에는 문제가 생길 수 있습니다. 즉, 스크롤을 하게 되면서 사용자는 다음과 같은 혼란에 빠지기 쉬운 것입니다.</p>

<blockquote>
  <p>“내가 지금 보고 있는 소제목 파트의 대제목이 뭐였지?”</p>
</blockquote>

<pre><code class="language-plain">    # 1. 대제목
    ...
    ...
    (중략)
    ...
    ...
    ## 1.1. 소제목
    ...
    ...
    (중략)
    ...
    ...
    ## 1.2. 소제목
</code></pre>

<p>이러한 문제가 생길 것을 직감하여, UX/UI 전문가이신 사내 디자이너 및 프론트엔드 개발자 동료 분들께 의견을 구하니 다음과 같은 조언을 해주셨습니다.</p>

<blockquote>
  <p>“현재 사용자가 focus한 내용은 소제목 파트이니, 소제목을 더 크게 표현하고, 대제목을 작게 표현해주는 게 사용자 경험을 잘 반영해줄 수 있을 것 같아요.”</p>
</blockquote>

<p>결국 저는 대제목을 크게 한 번 표현한 이후부터는, <strong>소제목 작성시 대제목을 머릿말 처럼 작게 표시함으로써 소제목에 focus하려는 사용자의 심리를 잘 따라갈 수 있도록</strong> 구성했습니다.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-example-users-cnt.webp" alt="" /></p>
<blockquote>
  <p>사내 대시보드 사례</p>
</blockquote>

<h3 id="7-카테고리의-cardinality가-높을-경우-차트에서는-최대-20개까지만-표현하고-보충-테이블을-통해-전수를-확인할-수-있도록-구성했습니다">7. 카테고리의 Cardinality가 높을 경우, 차트에서는 최대 20개까지만 표현하고, 보충 테이블을 통해 전수를 확인할 수 있도록 구성했습니다.</h3>

<p>사실 본 기업은 글로벌 서비스를 운영하고 있다보니, 사용자들의 접속 국가 개수가 100개를 훨씬 넘습니다. 만일 국가별 획득 사용자 수 추이를 차트로 표현한다면 아래의 두 가지 방식이 존재할 것입니다.</p>

<p><strong>(1) 전체 국가를 모두 표현하는 방식</strong></p>
<ul>
  <li><strong>장점</strong>: 정보의 완전성을 갖출 수 있어요.</li>
  <li><strong>단점</strong>: 가독성이 떨어지고, 브라우저의 메모리 사용량이 지나치게 높아져요.</li>
</ul>

<p><strong>(2) 상위 N개 국가만 명시하고, 나머지는 “기타”로 집계하는 방식</strong></p>
<ul>
  <li><strong>장점</strong>: 가독성이 높아져 흐름을 읽기 쉬워져요.</li>
  <li><strong>단점</strong>: 정보가 불완전하여 “소수 국가”의 데이터를 확인하기 어려워져요.</li>
</ul>

<p>이 딜레마를 해결하기 위해 다음과 같은 접근 방법을 선택했습니다.</p>
<ul>
  <li>가독성을 위해 차트에서는 최대 20개국만 명시하기</li>
  <li>정보의 완전성을 위해 전체 국가 데이터를 별도의 테이블로 보충하기</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-example-users-cnt-by-country.webp" alt="" /></p>
<blockquote>
  <p>사내 대시보드 사례</p>
</blockquote>

<p>사실 BI 전문가분들 사이에서 차트에 표현할 Cardinality를 최대 7개로 제한하는 것이 좋다는 불문율이 존재하기도 합니다. 하지만 저희 기업의 사업 특성상 워낙 많은 국가에서 프로덕트가 사용되고 있기 때문에 20개국으로 Limit을 올리기로 결정했습니다.</p>

<h3 id="8-하이퍼링크를-통해-편의성을-제공했습니다">8. 하이퍼링크를 통해 편의성을 제공했습니다.</h3>

<p>가령, <strong>컨텐츠 마케팅 영역에서는 각 컨텐츠 페이지를 비교 분석해야 하는 경우가 빈번합니다.</strong> 따라서 “페이지별” 인사이트를 제공하기 위한 테이블을 만들 때는 항상 하이퍼링크를 추가했습니다.</p>

<p>비교 분석을 하는 컨텐츠 마케터 시각에서는, 각 페이지의 트래픽, CTA 전환율, Engagements, 체류 시간 등의 수치를 확인하면서 해당 컨텐츠 자체의 정성적인 배경을 파악하는 것이 자연스러운 사고 흐름일 것입니다. <strong>따라서 편하게 해당 페이지로 이동하여 비교 분석할 수 있도록 하이퍼링크를 사용하게 된 것입니다.</strong></p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-clicks.webp" alt="" /></p>
<blockquote>
  <p>사내 대시보드 사례</p>
</blockquote>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-hyperlinks.webp" alt="" /></p>
<blockquote>
  <p>하이퍼링크 옵션</p>
</blockquote>

<h3 id="9-각-쿼리문은-모두-git-repo에-별도로-보관했습니다">9. 각 쿼리문은 모두 Git Repo에 별도로 보관했습니다.</h3>

<p>Redash에서 각 쿼리문을 저장할 수 있고, 대시보드 처럼 태그를 통해 탐색의 편의성을 높일 수 있습니다.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-queries.webp" alt="" /></p>
<blockquote>
  <p>Redash &gt; Queries</p>
</blockquote>

<p><strong>그러나 대시보드를 만드는 과정에서 쿼리문의 재사용이나 반복 적용된 쿼리문의 전면 수정 등을 진행할 경우 이를 일일이 탐색하려면 엄청난 작업 비효율성을 발생할 것입니다.</strong> 따라서 저는 기본적으로 모든 쿼리문을 다음과 같은 체계를 두어 Git Repo로 관리하고 있습니다.</p>
<ul>
  <li>**디렉토리: 각 대시보드</li>
  <li><strong>개별 파일</strong>: 대시보드에 포함된 각 쿼리문</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-git-repo.webp" alt="" /></p>
<blockquote>
  <p>사내 Redash 전용 Git Repo</p>
</blockquote>

<p>Git Repo를 통한 관리는 다음과 같은 장점을 가져다줄 수 있습니다.</p>
<ul>
  <li>데이터 마트의 도입이나 택소노미의 변경 등으로 인해 모든 쿼리문을 한꺼번에 수정해야 한다면, 반복 작업 시간을 크게 단축할 수 있습니다.</li>
  <li>쿼리문을 재사용하여 새로운 대시보드를 생성할 경우, 탐색 시간이 크게 단축됩니다.</li>
  <li>VS Code의 Copilot의 코드 생성 기능을 사용함으로써 작업 시간이 매우 크게 단축됩니다.</li>
</ul>

<hr />

<h1 id="5-conclusion">5. Conclusion</h1>

<blockquote>
  <ul>
    <li>생각을 닫은 채 기계적으로 대시보드를 만드는 행위를 지양했습니다.</li>
    <li>사내 구성원들에게 실질적으로 도움이 되는 방식으로 제공했습니다.</li>
    <li>Redash의 사용 빈도가 크게 증가하여 조직의 BI 중심 역할을 강화했습니다. (전체 Redash 계정 보유자 중 대략 DAU <code class="language-plaintext highlighter-rouge">39%</code>, WAU <code class="language-plaintext highlighter-rouge">52%</code>, MAU <code class="language-plaintext highlighter-rouge">77%</code>)</li>
  </ul>
</blockquote>

<p>지금까지 제가 근무하고 있는 기업에서 Redash를 어떻게 활용하고 있는지에 대해 말씀 드렸습니다. 이 과정에서 데이터 분석과 엔지니어링 업무를 수행하며 느낀 중요한 점이 하나 있습니다. <strong>바로, 생각을 닫은 채 기계적으로 대시보드를 만드는 행위를 지양해야 한다는 것입니다.</strong> 데이터 기반 의사결정과 데이터 리터러시에 기여하기 위해 다음과 같은 내적 질문을 끊임없이 던져야 합니다.</p>

<blockquote>
  <p>“대시보드를 어떤 방식으로 제공해야 의사결정의 실효성과 데이터 활용도를 높일 수 있을까?”</p>
</blockquote>

<p>다양하고 복잡한 기능을 갖춘 웅장한 차트를 제공하는 것도 좋지만, 결국 가장 중요한 것은 <strong>사내 구성원들에게 실질적인 도움이 되는 방식으로 제공</strong>하는 것입니다. Redash 대시보드를 만드는 과정에서 사용자 심리를 공부하고 LLM을 활용하게 된 배경에도 결국 이러한 고민이 있었습니다.</p>

<p><strong>현재의 대시보드가 결코 완벽하다고 생각하지 않습니다.</strong> 사업 전략, 데이터의 변화, 조직의 성장과 변화에 따라 대시보드를 개선해야 하는 시기가 올 것입니다. 고객이 애정하는 프로덕트가 되는 데 기여할 수 있도록 BI에 대한 관심을 지속적으로 갖고 열심히 노력해야 할 것으로 생각합니다.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (Korean)" /><category term="Article (Project)" /><category term="Level (2. Intermediate)" /><category term="Field (Data Visualization)" /><category term="Skills (Redash)" /><summary type="html"><![CDATA[“오픈소스 BI 도구인 Redash를 활용해 데이터를 시각화하고, 조직 내 다양한 구성원이 데이터를 쉽게 활용할 수 있도록 대시보드를 체계적으로 관리했습니다. 높은 접근성과 데이터 리터러시를 확보하기 위해 관리 규칙을 설정하고, 쿼리 파라미터 기능을 적극적으로 활용했습니다. 그 결과, Redash의 사용 빈도가 크게 증가하여 조직의 BI 중심 역할을 강화했습니다. (전체 Redash 계정 보유자 중 대략 DAU 39%, WAU 52%, MAU 77%)”]]></summary></entry><entry><title type="html">Redash Dashboard Usage Review</title><link href="http://localhost:4000/redash-dashboard-en/" rel="alternate" type="text/html" title="Redash Dashboard Usage Review" /><published>2024-08-09T00:00:00+09:00</published><updated>2024-08-09T00:00:00+09:00</updated><id>http://localhost:4000/redash-dashboard-en</id><content type="html" xml:base="http://localhost:4000/redash-dashboard-en/"><![CDATA[<blockquote>
  <p>“Utilizing the open-source BI tool Redash, I visualized data and systematically managed dashboards to ensure easy access for various members of the organization. To improve accessibility and data literacy, I implemented management rules and actively used query parameter functions. This significantly increased Redash usage frequency, strengthening its role as the organization’s BI hub. (Approximately DAU <code class="language-plaintext highlighter-rouge">39%</code>, WAU <code class="language-plaintext highlighter-rouge">52%</code>, MAU <code class="language-plaintext highlighter-rouge">77%</code> among all Redash account holders).”</p>
</blockquote>

<hr />

<table>
  <thead>
    <tr>
      <th><strong>Performance Summary</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>- Redash DAU: approx. <code class="language-plaintext highlighter-rouge">39%</code> (compared to the total number of internal Redash account holders)</td>
    </tr>
    <tr>
      <td>- Redash WAU: approx. <code class="language-plaintext highlighter-rouge">52%</code> (compared to the total number of internal Redash account holders)</td>
    </tr>
    <tr>
      <td>- Redash MAU: approx. <code class="language-plaintext highlighter-rouge">77%</code> (compared to the total number of internal Redash account holders)</td>
    </tr>
  </tbody>
</table>

<hr />

<h1 id="table-of-contents">Table of Contents</h1>
<ol>
  <li>Summary</li>
  <li>Introduction</li>
  <li>Background</li>
  <li>How I Used Redash</li>
  <li>Conclusion</li>
</ol>

<hr />

<h1 id="1-summary">1. Summary</h1>

<h3 id="introduction">Introduction</h3>
<ul>
  <li>At my company, a product data analysis environment is in place, and Redash has been used as a BI tool for nearly two years. In this post, I will share <strong>how Redash was implemented and utilized to enhance our data analysis environment.</strong></li>
</ul>

<h3 id="background">Background</h3>
<ul>
  <li>The decision to implement Redash was driven by the following reasons:</li>
  <li>(1) <strong>High flexibility in data extraction.</strong></li>
  <li>(2) It could be used <strong>without any additional costs</strong> due to its open-source nature.</li>
</ul>

<h3 id="how-i-used-redash">How I Used Redash</h3>
<ol>
  <li>Organized dashboard names and tags to make navigation easier for users.</li>
  <li>Actively used query parameters.</li>
  <li>Added titles, a table of contents, and simple guides at the top of each dashboard.</li>
  <li>Positioned explanations on the left and the corresponding charts on the right.</li>
  <li>Wrote chart usage guides with the help of LLMs.</li>
  <li>Made subheadings larger and main headings smaller for clarity.</li>
  <li>Limited the display of charts with high cardinality categories to a maximum of 20 items, providing supplementary tables for the full data.</li>
  <li>Added hyperlinks for convenience.</li>
  <li>Stored all query scripts separately in a Git repository.</li>
</ol>

<h3 id="conclusion">Conclusion</h3>
<ul>
  <li>Avoided creating dashboards mechanically, ensuring they provided real value to users.</li>
  <li>Delivered dashboards that were practically useful for team members.</li>
  <li>Significantly increased Redash usage, reinforcing its role as a BI hub in the organization (approximately DAU <code class="language-plaintext highlighter-rouge">39%</code>, WAU <code class="language-plaintext highlighter-rouge">52%</code>, MAU <code class="language-plaintext highlighter-rouge">77%</code>).</li>
</ul>

<hr />

<h1 id="2-introduction">2. Introduction</h1>

<blockquote>
  <ul>
    <li>At my company, a product data analysis environment is in place, and Redash has been used as a BI tool for nearly two years. In this post, I will share <strong>how Redash was implemented and utilized to enhance our data analysis environment.</strong></li>
  </ul>
</blockquote>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-logo.webp" alt="" /></p>

<hr />

<h1 id="3-background">3. Background</h1>

<blockquote>
  <ul>
    <li>The decision to implement Redash was driven by the following reasons:</li>
    <li>(1) <strong>High flexibility in data extraction.</strong></li>
    <li>(2) It could be used <strong>without any additional costs</strong> due to its open-source nature.</li>
  </ul>
</blockquote>

<p>Before hiring a dedicated data analyst, we were only using GA4 and Amplitude for basic data checks without any structured data catalog or event definitions, making data utilization difficult.</p>

<p>Upon joining as the company’s first data analyst, I set a goal of <strong>creating an environment with consistency and high usability</strong> within the first six months. This resulted in the establishment of a pipeline that enabled the organization to operate in a more data-informed decision-making environment than ever before.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/pipeline.webp" alt="" /></p>
<blockquote>
  <p>In-house Data Pipeline</p>
</blockquote>

<p>The final BI tool in this pipeline was Redash, chosen for the following reasons:</p>

<p><strong>(1) High flexibility in data extraction.</strong></p>

<p>Many data analysts agree that while no-code PA tools may be easy to use initially, as the depth of analysis increases, these tools limit analytical freedom.</p>

<p>However, Redash allows for writing custom queries and visualizing results based on flexible conditions and aggregations, making it <strong>an attractive choice for long-term use as the organization’s data-driven decision-making deepens.</strong></p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-query.webp" alt="" /></p>
<blockquote>
  <p><a href="https://redash.io/product/">https://redash.io/product/</a></p>
</blockquote>

<p><strong>(2) It could be used without additional costs due to its open-source nature.</strong></p>

<p>By building Redash using <a href="https://hub.docker.com/r/redash/redash">Docker Compose</a>, we could easily develop the Redash application without incurring extra costs beyond operating a VM instance.</p>

<hr />

<h1 id="4-how-i-used-redash">4. How I Used Redash</h1>

<blockquote>
  <ol>
    <li>Organized dashboard names and tags to make navigation easier for users.</li>
    <li>Actively used query parameters.</li>
    <li>Added titles, a table of contents, and simple guides at the top of each dashboard.</li>
    <li>Positioned explanations on the left and the corresponding charts on the right.</li>
    <li>Wrote chart usage guides with the help of LLMs.</li>
    <li>Made subheadings larger and main headings smaller for clarity.</li>
    <li>Limited the display of charts with high cardinality categories to a maximum of 20 items, providing supplementary tables for the full data.</li>
    <li>Added hyperlinks for convenience.</li>
    <li>Stored all query scripts separately in a Git repository.</li>
  </ol>
</blockquote>

<h3 id="1-organized-dashboard-names-and-tags-to-make-navigation-easier-for-users">1. Organized dashboard names and tags to make navigation easier for users.</h3>

<p>One of Redash’s limitations is the lack of a built-in feature to categorize dashboards into directories. Within our organization, dashboards are generally divided into two main types:</p>
<ul>
  <li>Regularly followed general dashboards (<strong>general use</strong>)</li>
  <li>Ad-hoc dashboards created in response to specific analysis requests (<strong>one-time/specialized use</strong>)</li>
</ul>

<p>As the number of dashboards with different purposes grows over time, it inevitably becomes difficult to navigate. <strong>This complexity hinders usability and eventually negatively impacts the organization’s data utilization and efficiency.</strong></p>

<p>To overcome this, I adopted a method where <strong>dashboard names and tags</strong> were used to maintain ease of navigation.</p>

<p><strong>(1) I applied the following prefixes to dashboard titles:</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">General-{Product Name}</code>: General dashboards that team members regularly check.</li>
  <li><code class="language-plaintext highlighter-rouge">Ad-hoc</code>: Dashboards summarizing specific analysis requests from individual team members.</li>
  <li><code class="language-plaintext highlighter-rouge">Private</code>: Dashboards containing sensitive information, shared only with specific team members.</li>
  <li><code class="language-plaintext highlighter-rouge">Public</code>: Dashboards made available for external purposes.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-prefix.webp" alt="" /></p>
<blockquote>
  <p>Sample of Internal Dashboards</p>
</blockquote>

<p><strong>(2) I applied two tags to each dashboard for easier filtering.</strong></p>

<ul>
  <li><strong>Higher-level tags</strong>: <code class="language-plaintext highlighter-rouge">General</code>, <code class="language-plaintext highlighter-rouge">Ad-hoc</code>, <code class="language-plaintext highlighter-rouge">Private</code>, <code class="language-plaintext highlighter-rouge">Public</code>.</li>
  <li><strong>Lower-level tags</strong>: Product name or the name of the team member who requested the analysis.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-tags.webp" alt="" /></p>
<blockquote>
  <p>Sample of Internal Dashboards</p>
</blockquote>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-filters.webp" alt="" /></p>
<blockquote>
  <p>Clicking on the tags in Redash filters the list of dashboards for easier navigation.</p>
</blockquote>

<h3 id="2-actively-used-query-parameters">2. Actively used query parameters.</h3>

<p>Query Parameters in Redash are dynamic variables that <strong>allow users to select values and run queries directly from the Redash UI.</strong> This feature has several benefits:</p>
<ul>
  <li>You can avoid creating individual queries for each case by changing the Query Parameters values at runtime to output the desired data.</li>
  <li>It improves dashboard visibility and prevents complexity by reducing the need to add charts for every individual case.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-query-parameters.webp" alt="" /></p>
<blockquote>
  <p>Query Parameters assigned to both dashboard and chart levels</p>
</blockquote>

<p>Query Parameters can be categorized by Level and Type.</p>

<p><strong>(1) By Level</strong></p>

<ul>
  <li><strong>Dashboard-level parameters</strong>: Parameters applied to all charts in a dashboard.</li>
  <li><strong>Widget-level parameters</strong>: Parameters applied only to the specific chart.</li>
  <li><strong>Static values</strong>: Parameters fixed to a specific value.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-query-parameter-level.webp" alt="" /></p>
<blockquote>
  <p>Setting the level of Query Parameters</p>
</blockquote>

<p><strong>(2) By Type</strong></p>

<ul>
  <li><strong>Text</strong>: Users can freely enter text values.</li>
  <li><strong>Number</strong>: Users can enter only numeric values.</li>
  <li><strong>Dropdown List</strong>: Values are selected from a predefined list (static).</li>
  <li><strong>Query-Based Dropdown List</strong>: Values are selected from the result of another query (dynamic).</li>
  <li><strong>Date</strong>: Users can select a specific date.</li>
  <li><strong>Date Range</strong>: Users can select a date range.</li>
</ul>

<p>Now, let me introduce some of the key Query Parameters I used.</p>

<p>(A) Interval Parameter</p>

<p>The <code class="language-plaintext highlighter-rouge">DATE_TRUNC()</code> function’s interval in the query below is a dynamic parameter. This allows users to view aggregated results based on DAY, WEEK, MONTH, QUARTER, or YEAR.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="n">DATE_TRUNC</span><span class="p">(</span><span class="nb">date</span><span class="p">,</span> <span class="p">{{</span> <span class="n">interval</span> <span class="p">}})</span> <span class="k">AS</span> <span class="nb">date</span><span class="p">,</span>
        <span class="p">...</span>
    <span class="k">FROM</span>
        <span class="p">...</span>
</code></pre></div></div>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-interval.webp" alt="" /></p>
<blockquote>
  <p>Interval Parameter</p>
</blockquote>

<p>(B) Date Range Parameter</p>

<p>The following query uses the partition filter <code class="language-plaintext highlighter-rouge">date</code> to search only the desired partitions. This filter is parameterized, allowing users to select the date range they want to query.</p>
<ul>
  <li><strong>Static Range</strong>: January 1, 2024 to January 10, 2024</li>
  <li><strong>Dynamic Range</strong>: This Week, Last Month, This Year, etc.</li>
</ul>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="p">...</span>
    <span class="k">FROM</span>
        <span class="p">...</span>
    <span class="k">WHERE</span>
        <span class="nb">date</span> <span class="k">BETWEEN</span> <span class="s1">'{{Date Range.start}}'</span> <span class="k">AND</span> <span class="s1">'{{Date Range.end}}'</span>
</code></pre></div></div>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-date-range.webp" alt="" /></p>
<blockquote>
  <p>Date Range Parameter</p>
</blockquote>

<p>(C) Country Parameter</p>

<p>For the country parameter, I used a <strong>Query Based Dropdown List</strong>. Since the number of user countries increases over time, maintaining a static list would be difficult.</p>
<ul>
  <li>First, I created a query to dynamically retrieve the country list (sorted by traffic size and including an “ALL” option).</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-country.webp" alt="" /></p>
<blockquote>
  <p>Saved query that only returns the country column.</p>
</blockquote>

<ul>
  <li>To maintain up-to-date information, I enabled Scheduled Runs to account for new incoming countries.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-scheduled-run.webp" alt="" /></p>
<blockquote>
  <p>Enabling Scheduled Run</p>
</blockquote>

<p>The query below outputs all data when <code class="language-plaintext highlighter-rouge">ALL</code> is selected for the Country parameter. If a specific country is selected, only the data for that <code class="language-plaintext highlighter-rouge">country</code> is shown.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">SELECT</span>
        <span class="p">...</span>
    <span class="k">FROM</span>
        <span class="p">...</span>
    <span class="k">WHERE</span>
        <span class="p">...</span>
        <span class="k">AND</span> <span class="k">CASE</span>
            <span class="k">WHEN</span> <span class="s1">'ALL'</span> <span class="k">IN</span> <span class="p">({{</span><span class="n">Country</span><span class="p">}})</span> <span class="k">THEN</span> <span class="mi">1</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">ELSE</span> <span class="n">country</span> <span class="k">IN</span> <span class="p">({{</span><span class="n">Country</span><span class="p">}})</span>
        <span class="k">END</span>
</code></pre></div></div>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-country-2.webp" alt="" /></p>

<h3 id="3-added-titles-a-table-of-contents-and-simple-guides-at-the-top-of-each-dashboard">3. Added titles, a table of contents, and simple guides at the top of each dashboard.</h3>

<p><strong>Within the company, there are individuals who actively use data analysis in their work, while others may not be as deeply involved for various reasons.</strong> This could be due to the lack of relevance to their main tasks, time constraints, or difficulty in understanding data.</p>

<p><strong>It was essential to provide dashboards that could be quickly and easily understood by as many team members as possible.</strong> To reduce any barriers, I added titles, a table of contents, and simple guides, as shown in the example below.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-josh-sample-dashboard.webp" alt="" /></p>

<p>In Redash, you can freely add not only charts but also textboxes. By leveraging <a href="https://www.markdownguide.org/cheat-sheet/#basic-syntax">Markdown syntax</a>, you can make content visually appealing and easy to read.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-markdown.webp" alt="" /></p>
<blockquote>
  <p><a href="https://www.markdownguide.org/cheat-sheet/#basic-syntax">https://www.markdownguide.org/cheat-sheet/#basic-syntax</a></p>
</blockquote>

<h3 id="4-positioned-explanations-on-the-left-and-the-corresponding-charts-on-the-right">4. Positioned explanations on the left and the corresponding charts on the right.</h3>

<p>As many designers and front-end developers know, <strong>languages like Korean and English are left-to-right (LTR) by nature</strong> (<a href="(https://developer.apple.com/design/human-interface-guidelines/layout)">Apple Developer Guidelines</a>). This means that people who use these languages tend to process text, numbers, and even images from left to right.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-ltr.webp" alt="" /></p>
<blockquote>
  <p><a href="https://www.linkedin.com/pulse/mastering-front-end-development-creating-ltrrtl-guide-limbachiya-17zif/">Mastering Front-End Development: Creating LTR/RTL Layouts - A Comprehensive Guide
</a></p>
</blockquote>

<p>To align with these cognitive patterns, I designed the dashboard layout as follows:</p>
<ul>
  <li><strong>Left 1/3 section</strong>: Titles, definitions, and detailed usage explanations for each chart.</li>
  <li><strong>Right 2/3 section</strong>: Displays the corresponding charts or tables.</li>
</ul>

<p>This layout follows <strong>the natural eye movement patterns of users.</strong></p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-topic-trends.webp" alt="" /></p>
<blockquote>
  <p>Example of Internal Dashboard</p>
</blockquote>

<h3 id="5-wrote-chart-usage-guides-with-the-help-of-llms">5. Wrote chart usage guides with the help of LLMs.</h3>

<p>While data analysts are usually familiar with the meaning of the metrics shown on dashboards, explaining them clearly to non-technical team members can be challenging. This requires not only knowledge of various roles and responsibilities but also the ability to empathize and communicate across different levels of data literacy. <strong>To bridge this gap, I used LLMs (Language Learning Models) to create user-friendly UX writing for the dashboards.</strong></p>

<p><strong>(1) Sample prompt I used:</strong></p>

<pre><code class="language-plain">    Please write a usage guide for the "Active Users" chart.

    Context: This chart will be viewed by employees using the internal BI dashboard.

    Condition 1: Some employees may lack data knowledge, so the explanation must be clear and friendly.
    Condition 2: It should include connections to business strategy, marketing, design, and development.

    Format:
    # Active Users
    &gt; Brief definition
    ---
    * 3-5 bullet points with detailed explanations
    ---
    * 3-5 bullet points with examples of how the chart can be used for work purposes
</code></pre>

<p><strong>(2) ChatGPT 4o의 답변 사례</strong></p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-chatgpt.webp" alt="" /></p>

<h3 id="6-made-subheadings-larger-and-main-headings-smaller-for-clarity">6. Made subheadings larger and main headings smaller for clarity.</h3>

<p>Those familiar with Markdown usually format <strong>main headings as larger and subheadings as smaller</strong>, like so:</p>

<pre><code class="language-plain">    # 1. Main Heading
    ## 1.1. Subheading
</code></pre>

<p>However, when subheadings contain a lot of content, this hierarchy can get lost as users scroll, leading to confusion. They might think:</p>

<blockquote>
  <p>“What was the main topic again?”</p>
</blockquote>

<pre><code class="language-plain">    # 1. Main Heading
    ...
    (several lines of content)
    ## 1.1. Subheading
    ...
    (several lines of content)
    ## 1.2. Subheading
</code></pre>

<p>To address this, I consulted with internal UX/UI experts, who advised:</p>

<blockquote>
  <p>“Since users will be focusing on the subheadings, it might be better to make subheadings larger and the main headings smaller to improve user experience.”</p>
</blockquote>

<p>So, I adjusted the layout so that <strong>the subheadings are emphasized while still keeping the main heading in view, helping users stay focused on relevant content.</strong></p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-example-users-cnt.webp" alt="" /></p>
<blockquote>
  <p>Example of Internal Dashboard</p>
</blockquote>

<h3 id="7-limited-the-display-of-charts-with-high-cardinality-categories-to-a-maximum-of-20-items-providing-supplementary-tables-for-the-full-data">7. Limited the display of charts with high cardinality categories to a maximum of 20 items, providing supplementary tables for the full data.</h3>

<p>Since our company operates a global service, we have more than 100 countries where users are active. If we displayed the user acquisition trend by country on a chart, we would face two options:</p>

<p><strong>(1) Show all countries.</strong></p>
<ul>
  <li><strong>Pros</strong>: Completeness of information.</li>
  <li><strong>Cons</strong>: Poor readability and high memory consumption in the browser.</li>
</ul>

<p><strong>(2) Display only the top N countries and aggregate the rest as “Others.”</strong></p>
<ul>
  <li><strong>Pros</strong>: Improved readability and easier to grasp trends.</li>
  <li><strong>Cons</strong>: The lack of detail for smaller countries might result in incomplete data.</li>
</ul>

<p>To solve this dilemma, I chose the following approach:</p>
<ul>
  <li>Limit charts to a maximum of 20 countries for readability.</li>
  <li>Provide a supplementary table with complete country data for comprehensiveness.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-example-users-cnt-by-country.webp" alt="" /></p>
<blockquote>
  <p>Example of Internal Dashboard</p>
</blockquote>

<p>While it’s commonly recommended in the BI field to limit the number of categories displayed in a chart to 7, our company’s global nature led us to increase the limit to 20 to suit our needs.</p>

<h3 id="8-added-hyperlinks-for-convenience">8. Added hyperlinks for convenience.</h3>

<p><strong>In the content marketing domain, it is common to compare and analyze individual content pages.</strong> For these cases, I always added hyperlinks when creating tables that provide “per-page” insights.</p>

<p>From the perspective of a content marketer, it’s natural to review traffic, CTA conversion rates, engagements, and session duration alongside qualitative insights for each piece of content. <strong>Adding hyperlinks allowed users to quickly navigate to the relevant content pages for deeper analysis.</strong></p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-clicks.webp" alt="" /></p>
<blockquote>
  <p>Example of Internal Dashboard</p>
</blockquote>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-hyperlinks.webp" alt="" /></p>
<blockquote>
  <p>Hyperlink Option</p>
</blockquote>

<h3 id="9-stored-all-query-scripts-separately-in-a-git-repository">9. Stored all query scripts separately in a Git repository.</h3>

<p>Redash allows queries to be saved and categorized with tags for easier retrieval, much like dashboards.</p>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-queries.webp" alt="" /></p>
<blockquote>
  <p>Redash &gt; Queries</p>
</blockquote>

<p><strong>However, as queries are reused or modified across dashboards, manually searching for specific queries becomes inefficient.</strong> Therefore, I implemented a system where all query scripts are managed separately in a Git repository:</p>
<ul>
  <li><strong>Directories</strong>: Correspond to individual dashboards.</li>
  <li><strong>Files</strong>: Each file contains the query for a specific dashboard.</li>
</ul>

<p><img src="/assets/2024-08-09-redash-dashboard/redash-git-repo.webp" alt="" /></p>
<blockquote>
  <p>Internal Redash Git Repository</p>
</blockquote>

<p>Using Git for query management has several advantages:</p>
<ul>
  <li>When a major update, such as taxonomy changes, requires modifications to multiple queries, it significantly reduces the time spent on repetitive tasks.</li>
  <li>When creating new dashboards, reusing queries shortens the search time.</li>
  <li>The VS Code Copilot feature for code generation can further accelerate the work process.</li>
</ul>

<hr />

<h1 id="5-conclusion">5. Conclusion</h1>

<blockquote>
  <ul>
    <li>Avoided creating dashboards mechanically, ensuring they provided real value to users.</li>
    <li>Delivered dashboards that were practically useful for team members.</li>
    <li>Significantly increased Redash usage, reinforcing its role as a BI hub in the organization (approximately DAU <code class="language-plaintext highlighter-rouge">39%</code>, WAU <code class="language-plaintext highlighter-rouge">52%</code>, MAU <code class="language-plaintext highlighter-rouge">77%</code>).</li>
  </ul>
</blockquote>

<p>In conclusion, I shared how Redash was utilized within my company. Throughout this process, one critical insight emerged: <strong>avoiding mechanical dashboard creation is key.</strong> In order to contribute to data-driven decision-making and data literacy, it is essential to continuously ask questions like:</p>

<blockquote>
  <p>“How can we design dashboards that maximize the effectiveness of decision-making and data utilization?”</p>
</blockquote>

<p>While sophisticated and complex charts are valuable, the ultimate goal should be <strong>to deliver dashboards that are truly helpful for team members</strong>. This mindset drove me to study user psychology and apply LLMs in the process of building Redash dashboards.</p>

<p><strong>I do not consider the current dashboards to be perfect.</strong> As business strategies, data, and organizational growth evolve, there will be opportunities to improve them. I plan to maintain a strong focus on BI, striving to continuously improve and contribute to creating a product loved by customers.</p>

<hr />

<h2 id="published-by-joshua-kim"><em>Published by</em> Joshua Kim</h2>
<p><img src="/assets/profile/joshua-profile.png" alt="Joshua Kim" /></p>]]></content><author><name></name></author><category term="Language (English)" /><category term="Article (Project)" /><category term="Level (2. Intermediate)" /><category term="Field (Data Visualization)" /><category term="Skills (Redash)" /><summary type="html"><![CDATA[“Utilizing the open-source BI tool Redash, I visualized data and systematically managed dashboards to ensure easy access for various members of the organization. To improve accessibility and data literacy, I implemented management rules and actively used query parameter functions. This significantly increased Redash usage frequency, strengthening its role as the organization’s BI hub. (Approximately DAU 39%, WAU 52%, MAU 77% among all Redash account holders).”]]></summary></entry></feed>